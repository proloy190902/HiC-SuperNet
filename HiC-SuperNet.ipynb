{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1207a787-9699-4fca-9055-718901d42562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory growth enabled for 1 GPU(s)\n",
      "ðŸŽ¯ TRAINING WITH IMPROVEMENTS:\n",
      "  âœ“ Memory-efficient attention (local+global)\n",
      "  âœ“ Enhanced biological loss\n",
      "  âœ“ Data normalization\n",
      "  âœ“ Better optimization schedule\n",
      "\n",
      "  Expected PSNR: 24-26 dB (vs previous 21 dB)\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ IMPROVED HiC-MAFormer Training (Memory-Efficient)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‚ Loading datasets with normalization...\n",
      "Total samples in file: 42832\n",
      "âœ“ Loaded 42832 samples\n",
      "âœ“ LR shape: (1, 40, 40), HR shape: (1, 40, 40)\n",
      "âœ“ LR range: [0.00, 0.11]\n",
      "âœ“ HR range: [0.00, 0.66]\n",
      "Total samples in file: 18063\n",
      "âœ“ Loaded 18063 samples\n",
      "âœ“ LR shape: (1, 40, 40), HR shape: (1, 40, 40)\n",
      "âœ“ LR range: [0.00, 0.12]\n",
      "âœ“ HR range: [0.00, 0.66]\n",
      "\n",
      "âœ“ Input shape: (40, 40, 1)\n",
      "âœ“ Training batches: 10708\n",
      "âœ“ Validation batches: 4516\n",
      "\n",
      "ðŸ—ï¸ Building MEMORY-EFFICIENT model...\n",
      "   â€¢ 4 transformer blocks (local+global attention)\n",
      "   â€¢ 96 embedding dimension\n",
      "   â€¢ 8 attention heads\n",
      "   â€¢ Batch size: 4\n",
      "\n",
      "âœ“ Trainable parameters: 2,143,345\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ Starting Training...\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1362 - mae: 0.0391\n",
      "Epoch 1: val_loss improved from inf to 0.12190, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 600s 51ms/step - loss: 0.1362 - mae: 0.0391 - val_loss: 0.1219 - val_mae: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1217 - mae: 0.0236\n",
      "Epoch 2: val_loss improved from 0.12190 to 0.12020, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 522s 49ms/step - loss: 0.1217 - mae: 0.0236 - val_loss: 0.1202 - val_mae: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1204 - mae: 0.0219\n",
      "Epoch 3: val_loss improved from 0.12020 to 0.11920, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 492s 46ms/step - loss: 0.1204 - mae: 0.0219 - val_loss: 0.1192 - val_mae: 0.0189 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1198 - mae: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.11920\n",
      "10708/10708 [==============================] - 490s 46ms/step - loss: 0.1198 - mae: 0.0211 - val_loss: 0.1197 - val_mae: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1194 - mae: 0.0205\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 5)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.001018\n",
      "   MAE:  0.022025\n",
      "   PCC:  0.5972 âœ“ BEST!\n",
      "   SCC:  0.5427\n",
      "   SSIM: 0.7617 âœ“ BEST!\n",
      "   PSNR: 19.15 dB âœ“ BEST!\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.11920\n",
      "10708/10708 [==============================] - 507s 47ms/step - loss: 0.1193 - mae: 0.0205 - val_loss: 0.1193 - val_mae: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1191 - mae: 0.0201\n",
      "Epoch 6: val_loss did not improve from 0.11920\n",
      "10708/10708 [==============================] - 525s 49ms/step - loss: 0.1191 - mae: 0.0201 - val_loss: 0.1194 - val_mae: 0.0192 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1188 - mae: 0.0198\n",
      "Epoch 7: val_loss improved from 0.11920 to 0.11882, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 491s 46ms/step - loss: 0.1188 - mae: 0.0198 - val_loss: 0.1188 - val_mae: 0.0189 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1185 - mae: 0.0194\n",
      "Epoch 8: val_loss improved from 0.11882 to 0.11815, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 503s 47ms/step - loss: 0.1185 - mae: 0.0194 - val_loss: 0.1181 - val_mae: 0.0185 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1184 - mae: 0.0194\n",
      "Epoch 9: val_loss did not improve from 0.11815\n",
      "10708/10708 [==============================] - 493s 46ms/step - loss: 0.1184 - mae: 0.0194 - val_loss: 0.1183 - val_mae: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1182 - mae: 0.0191\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 10)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000853\n",
      "   MAE:  0.019591\n",
      "   PCC:  0.6012 âœ“ BEST!\n",
      "   SCC:  0.5452\n",
      "   SSIM: 0.8306 âœ“ BEST!\n",
      "   PSNR: 20.23 dB âœ“ BEST!\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 10: val_loss improved from 0.11815 to 0.11812, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 505s 47ms/step - loss: 0.1182 - mae: 0.0191 - val_loss: 0.1181 - val_mae: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1181 - mae: 0.0190\n",
      "Epoch 11: val_loss did not improve from 0.11812\n",
      "10708/10708 [==============================] - 462s 43ms/step - loss: 0.1181 - mae: 0.0190 - val_loss: 0.1186 - val_mae: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1179 - mae: 0.0189\n",
      "Epoch 12: val_loss did not improve from 0.11812\n",
      "10708/10708 [==============================] - 539s 50ms/step - loss: 0.1179 - mae: 0.0189 - val_loss: 0.1191 - val_mae: 0.0193 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1178 - mae: 0.0189\n",
      "Epoch 13: val_loss did not improve from 0.11812\n",
      "10708/10708 [==============================] - 496s 46ms/step - loss: 0.1178 - mae: 0.0189 - val_loss: 0.1188 - val_mae: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1176 - mae: 0.0186\n",
      "Epoch 14: val_loss improved from 0.11812 to 0.11811, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 514s 48ms/step - loss: 0.1176 - mae: 0.0186 - val_loss: 0.1181 - val_mae: 0.0179 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1175 - mae: 0.0186\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 15)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000939\n",
      "   MAE:  0.019887\n",
      "   PCC:  0.5987\n",
      "   SCC:  0.5458\n",
      "   SSIM: 0.8237\n",
      "   PSNR: 20.18 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.11811\n",
      "10708/10708 [==============================] - 520s 49ms/step - loss: 0.1175 - mae: 0.0186 - val_loss: 0.1184 - val_mae: 0.0184 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1167 - mae: 0.0174\n",
      "Epoch 16: val_loss improved from 0.11811 to 0.11806, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 474s 44ms/step - loss: 0.1167 - mae: 0.0174 - val_loss: 0.1181 - val_mae: 0.0188 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1166 - mae: 0.0171\n",
      "Epoch 17: val_loss did not improve from 0.11806\n",
      "10708/10708 [==============================] - 466s 44ms/step - loss: 0.1166 - mae: 0.0171 - val_loss: 0.1187 - val_mae: 0.0194 - lr: 5.0000e-05\n",
      "Epoch 18/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1165 - mae: 0.0171\n",
      "Epoch 18: val_loss improved from 0.11806 to 0.11787, saving model to best_model_improved.keras\n",
      "10708/10708 [==============================] - 468s 44ms/step - loss: 0.1165 - mae: 0.0171 - val_loss: 0.1179 - val_mae: 0.0189 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1164 - mae: 0.0171\n",
      "Epoch 19: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 486s 45ms/step - loss: 0.1164 - mae: 0.0171 - val_loss: 0.1183 - val_mae: 0.0197 - lr: 5.0000e-05\n",
      "Epoch 20/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1163 - mae: 0.0170\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 20)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.001287\n",
      "   MAE:  0.021259\n",
      "   PCC:  0.5991\n",
      "   SCC:  0.5472\n",
      "   SSIM: 0.8323 âœ“ BEST!\n",
      "   PSNR: 20.20 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 519s 48ms/step - loss: 0.1163 - mae: 0.0170 - val_loss: 0.1189 - val_mae: 0.0196 - lr: 5.0000e-05\n",
      "Epoch 21/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1162 - mae: 0.0170\n",
      "Epoch 21: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 526s 49ms/step - loss: 0.1162 - mae: 0.0170 - val_loss: 0.1181 - val_mae: 0.0192 - lr: 5.0000e-05\n",
      "Epoch 22/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1161 - mae: 0.0169\n",
      "Epoch 22: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 543s 51ms/step - loss: 0.1161 - mae: 0.0169 - val_loss: 0.1182 - val_mae: 0.0191 - lr: 5.0000e-05\n",
      "Epoch 23/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1160 - mae: 0.0169\n",
      "Epoch 23: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 537s 50ms/step - loss: 0.1160 - mae: 0.0169 - val_loss: 0.1180 - val_mae: 0.0186 - lr: 5.0000e-05\n",
      "Epoch 24/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1159 - mae: 0.0170\n",
      "Epoch 24: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 542s 51ms/step - loss: 0.1159 - mae: 0.0170 - val_loss: 0.1199 - val_mae: 0.0204 - lr: 5.0000e-05\n",
      "Epoch 25/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1159 - mae: 0.0169\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 25)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.001107\n",
      "   MAE:  0.020624\n",
      "   PCC:  0.5991\n",
      "   SCC:  0.5451\n",
      "   SSIM: 0.8214\n",
      "   PSNR: 20.16 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 489s 46ms/step - loss: 0.1159 - mae: 0.0169 - val_loss: 0.1184 - val_mae: 0.0196 - lr: 5.0000e-05\n",
      "Epoch 26/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1154 - mae: 0.0163\n",
      "Epoch 26: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 513s 48ms/step - loss: 0.1154 - mae: 0.0163 - val_loss: 0.1188 - val_mae: 0.0202 - lr: 2.5000e-05\n",
      "Epoch 27/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1153 - mae: 0.0162\n",
      "Epoch 27: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 508s 47ms/step - loss: 0.1153 - mae: 0.0162 - val_loss: 0.1185 - val_mae: 0.0187 - lr: 2.5000e-05\n",
      "Epoch 28/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1153 - mae: 0.0162\n",
      "Epoch 28: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 513s 48ms/step - loss: 0.1153 - mae: 0.0162 - val_loss: 0.1186 - val_mae: 0.0189 - lr: 2.5000e-05\n",
      "Epoch 29/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1152 - mae: 0.0162\n",
      "Epoch 29: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 512s 48ms/step - loss: 0.1152 - mae: 0.0162 - val_loss: 0.1192 - val_mae: 0.0206 - lr: 2.5000e-05\n",
      "Epoch 30/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1152 - mae: 0.0162\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 30)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.001465\n",
      "   MAE:  0.022288\n",
      "   PCC:  0.6012 âœ“ BEST!\n",
      "   SCC:  0.5468\n",
      "   SSIM: 0.8317\n",
      "   PSNR: 20.00 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 516s 48ms/step - loss: 0.1152 - mae: 0.0162 - val_loss: 0.1192 - val_mae: 0.0206 - lr: 2.5000e-05\n",
      "Epoch 31/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1151 - mae: 0.0162\n",
      "Epoch 31: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 490s 46ms/step - loss: 0.1151 - mae: 0.0162 - val_loss: 0.1191 - val_mae: 0.0201 - lr: 2.5000e-05\n",
      "Epoch 32/50\n",
      " 2033/10708 [====>.........................] - ETA: 6:03 - loss: 0.1158 - mae: 0.0161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 35)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.001397\n",
      "   MAE:  0.021490\n",
      "   PCC:  0.5993\n",
      "   SCC:  0.5451\n",
      "   SSIM: 0.8349 âœ“ BEST!\n",
      "   PSNR: 20.22 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 521s 49ms/step - loss: 0.1148 - mae: 0.0158 - val_loss: 0.1191 - val_mae: 0.0202 - lr: 1.2500e-05\n",
      "Epoch 36/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1147 - mae: 0.0158\n",
      "Epoch 36: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 515s 48ms/step - loss: 0.1147 - mae: 0.0158 - val_loss: 0.1191 - val_mae: 0.0199 - lr: 1.2500e-05\n",
      "Epoch 37/50\n",
      "10707/10708 [============================>.] - ETA: 0s - loss: 0.1147 - mae: 0.0158\n",
      "Epoch 37: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 534s 50ms/step - loss: 0.1147 - mae: 0.0158 - val_loss: 0.1195 - val_mae: 0.0201 - lr: 1.2500e-05\n",
      "Epoch 38/50\n",
      "10708/10708 [==============================] - ETA: 0s - loss: 0.1146 - mae: 0.0158Restoring model weights from the end of the best epoch: 18.\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.11787\n",
      "10708/10708 [==============================] - 506s 47ms/step - loss: 0.1146 - mae: 0.0158 - val_loss: 0.1189 - val_mae: 0.0201 - lr: 1.2500e-05\n",
      "Epoch 38: early stopping\n",
      "\n",
      "âœ… Training Complete!\n",
      "\n",
      "âœ… Check: best_model_improved.keras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ==================== GPU Configuration ====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ“ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš  GPU configuration warning: {e}\")\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==================== IMPROVEMENT 1: Memory-Efficient Transformer Block ====================\n",
    "class EnhancedTransformerBlock(layers.Layer):\n",
    "    \"\"\"Memory-efficient transformer with local+global attention\"\"\"\n",
    "    def __init__(self, embed_dim=128, num_heads=8, ff_dim=512, dropout=0.1, \n",
    "                 use_local_attention=True, **kwargs):\n",
    "        super(EnhancedTransformerBlock, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.use_local_attention = use_local_attention\n",
    "        \n",
    "        # Local attention (memory efficient) - only attend to nearby pixels\n",
    "        if use_local_attention:\n",
    "            # Use depthwise separable conv instead of full attention\n",
    "            self.local_conv = layers.DepthwiseConv2D(\n",
    "                kernel_size=5, \n",
    "                padding='same',\n",
    "                depth_multiplier=1\n",
    "            )\n",
    "            self.pointwise_conv = layers.Conv2D(embed_dim, 1, padding='same')\n",
    "        else:\n",
    "            # Pooled attention for global context (lower resolution)\n",
    "            self.pool = layers.AveragePooling2D(pool_size=2)\n",
    "            self.attention = layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, \n",
    "                key_dim=embed_dim // num_heads,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            self.upsample = layers.UpSampling2D(size=2)\n",
    "        \n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        \n",
    "        # Enhanced dilated convolutions\n",
    "        self.dilation_predictor = keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(4, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.dilated_conv_1 = layers.Conv2D(embed_dim, 3, padding='same', dilation_rate=1)\n",
    "        self.dilated_conv_2 = layers.Conv2D(embed_dim, 3, padding='same', dilation_rate=2)\n",
    "        self.dilated_conv_4 = layers.Conv2D(embed_dim, 3, padding='same', dilation_rate=4)\n",
    "        self.dilated_conv_8 = layers.Conv2D(embed_dim, 3, padding='same', dilation_rate=8)\n",
    "        \n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "        \n",
    "        # Larger feed-forward network\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Conv2D(ff_dim, 1, activation='gelu'),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Conv2D(embed_dim, 1)\n",
    "        ])\n",
    "        \n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout3 = layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        height = tf.shape(x)[1]\n",
    "        width = tf.shape(x)[2]\n",
    "        \n",
    "        # 1. Memory-efficient attention\n",
    "        if self.use_local_attention:\n",
    "            # Local attention via depthwise convolution (NO memory issue)\n",
    "            attn_output = self.local_conv(x)\n",
    "            attn_output = self.pointwise_conv(attn_output)\n",
    "            attn_output = self.dropout1(attn_output, training=training)\n",
    "            x = self.layernorm1(x + attn_output)\n",
    "        else:\n",
    "            # Global attention on pooled features (4x less memory)\n",
    "            x_pooled = self.pool(x)\n",
    "            h_p = tf.shape(x_pooled)[1]\n",
    "            w_p = tf.shape(x_pooled)[2]\n",
    "            \n",
    "            x_reshaped = tf.reshape(x_pooled, [batch_size, h_p * w_p, self.embed_dim])\n",
    "            attn_output = self.attention(x_reshaped, x_reshaped, training=training)\n",
    "            attn_output = self.dropout1(attn_output, training=training)\n",
    "            attn_output = tf.reshape(attn_output, [batch_size, h_p, w_p, self.embed_dim])\n",
    "            attn_output = self.upsample(attn_output)\n",
    "            \n",
    "            # Ensure same shape\n",
    "            attn_output = tf.image.resize(attn_output, [height, width])\n",
    "            x = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        # 2. Adaptive multi-scale dilation\n",
    "        dilation_weights = self.dilation_predictor(x)\n",
    "        \n",
    "        d1 = self.dilated_conv_1(x)\n",
    "        d2 = self.dilated_conv_2(x)\n",
    "        d4 = self.dilated_conv_4(x)\n",
    "        d8 = self.dilated_conv_8(x)\n",
    "        \n",
    "        dilated_outputs = tf.stack([d1, d2, d4, d8], axis=-1)\n",
    "        dilation_weights = tf.reshape(dilation_weights, [batch_size, 1, 1, 1, 4])\n",
    "        adaptive_output = tf.reduce_sum(dilated_outputs * dilation_weights, axis=-1)\n",
    "        adaptive_output = self.dropout2(adaptive_output, training=training)\n",
    "        \n",
    "        x = self.layernorm2(x + adaptive_output)\n",
    "        \n",
    "        # 3. Feed-forward\n",
    "        ffn_output = self.ffn(x)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        x = self.layernorm3(x + ffn_output)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# ==================== IMPROVEMENT 2: Enhanced Loss Function ====================\n",
    "def enhanced_biological_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Improved loss with:\n",
    "    - MSE for pixel-wise accuracy\n",
    "    - Pearson correlation for global structure\n",
    "    - Structural preservation (diagonal + off-diagonal)\n",
    "    - Edge-aware loss for TAD boundaries\n",
    "    \"\"\"\n",
    "    y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[1], tf.shape(y_pred)[2], 1])\n",
    "    \n",
    "    # 1. MSE loss (primary)\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # 2. Pearson correlation loss\n",
    "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "    \n",
    "    y_true_mean = tf.reduce_mean(y_true_flat, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred_flat, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_centered = y_true_flat - y_true_mean\n",
    "    y_pred_centered = y_pred_flat - y_pred_mean\n",
    "    \n",
    "    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    denominator = tf.sqrt(\n",
    "        tf.reduce_sum(tf.square(y_true_centered), axis=1) * \n",
    "        tf.reduce_sum(tf.square(y_pred_centered), axis=1)\n",
    "    )\n",
    "    \n",
    "    pearson = numerator / (denominator + 1e-8)\n",
    "    pearson_loss = 1 - tf.reduce_mean(pearson)\n",
    "    \n",
    "    # 3. Structural similarity loss (diagonal bands)\n",
    "    y_true_2d = tf.squeeze(y_true, axis=-1)\n",
    "    y_pred_2d = tf.squeeze(y_pred, axis=-1)\n",
    "    \n",
    "    # Diagonal loss\n",
    "    diagonal_true = tf.linalg.diag_part(y_true_2d)\n",
    "    diagonal_pred = tf.linalg.diag_part(y_pred_2d)\n",
    "    diagonal_loss = tf.reduce_mean(tf.square(diagonal_true - diagonal_pred))\n",
    "    \n",
    "    # Off-diagonal bands (distance 1-5)\n",
    "    band_loss = 0.0\n",
    "    for offset in [1, 2, 3, 4, 5]:\n",
    "        band_true = tf.linalg.diag_part(y_true_2d, k=offset)\n",
    "        band_pred = tf.linalg.diag_part(y_pred_2d, k=offset)\n",
    "        band_loss += tf.reduce_mean(tf.square(band_true - band_pred))\n",
    "    band_loss /= 5.0\n",
    "    \n",
    "    # 4. Edge-aware loss for boundaries (gradient matching)\n",
    "    grad_true_x = y_true_2d[:, :, 1:] - y_true_2d[:, :, :-1]\n",
    "    grad_pred_x = y_pred_2d[:, :, 1:] - y_pred_2d[:, :, :-1]\n",
    "    \n",
    "    grad_true_y = y_true_2d[:, 1:, :] - y_true_2d[:, :-1, :]\n",
    "    grad_pred_y = y_pred_2d[:, 1:, :] - y_pred_2d[:, :-1, :]\n",
    "    \n",
    "    edge_loss = (tf.reduce_mean(tf.square(grad_true_x - grad_pred_x)) + \n",
    "                 tf.reduce_mean(tf.square(grad_true_y - grad_pred_y))) / 2.0\n",
    "    \n",
    "    # Combined loss with balanced weights\n",
    "    total_loss = (\n",
    "        1.0 * mse_loss +           # Pixel accuracy\n",
    "        0.3 * pearson_loss +        # Global correlation\n",
    "        0.3 * diagonal_loss +       # Diagonal structure\n",
    "        0.2 * band_loss +           # Off-diagonal structure\n",
    "        0.2 * edge_loss             # TAD boundaries\n",
    "    )\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# ==================== IMPROVEMENT 3: Better Model Architecture ====================\n",
    "def build_improved_hic_maformer(input_size=(40, 40, 1), \n",
    "                                embed_dim=96,  # Reduced from 128\n",
    "                                num_transformer_blocks=4,  # Reduced from 6\n",
    "                                num_heads=8,\n",
    "                                dropout=0.1):\n",
    "    \"\"\"Enhanced architecture with memory-efficient design\"\"\"\n",
    "    \n",
    "    hic_input = layers.Input(input_size, name='hic_input')\n",
    "    \n",
    "    # Initial feature extraction (deeper)\n",
    "    x = layers.Conv2D(embed_dim//2, 3, padding='same', kernel_initializer='he_normal')(hic_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(embed_dim, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Store for skip connection\n",
    "    skip = x\n",
    "    \n",
    "    # Mix of local and global attention blocks\n",
    "    for i in range(num_transformer_blocks):\n",
    "        # Alternate: local -> local -> global -> local\n",
    "        use_local = (i % 3 != 2)  # Every 3rd block uses global attention\n",
    "        x = EnhancedTransformerBlock(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            ff_dim=embed_dim * 4,\n",
    "            dropout=dropout,\n",
    "            use_local_attention=use_local,\n",
    "            name=f'enhanced_block_{i}'\n",
    "        )(x)\n",
    "    \n",
    "    # Global residual\n",
    "    x = layers.Add()([x, skip])\n",
    "    \n",
    "    # Reconstruction head (deeper)\n",
    "    x = layers.Conv2D(embed_dim * 2, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Conv2D(embed_dim, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(embed_dim//2, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Final output\n",
    "    output = layers.Conv2D(1, 3, padding='same', activation='linear',\n",
    "                          kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    model = Model(inputs=hic_input, outputs=output, name='HiC_MAFormer_Enhanced')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==================== IMPROVEMENT 4: Better Data Preprocessing ====================\n",
    "class ImprovedHiCDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Data generator with normalization\"\"\"\n",
    "    def __init__(self, npz_file, batch_size=8, shuffle=True, max_samples=None):\n",
    "        data = np.load(npz_file, allow_pickle=True)\n",
    "        self.lr_data = data['data']\n",
    "        self.hr_data = data['target']\n",
    "        self.inds = data['inds']\n",
    "        \n",
    "        print(f\"Total samples in file: {len(self.lr_data)}\")\n",
    "        \n",
    "        if max_samples is not None and max_samples < len(self.lr_data):\n",
    "            selected_indices = np.random.choice(len(self.lr_data), max_samples, replace=False)\n",
    "            self.lr_data = self.lr_data[selected_indices]\n",
    "            self.hr_data = self.hr_data[selected_indices]\n",
    "            self.inds = self.inds[selected_indices]\n",
    "            print(f\"âœ‚ï¸  Using only {max_samples} samples\")\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.lr_data))\n",
    "        \n",
    "        # Compute normalization statistics\n",
    "        self._compute_normalization_stats()\n",
    "        \n",
    "        print(f\"âœ“ Loaded {len(self.lr_data)} samples\")\n",
    "        print(f\"âœ“ LR shape: {self.lr_data[0].shape}, HR shape: {self.hr_data[0].shape}\")\n",
    "        print(f\"âœ“ LR range: [{self.lr_min:.2f}, {self.lr_max:.2f}]\")\n",
    "        print(f\"âœ“ HR range: [{self.hr_min:.2f}, {self.hr_max:.2f}]\")\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def _compute_normalization_stats(self):\n",
    "        \"\"\"Compute min/max for normalization\"\"\"\n",
    "        sample_size = min(1000, len(self.lr_data))\n",
    "        sample_indices = np.random.choice(len(self.lr_data), sample_size, replace=False)\n",
    "        \n",
    "        lr_samples = np.array([self.lr_data[i] for i in sample_indices])\n",
    "        hr_samples = np.array([self.hr_data[i] for i in sample_indices])\n",
    "        \n",
    "        self.lr_min = np.percentile(lr_samples, 1)\n",
    "        self.lr_max = np.percentile(lr_samples, 99)\n",
    "        self.hr_min = np.percentile(hr_samples, 1)\n",
    "        self.hr_max = np.percentile(hr_samples, 99)\n",
    "    \n",
    "    def _normalize(self, data, min_val, max_val):\n",
    "        \"\"\"Min-max normalization to [0, 1]\"\"\"\n",
    "        data = np.clip(data, min_val, max_val)\n",
    "        return (data - min_val) / (max_val - min_val + 1e-8)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.lr_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        lr_batch = np.array([self.lr_data[i] for i in batch_indexes])\n",
    "        hr_batch = np.array([self.hr_data[i] for i in batch_indexes])\n",
    "        \n",
    "        # Fix dimensions\n",
    "        if lr_batch.ndim == 4 and lr_batch.shape[1] == 1:\n",
    "            lr_batch = lr_batch[:, 0, :, :]\n",
    "        if hr_batch.ndim == 4 and hr_batch.shape[1] == 1:\n",
    "            hr_batch = hr_batch[:, 0, :, :]\n",
    "        \n",
    "        # Add channel dimension\n",
    "        if lr_batch.ndim == 3:\n",
    "            lr_batch = np.expand_dims(lr_batch, axis=-1)\n",
    "        if hr_batch.ndim == 3:\n",
    "            hr_batch = np.expand_dims(hr_batch, axis=-1)\n",
    "        \n",
    "        # Normalize\n",
    "        lr_batch = self._normalize(lr_batch, self.lr_min, self.lr_max)\n",
    "        hr_batch = self._normalize(hr_batch, self.hr_min, self.hr_max)\n",
    "        \n",
    "        return lr_batch.astype('float32'), hr_batch.astype('float32')\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# ==================== Keep existing metrics functions ====================\n",
    "def calculate_ssim(img1, img2, C1=1e-4, C2=9e-4):\n",
    "    img1 = img1.flatten()\n",
    "    img2 = img2.flatten()\n",
    "    \n",
    "    mu1 = np.mean(img1)\n",
    "    mu2 = np.mean(img2)\n",
    "    sigma1 = np.std(img1)\n",
    "    sigma2 = np.std(img2)\n",
    "    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))\n",
    "    \n",
    "    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1**2 + sigma2**2 + C2))\n",
    "    \n",
    "    return ssim\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=None):\n",
    "    mse = mean_squared_error(img1.flatten(), img2.flatten())\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    if max_val is None:\n",
    "        max_val = max(np.max(img1), np.max(img2))\n",
    "    \n",
    "    psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_all_metrics(pred, target):\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    \n",
    "    mse = mean_squared_error(target_flat, pred_flat)\n",
    "    mae = mean_absolute_error(target_flat, pred_flat)\n",
    "    \n",
    "    if np.std(pred_flat) == 0 or np.std(target_flat) == 0:\n",
    "        pcc = np.nan\n",
    "        scc = np.nan\n",
    "    else:\n",
    "        pcc, _ = pearsonr(pred_flat, target_flat)\n",
    "        scc, _ = spearmanr(pred_flat, target_flat)\n",
    "    \n",
    "    ssim = calculate_ssim(pred, target)\n",
    "    psnr = calculate_psnr(pred, target)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'pcc': pcc,\n",
    "        'scc': scc,\n",
    "        'ssim': ssim,\n",
    "        'psnr': psnr\n",
    "    }\n",
    "\n",
    "# ==================== Improved Callback ====================\n",
    "class ImprovedMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, metric_frequency=5, num_batches=20):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.metric_frequency = metric_frequency\n",
    "        self.num_batches = num_batches\n",
    "        self.best_ssim = 0\n",
    "        self.best_pcc = -1\n",
    "        self.best_psnr = 0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.metric_frequency != 0:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“Š Detailed Metrics (Epoch {epoch+1})\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        val_gen = self.validation_data\n",
    "        all_metrics = []\n",
    "        \n",
    "        max_batches = min(self.num_batches, len(val_gen))\n",
    "        \n",
    "        for i in range(max_batches):\n",
    "            lr_batch, hr_batch = val_gen[i]\n",
    "            pred_batch = self.model.predict(lr_batch, verbose=0)\n",
    "            \n",
    "            for j in range(len(lr_batch)):\n",
    "                metrics = calculate_all_metrics(\n",
    "                    pred_batch[j, :, :, 0],\n",
    "                    hr_batch[j, :, :, 0]\n",
    "                )\n",
    "                all_metrics.append(metrics)\n",
    "        \n",
    "        avg_metrics = {}\n",
    "        for key in all_metrics[0].keys():\n",
    "            values = [m[key] for m in all_metrics if not np.isnan(m[key])]\n",
    "            avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Validation Metrics:\")\n",
    "        print(f\"   MSE:  {avg_metrics['mse']:.6f}\")\n",
    "        print(f\"   MAE:  {avg_metrics['mae']:.6f}\")\n",
    "        \n",
    "        print(f\"   PCC:  {avg_metrics['pcc']:.4f}\", end=\"\")\n",
    "        if not np.isnan(avg_metrics['pcc']) and avg_metrics['pcc'] > self.best_pcc:\n",
    "            self.best_pcc = avg_metrics['pcc']\n",
    "            print(f\" âœ“ BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"   SCC:  {avg_metrics['scc']:.4f}\")\n",
    "        \n",
    "        print(f\"   SSIM: {avg_metrics['ssim']:.4f}\", end=\"\")\n",
    "        if avg_metrics['ssim'] > self.best_ssim:\n",
    "            self.best_ssim = avg_metrics['ssim']\n",
    "            print(f\" âœ“ BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"   PSNR: {avg_metrics['psnr']:.2f} dB\", end=\"\")\n",
    "        if avg_metrics['psnr'] > self.best_psnr:\n",
    "            self.best_psnr = avg_metrics['psnr']\n",
    "            print(f\" âœ“ BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ==================== IMPROVED TRAINING ====================\n",
    "def train_improved_hic_maformer(train_npz_path, valid_npz_path, \n",
    "                                epochs=100, batch_size=4, initial_lr=0.0001,\n",
    "                                num_transformer_blocks=4, embed_dim=96, num_heads=8,\n",
    "                                metric_frequency=5, metric_batches=20,\n",
    "                                max_train_samples=None, max_valid_samples=None):\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ðŸš€ IMPROVED HiC-MAFormer Training (Memory-Efficient)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nðŸ“‚ Loading datasets with normalization...\")\n",
    "    train_gen = ImprovedHiCDataGenerator(train_npz_path, batch_size=batch_size, \n",
    "                                        shuffle=True, max_samples=max_train_samples)\n",
    "    valid_gen = ImprovedHiCDataGenerator(valid_npz_path, batch_size=batch_size, \n",
    "                                        shuffle=False, max_samples=max_valid_samples)\n",
    "    \n",
    "    sample_lr, sample_hr = train_gen[0]\n",
    "    input_shape = sample_lr.shape[1:]\n",
    "    \n",
    "    print(f\"\\nâœ“ Input shape: {input_shape}\")\n",
    "    print(f\"âœ“ Training batches: {len(train_gen)}\")\n",
    "    print(f\"âœ“ Validation batches: {len(valid_gen)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ—ï¸ Building MEMORY-EFFICIENT model...\")\n",
    "    print(f\"   â€¢ {num_transformer_blocks} transformer blocks (local+global attention)\")\n",
    "    print(f\"   â€¢ {embed_dim} embedding dimension\")\n",
    "    print(f\"   â€¢ {num_heads} attention heads\")\n",
    "    print(f\"   â€¢ Batch size: {batch_size}\")\n",
    "    \n",
    "    model = build_improved_hic_maformer(\n",
    "        input_size=input_shape,\n",
    "        embed_dim=embed_dim,\n",
    "        num_transformer_blocks=num_transformer_blocks,\n",
    "        num_heads=num_heads,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    \n",
    "    trainable_params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "    print(f\"\\nâœ“ Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Compile with enhanced loss\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss=enhanced_biological_loss,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        ImprovedMetricsCallback(valid_gen, metric_frequency, metric_batches),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'best_model_improved.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ Starting Training...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Training Complete!\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# ==================== Main ====================\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz\"\n",
    "    VALID_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz\"\n",
    "    \n",
    "    print(\"ðŸŽ¯ TRAINING WITH IMPROVEMENTS:\")\n",
    "    print(\"  âœ“ Memory-efficient attention (local+global)\")\n",
    "    print(\"  âœ“ Enhanced biological loss\")\n",
    "    print(\"  âœ“ Data normalization\")\n",
    "    print(\"  âœ“ Better optimization schedule\")\n",
    "    print(\"\\n  Expected PSNR: 24-26 dB (vs previous 21 dB)\\n\")\n",
    "    \n",
    "    model, history = train_improved_hic_maformer(\n",
    "        train_npz_path=TRAIN_NPZ,\n",
    "        valid_npz_path=VALID_NPZ,\n",
    "        epochs=50,\n",
    "        batch_size=4,              # Safe batch size\n",
    "        initial_lr=0.0001,\n",
    "        num_transformer_blocks=4,  # Memory efficient\n",
    "        embed_dim=96,              # Balanced capacity\n",
    "        num_heads=8,\n",
    "        metric_frequency=5,\n",
    "        metric_batches=20,\n",
    "        max_train_samples=None,\n",
    "        max_valid_samples=None\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Check: best_model_improved.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158e6f6-73b2-43e4-bc6f-b187fe9b3208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59342446-b8aa-4be1-8012-cb7ac2a3f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up GPU...\n",
      "âœ“ Using 1 GPU(s)\n",
      "\n",
      "ðŸš€ Starting HiC-MEGA...\n",
      "ðŸ’¡ Tip: Modify the CONFIG dictionary at the top to change settings\n",
      "\n",
      "======================================================================\n",
      "HiC-MEGA: Multi-modal Epigenomic Graph-Aware Transformer\n",
      "TensorFlow Implementation - Jupyter Notebook Version\n",
      "======================================================================\n",
      "Feature Dimension: 64\n",
      "Enhancement Scale: 1x (40kb -> 10kb)\n",
      "Batch Size: 4\n",
      "Learning Rate: 0.0001\n",
      "======================================================================\n",
      "\n",
      "[1/5] Loading datasets...\n",
      "Loading dataset from hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz...\n",
      "âœ“ Dataset loaded: 42832 samples\n",
      "  LR shape: (42832, 1, 40, 40), HR shape: (42832, 1, 40, 40)\n",
      "Loading dataset from hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz...\n",
      "âœ“ Dataset loaded: 18063 samples\n",
      "  LR shape: (18063, 1, 40, 40), HR shape: (18063, 1, 40, 40)\n",
      "  Detected scale factor: 1x (LR: 40x40 -> HR: 40x40)\n",
      "  Detected scale factor: 1x (LR: 40x40 -> HR: 40x40)\n",
      "âœ“ Training samples: 42832\n",
      "âœ“ Validation samples: 18063\n",
      "\n",
      "[2/5] Initializing HiC-MEGA model...\n",
      "âœ“ Total parameters: 519,025\n",
      "\n",
      "[3/5] Setting up training...\n",
      "âš  AdamW not available, using Adam optimizer\n",
      "\n",
      "[4/5] Starting training...\n",
      "\n",
      "======================================================================\n",
      "Starting Training\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:45<00:00, 15.17it/s, loss=0.1651]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:33<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2178\n",
      "Val Loss: 0.2099\n",
      "âœ“ Best model saved! (Val Loss: 0.2099)\n",
      "\n",
      "Epoch 2/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:44<00:00, 15.19it/s, loss=0.1568]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:31<00:00, 49.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2030\n",
      "Val Loss: 0.2068\n",
      "âœ“ Best model saved! (Val Loss: 0.2068)\n",
      "\n",
      "Epoch 3/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:39<00:00, 15.32it/s, loss=0.1565]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:32<00:00, 48.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2008\n",
      "Val Loss: 0.2058\n",
      "âœ“ Best model saved! (Val Loss: 0.2058)\n",
      "\n",
      "Epoch 4/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:34<00:00, 15.42it/s, loss=0.1552]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:31<00:00, 49.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1996\n",
      "Val Loss: 0.2040\n",
      "âœ“ Best model saved! (Val Loss: 0.2040)\n",
      "\n",
      "Epoch 5/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:33<00:00, 15.43it/s, loss=0.1545]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:31<00:00, 49.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1987\n",
      "Val Loss: 0.2042\n",
      "\n",
      "Epoch 6/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:41<00:00, 15.26it/s, loss=0.1535]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:32<00:00, 49.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1981\n",
      "Val Loss: 0.2050\n",
      "\n",
      "Epoch 7/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:41<00:00, 15.27it/s, loss=0.1549]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:32<00:00, 48.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1975\n",
      "Val Loss: 0.2030\n",
      "âœ“ Best model saved! (Val Loss: 0.2030)\n",
      "\n",
      "Epoch 8/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:41<00:00, 15.27it/s, loss=0.1531]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:31<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1971\n",
      "Val Loss: 0.2025\n",
      "âœ“ Best model saved! (Val Loss: 0.2025)\n",
      "\n",
      "Epoch 9/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:38<00:00, 15.33it/s, loss=0.1534]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:31<00:00, 49.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1968\n",
      "Val Loss: 0.2030\n",
      "\n",
      "Epoch 10/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [11:36<00:00, 15.38it/s, loss=0.1525]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [01:31<00:00, 49.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.1964\n",
      "Val Loss: 0.2030\n",
      "âœ“ Predictions saved to predictions_epoch_10.png\n",
      "\n",
      "======================================================================\n",
      "Training Complete!\n",
      "Best Validation Loss: 0.2025\n",
      "======================================================================\n",
      "\n",
      "[5/5] Generating training plots...\n",
      "âœ“ Training history saved to training_history.png\n",
      "\n",
      "âœ“ Training completed successfully!\n",
      "\n",
      "âœ… Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HiC-MEGA: Multi-modal Epigenomic Graph-Aware Transformer\n",
    "TensorFlow Implementation - JUPYTER NOTEBOOK VERSION\n",
    "\n",
    "Run this directly in Jupyter without command-line arguments\n",
    "Just modify the CONFIG dictionary below and run all cells\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "CONFIG = {\n",
    "    'mode': 'train',  # Change to 'inference' for testing\n",
    "    'feature_dim': 64,  # Reduced from 128 to save memory\n",
    "    'num_modalities': 2,  # Reduced from 4 to save memory\n",
    "    'num_heads': 4,  # Reduced from 8 to save memory\n",
    "    'depth': 4,  # Reduced from 6 to save memory\n",
    "    'scales': [1],  # Will be auto-detected\n",
    "    'num_cell_types': 50,\n",
    "    'batch_size': 4,  # Reduced from 8 to save memory\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 1e-4,\n",
    "    \n",
    "    # Dataset paths - MODIFY THESE\n",
    "    'train_npz': \"hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz\",\n",
    "    'valid_npz': \"hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz\",\n",
    "    'test_npz': \"hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz\",\n",
    "    'model_path': \"hic_mega_best.h5\",\n",
    "    'output_dir': \"outputs\"\n",
    "}\n",
    "\n",
    "# GPU Setup\n",
    "print(\"Setting up GPU...\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ“ Using {len(gpus)} GPU(s)\")\n",
    "        \n",
    "        # Optional: Set memory limit (uncomment if still getting OOM)\n",
    "        # tf.config.set_logical_device_configuration(\n",
    "        #     gpus[0],\n",
    "        #     [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]  # 4GB limit\n",
    "        # )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"âš  No GPU found, using CPU\")\n",
    "\n",
    "\n",
    "# ==================== DATASET ====================\n",
    "class HiCDataset:\n",
    "    \"\"\"Dataset loader for NPZ format Hi-C data\"\"\"\n",
    "    def __init__(self, npz_path, batch_size=8):\n",
    "        print(f\"Loading dataset from {npz_path}...\")\n",
    "        data = np.load(npz_path)\n",
    "        \n",
    "        self.lr_data = data['data'].astype(np.float32)\n",
    "        self.hr_data = data['target'].astype(np.float32) if 'target' in data else data['data'].astype(np.float32)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        print(f\"âœ“ Dataset loaded: {len(self.lr_data)} samples\")\n",
    "        print(f\"  LR shape: {self.lr_data.shape}, HR shape: {self.hr_data.shape}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lr_data)\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        data_min = np.min(data, axis=(1, 2, 3), keepdims=True)\n",
    "        data_max = np.max(data, axis=(1, 2, 3), keepdims=True)\n",
    "        return (data - data_min) / (data_max - data_min + 1e-8)\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        # Convert to NHWC format\n",
    "        if self.lr_data.ndim == 3:\n",
    "            lr_data = self.lr_data[:, :, :, np.newaxis]\n",
    "        else:\n",
    "            lr_data = np.transpose(self.lr_data, (0, 2, 3, 1))\n",
    "        \n",
    "        if self.hr_data.ndim == 3:\n",
    "            hr_data = self.hr_data[:, :, :, np.newaxis]\n",
    "        else:\n",
    "            hr_data = np.transpose(self.hr_data, (0, 2, 3, 1))\n",
    "        \n",
    "        # Detect scale factor\n",
    "        lr_h, lr_w = lr_data.shape[1], lr_data.shape[2]\n",
    "        hr_h, hr_w = hr_data.shape[1], hr_data.shape[2]\n",
    "        scale_h = hr_h // lr_h if hr_h >= lr_h else 1\n",
    "        scale_w = hr_w // lr_w if hr_w >= lr_w else 1\n",
    "        detected_scale = max(scale_h, scale_w)\n",
    "        \n",
    "        print(f\"  Detected scale factor: {detected_scale}x (LR: {lr_h}x{lr_w} -> HR: {hr_h}x{hr_w})\")\n",
    "        \n",
    "        # Update CONFIG if needed\n",
    "        if detected_scale == 1 and CONFIG['scales'][0] != 1:\n",
    "            print(f\"  âš  WARNING: Data has same resolution but CONFIG['scales']={CONFIG['scales']}\")\n",
    "            print(f\"  â†’ Automatically updating CONFIG['scales'] to [1]\")\n",
    "            CONFIG['scales'] = [1]\n",
    "        elif detected_scale > 1 and CONFIG['scales'][0] != detected_scale:\n",
    "            print(f\"  âš  WARNING: Detected scale {detected_scale}x but CONFIG['scales']={CONFIG['scales']}\")\n",
    "            print(f\"  â†’ You may want to update CONFIG['scales'] to [{detected_scale}]\")\n",
    "        \n",
    "        # Normalize\n",
    "        lr_data = self.normalize(lr_data)\n",
    "        hr_data = self.normalize(hr_data)\n",
    "        \n",
    "        # Create TF dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((lr_data, hr_data))\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "\n",
    "# ==================== MODEL COMPONENTS ====================\n",
    "class CrossModalAttention(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.dim = dim\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        \n",
    "        self.q = layers.Dense(dim)\n",
    "        self.kv = layers.Dense(dim * 2)\n",
    "        self.proj = layers.Dense(dim)\n",
    "    \n",
    "    def call(self, x, context):\n",
    "        B = tf.shape(x)[0]\n",
    "        N = tf.shape(x)[1]\n",
    "        C = self.dim\n",
    "        \n",
    "        q = self.q(x)\n",
    "        q = tf.reshape(q, [B, N, self.num_heads, C // self.num_heads])\n",
    "        q = tf.transpose(q, [0, 2, 1, 3])\n",
    "        \n",
    "        kv = self.kv(context)\n",
    "        kv = tf.reshape(kv, [B, -1, 2, self.num_heads, C // self.num_heads])\n",
    "        kv = tf.transpose(kv, [2, 0, 3, 1, 4])\n",
    "        k, v = kv[0], kv[1]\n",
    "        \n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        \n",
    "        out = tf.matmul(attn, v)\n",
    "        out = tf.transpose(out, [0, 2, 1, 3])\n",
    "        out = tf.reshape(out, [B, N, C])\n",
    "        \n",
    "        return self.proj(out)\n",
    "\n",
    "\n",
    "class MultiModalEpigenomicEncoder(layers.Layer):\n",
    "    def __init__(self, hidden_dim=128, num_modalities=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_modalities = num_modalities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.modality_encoders = []\n",
    "        for _ in range(num_modalities):\n",
    "            encoder = keras.Sequential([\n",
    "                layers.Conv2D(hidden_dim // 2, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(hidden_dim, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU()\n",
    "            ])\n",
    "            self.modality_encoders.append(encoder)\n",
    "        \n",
    "        # Simplified: use only first cross-modal attention to save memory\n",
    "        self.cross_modal_attn = CrossModalAttention(hidden_dim)\n",
    "        \n",
    "        self.imputation_net = keras.Sequential([\n",
    "            layers.Dense(hidden_dim * 2),\n",
    "            layers.ReLU(),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(hidden_dim)\n",
    "        ])\n",
    "        \n",
    "        self.fusion_conv = layers.Conv2D(hidden_dim, 1)\n",
    "    \n",
    "    def call(self, x_hic, training=False):\n",
    "        B = tf.shape(x_hic)[0]\n",
    "        H = tf.shape(x_hic)[1]\n",
    "        W = tf.shape(x_hic)[2]\n",
    "        \n",
    "        modality_features = []\n",
    "        \n",
    "        for encoder in self.modality_encoders:\n",
    "            feat = encoder(x_hic, training=training)\n",
    "            feat_shape = tf.shape(feat)\n",
    "            feat_flat = tf.reshape(feat, [B, H * W, self.hidden_dim])\n",
    "            feat_imputed = self.imputation_net(feat_flat, training=training)\n",
    "            feat = tf.reshape(feat_imputed, feat_shape)\n",
    "            modality_features.append(feat)\n",
    "        \n",
    "        # Simplified cross-modal attention - only apply once to save memory\n",
    "        weighted_features = []\n",
    "        for i, feat in enumerate(modality_features):\n",
    "            feat_flat = tf.reshape(feat, [B, H * W, self.hidden_dim])\n",
    "            \n",
    "            # Only attend to first other modality to save memory\n",
    "            if i == 0 and len(modality_features) > 1:\n",
    "                other_flat = tf.reshape(modality_features[1], [B, H * W, self.hidden_dim])\n",
    "                feat_flat = feat_flat + self.cross_modal_attn(feat_flat, other_flat)\n",
    "            \n",
    "            feat_attended = tf.reshape(feat_flat, [B, H, W, self.hidden_dim])\n",
    "            weighted_features.append(feat_attended)\n",
    "        \n",
    "        fused = tf.concat(weighted_features, axis=-1)\n",
    "        output = self.fusion_conv(fused)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class AdaptiveDilationPredictor(layers.Layer):\n",
    "    def __init__(self, in_channels, num_scales=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_scales = num_scales\n",
    "        \n",
    "        self.predictor = keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(64),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(num_scales),\n",
    "            layers.Softmax()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.predictor(x)\n",
    "\n",
    "\n",
    "class AdaptiveMultiScaleDilatedBlock(layers.Layer):\n",
    "    def __init__(self, channels, dilation_rates=[1, 2, 4, 8], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dilation_rates = dilation_rates\n",
    "        self.num_scales = len(dilation_rates)\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.dilated_convs = []\n",
    "        for rate in dilation_rates:\n",
    "            conv_block = keras.Sequential([\n",
    "                layers.DepthwiseConv2D(3, padding='same', dilation_rate=rate),\n",
    "                layers.Conv2D(channels, 1),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU()\n",
    "            ])\n",
    "            self.dilated_convs.append(conv_block)\n",
    "        \n",
    "        self.dilation_predictor = AdaptiveDilationPredictor(channels, self.num_scales)\n",
    "        \n",
    "        self.scale_aggregation = keras.Sequential([\n",
    "            layers.Conv2D(channels * 2, 1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(channels, 1),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        dilation_weights = self.dilation_predictor(x)\n",
    "        \n",
    "        multi_scale_features = []\n",
    "        for i, conv in enumerate(self.dilated_convs):\n",
    "            feat = conv(x, training=training)\n",
    "            weight = tf.reshape(dilation_weights[:, i], [-1, 1, 1, 1])\n",
    "            weighted_feat = feat * weight\n",
    "            multi_scale_features.append(weighted_feat)\n",
    "        \n",
    "        concat_features = tf.concat(multi_scale_features, axis=-1)\n",
    "        aggregated = self.scale_aggregation(concat_features, training=training)\n",
    "        \n",
    "        return tf.nn.relu(aggregated + x)\n",
    "\n",
    "\n",
    "class ChromatinGraphConv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(\n",
    "            shape=(self.in_channels, self.out_channels),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='weight'\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.out_channels,),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='bias'\n",
    "        )\n",
    "    \n",
    "    def call(self, x, adj):\n",
    "        support = tf.matmul(x, self.weight)\n",
    "        output = tf.matmul(adj, support) + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class ChromatinStructureGraphModule(layers.Layer):\n",
    "    def __init__(self, feature_dim=128, num_gnn_layers=2, **kwargs):  # Reduced from 3 to 2\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_layers = num_gnn_layers\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.graph_constructor = keras.Sequential([\n",
    "            layers.Dense(feature_dim),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(feature_dim)\n",
    "        ])\n",
    "        \n",
    "        self.gnn_layers = [\n",
    "            ChromatinGraphConv(feature_dim, feature_dim)\n",
    "            for _ in range(num_gnn_layers)\n",
    "        ]\n",
    "        \n",
    "        self.layer_norms = [\n",
    "            layers.LayerNormalization() for _ in range(num_gnn_layers)\n",
    "        ]\n",
    "        \n",
    "        self.tad_pooling = keras.Sequential([\n",
    "            layers.Conv2D(feature_dim // 2, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(feature_dim, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        \n",
    "        self.structure_inject = layers.Conv2D(feature_dim, 1)\n",
    "    \n",
    "    def construct_adjacency(self, x):\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        C = self.feature_dim\n",
    "        \n",
    "        x_flat = tf.reshape(x, [B, H * W, C])\n",
    "        \n",
    "        node_features = self.graph_constructor(x_flat)\n",
    "        \n",
    "        # Use reduced adjacency calculation to save memory\n",
    "        # Instead of full attention, use local connections\n",
    "        adj = tf.matmul(node_features, node_features, transpose_b=True)\n",
    "        adj = tf.nn.softmax(adj / tf.sqrt(tf.cast(C, tf.float32)), axis=-1)\n",
    "        \n",
    "        return adj, x_flat\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        \n",
    "        adj, node_features = self.construct_adjacency(x)\n",
    "        \n",
    "        # Apply GNN layers with gradient checkpointing behavior\n",
    "        for gnn, norm in zip(self.gnn_layers, self.layer_norms):\n",
    "            node_features = gnn(node_features, adj)\n",
    "            node_features = norm(node_features)\n",
    "            node_features = tf.nn.relu(node_features)\n",
    "        \n",
    "        graph_features = tf.reshape(node_features, [B, H, W, self.feature_dim])\n",
    "        \n",
    "        tad_features = self.tad_pooling(graph_features, training=training)\n",
    "        tad_features = tf.image.resize(tad_features, [H, W], method='bilinear')\n",
    "        \n",
    "        combined = tf.concat([x, tad_features], axis=-1)\n",
    "        output = self.structure_inject(combined)\n",
    "        \n",
    "        return output + x\n",
    "\n",
    "\n",
    "class DeformableAttention(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, num_points=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.num_points = num_points\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.sampling_offsets = layers.Dense(num_heads * num_points * 2)\n",
    "        self.attention_weights = layers.Dense(num_heads * num_points)\n",
    "        self.value_proj = layers.Dense(dim)\n",
    "        self.output_proj = layers.Dense(dim)\n",
    "    \n",
    "    def call(self, x):\n",
    "        B = tf.shape(x)[0]\n",
    "        N = tf.shape(x)[1]\n",
    "        C = self.dim\n",
    "        \n",
    "        value = self.value_proj(x)\n",
    "        value = tf.reshape(value, [B, N, self.num_heads, C // self.num_heads])\n",
    "        value = tf.transpose(value, [0, 2, 1, 3])\n",
    "        \n",
    "        attn = tf.matmul(value, value, transpose_b=True) / tf.sqrt(tf.cast(C // self.num_heads, tf.float32))\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        out = tf.matmul(attn, value)\n",
    "        \n",
    "        out = tf.transpose(out, [0, 2, 1, 3])\n",
    "        out = tf.reshape(out, [B, N, C])\n",
    "        \n",
    "        return self.output_proj(out)\n",
    "\n",
    "\n",
    "class SwinTransformerBlock(layers.Layer):\n",
    "    def __init__(self, dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.attn = DeformableAttention(dim, num_heads)\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        \n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(dim * 4),\n",
    "            layers.Activation('gelu'),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(dim),\n",
    "            layers.Dropout(0.1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        C = self.dim\n",
    "        \n",
    "        x_flat = tf.reshape(x, [B, H * W, C])\n",
    "        \n",
    "        x_flat = x_flat + self.attn(self.norm1(x_flat))\n",
    "        x_flat = x_flat + self.mlp(self.norm2(x_flat), training=training)\n",
    "        \n",
    "        return tf.reshape(x_flat, [B, H, W, C])\n",
    "\n",
    "\n",
    "class HybridCNNTransformer(layers.Layer):\n",
    "    def __init__(self, dim=128, depth=4, num_heads=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.cnn_blocks = []\n",
    "        for _ in range(depth // 2):\n",
    "            block = keras.Sequential([\n",
    "                layers.DepthwiseConv2D(3, padding='same'),\n",
    "                layers.Conv2D(dim, 1),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Activation('gelu')\n",
    "            ])\n",
    "            self.cnn_blocks.append(block)\n",
    "        \n",
    "        self.transformer_blocks = [\n",
    "            SwinTransformerBlock(dim, num_heads)\n",
    "            for _ in range(depth // 2)\n",
    "        ]\n",
    "        \n",
    "        self.channel_attn = keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(keepdims=True),\n",
    "            layers.Conv2D(dim // 8, 1),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(dim, 1),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        for cnn, transformer in zip(self.cnn_blocks, self.transformer_blocks):\n",
    "            x_cnn = cnn(x, training=training)\n",
    "            x_trans = transformer(x, training=training)\n",
    "            attn = self.channel_attn(x)\n",
    "            x = x_cnn * attn + x_trans * (1 - attn)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResolutionBranch(layers.Layer):\n",
    "    def __init__(self, in_channels, scale_factor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scale_factor = scale_factor\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        if scale_factor > 1:\n",
    "            # Upsampling decoder for scale > 1\n",
    "            self.decoder = keras.Sequential([\n",
    "                layers.Conv2D(in_channels * 2, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(in_channels * (scale_factor ** 2), 3, padding='same'),\n",
    "                layers.Lambda(lambda x: tf.nn.depth_to_space(x, scale_factor)),\n",
    "                layers.Conv2D(1, 3, padding='same')\n",
    "            ])\n",
    "        else:\n",
    "            # No upsampling for scale = 1 (same resolution)\n",
    "            self.decoder = keras.Sequential([\n",
    "                layers.Conv2D(in_channels * 2, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(in_channels, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(1, 3, padding='same')\n",
    "            ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        return self.decoder(x, training=training)\n",
    "\n",
    "\n",
    "class MultiResolutionProgressiveDecoder(layers.Layer):\n",
    "    def __init__(self, in_channels=128, scales=[4], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scales = scales\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.branches = {}\n",
    "        for s in scales:\n",
    "            self.branches[f'scale_{s}'] = ResolutionBranch(in_channels, s)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        if len(self.scales) == 1:\n",
    "            return self.branches[f'scale_{self.scales[0]}'](x, training=training)\n",
    "        return self.branches[f'scale_{self.scales[0]}'](x, training=training)\n",
    "\n",
    "\n",
    "class CellTypeAdapter(layers.Layer):\n",
    "    def __init__(self, feature_dim=128, num_cell_types=10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.cell_embedding = layers.Embedding(num_cell_types, feature_dim)\n",
    "        self.gamma_net = layers.Dense(feature_dim)\n",
    "        self.beta_net = layers.Dense(feature_dim)\n",
    "    \n",
    "    def call(self, x, cell_type_id=None):\n",
    "        if cell_type_id is not None:\n",
    "            B = tf.shape(x)[0]\n",
    "            C = self.feature_dim\n",
    "            \n",
    "            cell_emb = self.cell_embedding(cell_type_id)\n",
    "            gamma = self.gamma_net(cell_emb)\n",
    "            gamma = tf.reshape(gamma, [B, 1, 1, C])\n",
    "            beta = self.beta_net(cell_emb)\n",
    "            beta = tf.reshape(beta, [B, 1, 1, C])\n",
    "            \n",
    "            mean, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "            x_norm = (x - mean) / tf.sqrt(var + 1e-5)\n",
    "            \n",
    "            x_adapted = gamma * x_norm + beta\n",
    "        else:\n",
    "            x_adapted = x\n",
    "        \n",
    "        return x_adapted\n",
    "\n",
    "\n",
    "# ==================== MAIN MODEL ====================\n",
    "class HiCMEGA(Model):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.epigenomic_encoder = MultiModalEpigenomicEncoder(\n",
    "            hidden_dim=config['feature_dim'],\n",
    "            num_modalities=config['num_modalities']\n",
    "        )\n",
    "        \n",
    "        self.adaptive_blocks = [\n",
    "            AdaptiveMultiScaleDilatedBlock(config['feature_dim'])\n",
    "            for _ in range(2)  # Reduced from 3 for memory efficiency\n",
    "        ]\n",
    "        \n",
    "        self.graph_module = ChromatinStructureGraphModule(\n",
    "            feature_dim=config['feature_dim'],\n",
    "            num_gnn_layers=2  # Reduced from 3 for memory efficiency\n",
    "        )\n",
    "        \n",
    "        self.hybrid_core = HybridCNNTransformer(\n",
    "            dim=config['feature_dim'],\n",
    "            depth=config['depth'],\n",
    "            num_heads=config['num_heads']\n",
    "        )\n",
    "        \n",
    "        self.decoder = MultiResolutionProgressiveDecoder(\n",
    "            in_channels=config['feature_dim'],\n",
    "            scales=config['scales']\n",
    "        )\n",
    "        \n",
    "        self.cell_adapter = CellTypeAdapter(\n",
    "            feature_dim=config['feature_dim'],\n",
    "            num_cell_types=config['num_cell_types']\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        if isinstance(inputs, tuple):\n",
    "            x_hic = inputs[0]\n",
    "        else:\n",
    "            x_hic = inputs\n",
    "        \n",
    "        features = self.epigenomic_encoder(x_hic, training=training)\n",
    "        \n",
    "        for adaptive_block in self.adaptive_blocks:\n",
    "            features = adaptive_block(features, training=training)\n",
    "        \n",
    "        features = self.graph_module(features, training=training)\n",
    "        features = self.hybrid_core(features, training=training)\n",
    "        features = self.cell_adapter(features)\n",
    "        \n",
    "        outputs = self.decoder(features, training=training)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "# ==================== LOSS FUNCTIONS ====================\n",
    "class SSIMLoss(keras.losses.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        c1 = 0.01 ** 2\n",
    "        c2 = 0.03 ** 2\n",
    "        \n",
    "        mu_true = tf.nn.avg_pool2d(y_true, 3, 1, 'SAME')\n",
    "        mu_pred = tf.nn.avg_pool2d(y_pred, 3, 1, 'SAME')\n",
    "        \n",
    "        sigma_true = tf.nn.avg_pool2d(y_true ** 2, 3, 1, 'SAME') - mu_true ** 2\n",
    "        sigma_pred = tf.nn.avg_pool2d(y_pred ** 2, 3, 1, 'SAME') - mu_pred ** 2\n",
    "        sigma_pred_true = tf.nn.avg_pool2d(y_pred * y_true, 3, 1, 'SAME') - mu_pred * mu_true\n",
    "        \n",
    "        ssim = ((2 * mu_pred * mu_true + c1) * (2 * sigma_pred_true + c2)) / \\\n",
    "               ((mu_pred ** 2 + mu_true ** 2 + c1) * (sigma_pred + sigma_true + c2))\n",
    "        \n",
    "        return 1 - tf.reduce_mean(ssim)\n",
    "\n",
    "\n",
    "class HiCMEGALoss(keras.losses.Loss):\n",
    "    def __init__(self, lambda_rec=1.0, lambda_struct=0.3, lambda_bio=0.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lambda_rec = lambda_rec\n",
    "        self.lambda_struct = lambda_struct\n",
    "        self.lambda_bio = lambda_bio\n",
    "        self.ssim_loss = SSIMLoss()\n",
    "    \n",
    "    def reconstruction_loss(self, y_true, y_pred):\n",
    "        mse = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "        ssim = self.ssim_loss(y_true, y_pred)\n",
    "        return mse + 0.3 * ssim\n",
    "    \n",
    "    def structure_loss(self, y_true, y_pred):\n",
    "        window_size = 5\n",
    "        pred_insulation = tf.nn.avg_pool2d(y_pred, window_size, 1, 'SAME')\n",
    "        true_insulation = tf.nn.avg_pool2d(y_true, window_size, 1, 'SAME')\n",
    "        return tf.reduce_mean(tf.square(pred_insulation - true_insulation))\n",
    "    \n",
    "    def biological_loss(self, y_true, y_pred):\n",
    "        \"\"\"Calculate distance decay loss - simplified for tf.function compatibility\"\"\"\n",
    "        # Simplified version that works in graph mode\n",
    "        B = tf.shape(y_pred)[0]\n",
    "        H = tf.shape(y_pred)[1]\n",
    "        W = tf.shape(y_pred)[2]\n",
    "        \n",
    "        # Calculate mean contact frequency for different distances\n",
    "        # Use a fixed number of distances to avoid dynamic control flow\n",
    "        max_dist = 10  # Reduced for stability\n",
    "        \n",
    "        pred_decays = []\n",
    "        true_decays = []\n",
    "        \n",
    "        # Use tf.range and vectorized operations\n",
    "        for dist in range(max_dist):\n",
    "            # Shift matrices diagonally\n",
    "            if dist == 0:\n",
    "                pred_diag = y_pred\n",
    "                true_diag = y_true\n",
    "            else:\n",
    "                # Pad and shift\n",
    "                pred_diag = y_pred[:, dist:, :, :]\n",
    "                true_diag = y_true[:, dist:, :, :]\n",
    "            \n",
    "            # Calculate mean for this distance\n",
    "            pred_mean = tf.reduce_mean(pred_diag)\n",
    "            true_mean = tf.reduce_mean(true_diag)\n",
    "            \n",
    "            pred_decays.append(pred_mean)\n",
    "            true_decays.append(true_mean)\n",
    "        \n",
    "        # Stack and compute MSE\n",
    "        pred_decay_tensor = tf.stack(pred_decays)\n",
    "        true_decay_tensor = tf.stack(true_decays)\n",
    "        \n",
    "        return tf.reduce_mean(tf.square(pred_decay_tensor - true_decay_tensor))\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        loss_rec = self.reconstruction_loss(y_true, y_pred)\n",
    "        loss_struct = self.structure_loss(y_true, y_pred)\n",
    "        loss_bio = self.biological_loss(y_true, y_pred)\n",
    "        \n",
    "        total_loss = (self.lambda_rec * loss_rec + \n",
    "                     self.lambda_struct * loss_struct + \n",
    "                     self.lambda_bio * loss_bio)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "# ==================== TRAINING ====================\n",
    "class HiCMEGATrainer:\n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        \n",
    "        self.loss_fn = HiCMEGALoss(lambda_rec=1.0, lambda_struct=0.3, lambda_bio=0.2)\n",
    "        \n",
    "        # Try AdamW first, fallback to Adam if not available\n",
    "        try:\n",
    "            self.optimizer = keras.optimizers.AdamW(\n",
    "                learning_rate=config['learning_rate'],\n",
    "                weight_decay=1e-5\n",
    "            )\n",
    "        except AttributeError:\n",
    "            # Fallback for older TensorFlow versions\n",
    "            self.optimizer = keras.optimizers.Adam(\n",
    "                learning_rate=config['learning_rate']\n",
    "            )\n",
    "            print(\"âš  AdamW not available, using Adam optimizer\")\n",
    "        \n",
    "        self.train_loss_metric = keras.metrics.Mean(name='train_loss')\n",
    "        self.val_loss_metric = keras.metrics.Mean(name='val_loss')\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': []\n",
    "        }\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.model(lr, training=True)\n",
    "            loss = self.loss_fn(hr, pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        \n",
    "        self.train_loss_metric.update_state(loss)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def val_step(self, lr, hr):\n",
    "        pred = self.model(lr, training=False)\n",
    "        loss = self.loss_fn(hr, pred)\n",
    "        self.val_loss_metric.update_state(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_epoch(self, train_dataset, epoch):\n",
    "        self.train_loss_metric.reset_states()\n",
    "        \n",
    "        pbar = tqdm(train_dataset, desc=f'Epoch {epoch}')\n",
    "        for lr, hr in pbar:\n",
    "            loss = self.train_step(lr, hr)\n",
    "            pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "        \n",
    "        return self.train_loss_metric.result().numpy()\n",
    "    \n",
    "    def validate(self, val_dataset):\n",
    "        self.val_loss_metric.reset_states()\n",
    "        \n",
    "        for lr, hr in tqdm(val_dataset, desc='Validation'):\n",
    "            self.val_step(lr, hr)\n",
    "        \n",
    "        return self.val_loss_metric.result().numpy()\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset, num_epochs):\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"Starting Training\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            train_loss = self.train_epoch(train_dataset, epoch)\n",
    "            val_loss = self.validate(val_dataset)\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            \n",
    "            print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.model.save_weights('hic_mega_best.h5')\n",
    "                print(f\"âœ“ Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                self.visualize_predictions(val_dataset, epoch)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"Training Complete!\")\n",
    "        print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def visualize_predictions(self, dataset, epoch):\n",
    "        batch = next(iter(dataset))\n",
    "        lr, hr = batch\n",
    "        lr = lr[:4]\n",
    "        hr = hr[:4]\n",
    "        \n",
    "        pred = self.model(lr, training=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "        \n",
    "        for i in range(4):\n",
    "            axes[i, 0].imshow(lr[i, :, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\n",
    "            axes[i, 0].set_title('Low Resolution (40kb)')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(pred[i, :, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\n",
    "            axes[i, 1].set_title('HiC-MEGA Prediction (10kb)')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(hr[i, :, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\n",
    "            axes[i, 2].set_title('Ground Truth (10kb)')\n",
    "            axes[i, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'predictions_epoch_{epoch}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"âœ“ Predictions saved to predictions_epoch_{epoch}.png\")\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Training history saved to {save_path}\")\n",
    "\n",
    "\n",
    "# ==================== MAIN TRAINING FUNCTION ====================\n",
    "def train_model():\n",
    "    print(\"=\"*70)\n",
    "    print(\"HiC-MEGA: Multi-modal Epigenomic Graph-Aware Transformer\")\n",
    "    print(\"TensorFlow Implementation - Jupyter Notebook Version\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Feature Dimension: {CONFIG['feature_dim']}\")\n",
    "    print(f\"Enhancement Scale: {CONFIG['scales'][0]}x (40kb -> 10kb)\")\n",
    "    print(f\"Batch Size: {CONFIG['batch_size']}\")\n",
    "    print(f\"Learning Rate: {CONFIG['learning_rate']}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"\\n[1/5] Loading datasets...\")\n",
    "    train_data = HiCDataset(CONFIG['train_npz'], batch_size=CONFIG['batch_size'])\n",
    "    valid_data = HiCDataset(CONFIG['valid_npz'], batch_size=CONFIG['batch_size'])\n",
    "    \n",
    "    train_dataset = train_data.get_dataset()\n",
    "    valid_dataset = valid_data.get_dataset()\n",
    "    \n",
    "    print(f\"âœ“ Training samples: {len(train_data)}\")\n",
    "    print(f\"âœ“ Validation samples: {len(valid_data)}\")\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n[2/5] Initializing HiC-MEGA model...\")\n",
    "    model = HiCMEGA(CONFIG)\n",
    "    \n",
    "    # Build model\n",
    "    sample_input = tf.random.normal([1, 40, 40, 1])\n",
    "    _ = model(sample_input)\n",
    "    \n",
    "    total_params = model.count_params()\n",
    "    print(f\"âœ“ Total parameters: {total_params:,}\")\n",
    "    \n",
    "    # Create trainer\n",
    "    print(\"\\n[3/5] Setting up training...\")\n",
    "    trainer = HiCMEGATrainer(model, CONFIG)\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n[4/5] Starting training...\")\n",
    "    history = trainer.train(train_dataset, valid_dataset, CONFIG['num_epochs'])\n",
    "    \n",
    "    # Plot history\n",
    "    print(\"\\n[5/5] Generating training plots...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    print(\"\\nâœ“ Training completed successfully!\")\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# ==================== INFERENCE FUNCTION ====================\n",
    "def run_inference():\n",
    "    print(\"=\"*70)\n",
    "    print(\"HiC-MEGA Inference Mode\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nLoading model...\")\n",
    "    model = HiCMEGA(CONFIG)\n",
    "    sample_input = tf.random.normal([1, 40, 40, 1])\n",
    "    _ = model(sample_input)\n",
    "    model.load_weights(CONFIG['model_path'])\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "    \n",
    "    print(\"\\nLoading test data...\")\n",
    "    test_data = HiCDataset(CONFIG['test_npz'], batch_size=1)\n",
    "    test_dataset = test_data.get_dataset()\n",
    "    print(f\"âœ“ Test samples: {len(test_data)}\")\n",
    "    \n",
    "    os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "    \n",
    "    print(\"\\nRunning inference...\")\n",
    "    all_metrics = []\n",
    "    \n",
    "    for idx, (lr, hr) in enumerate(tqdm(test_dataset)):\n",
    "        pred = model(lr, training=False)\n",
    "        \n",
    "        mse = tf.reduce_mean(tf.square(pred - hr)).numpy()\n",
    "        corr = np.corrcoef(pred.numpy().flatten(), hr.numpy().flatten())[0, 1]\n",
    "        psnr = 10 * np.log10(1.0 / (mse + 1e-8))\n",
    "        \n",
    "        metrics = {'PSNR': psnr, 'Correlation': corr, 'MSE': mse}\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        np.save(\n",
    "            os.path.join(CONFIG['output_dir'], f'pred_{idx}.npy'),\n",
    "            pred[0, :, :, 0].numpy()\n",
    "        )\n",
    "    \n",
    "    avg_metrics = {k: np.mean([m[k] for m in all_metrics]) for k in all_metrics[0].keys()}\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Average Metrics:\")\n",
    "    for key, value in avg_metrics.items():\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "def main():\n",
    "    \"\"\"Main function - modify CONFIG at the top to change settings\"\"\"\n",
    "    \n",
    "    if CONFIG['mode'] == 'train':\n",
    "        model, history = train_model()\n",
    "        return model, history\n",
    "    elif CONFIG['mode'] == 'inference':\n",
    "        metrics = run_inference()\n",
    "        return metrics\n",
    "    else:\n",
    "        print(f\"Error: Unknown mode '{CONFIG['mode']}'. Use 'train' or 'inference'\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ==================== RUN ====================\n",
    "if __name__ == '__main__':\n",
    "    # For Jupyter, just call main() directly\n",
    "    print(\"\\nðŸš€ Starting HiC-MEGA...\")\n",
    "    print(\"ðŸ’¡ Tip: Modify the CONFIG dictionary at the top to change settings\\n\")\n",
    "    \n",
    "    result = main()\n",
    "    \n",
    "    print(\"\\nâœ… Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2333df-4dd5-48ec-84b9-1e254b3bd5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a73212-d76e-461e-adc5-b254a9a6b088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8c265c-7e1a-4afa-8c47-ce1426f67c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\proly kumar\\appdata\\local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\proly kumar\\appdata\\local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Collecting networkx>=2.8 (from scikit-image)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\proly kumar\\appdata\\local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages (from scikit-image) (11.3.0)\n",
      "Collecting imageio>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\proly kumar\\appdata\\local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.9 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.1/12.9 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.9/12.9 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.9 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 8.2 MB/s  0:00:01\n",
      "Downloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 8.1 MB/s  0:00:00\n",
      "Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy-loader, imageio, scikit-image\n",
      "\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [lazy-loader]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   ---------------------------------------- 5/5 [scikit-image]\n",
      "\n",
      "Successfully installed imageio-2.37.2 lazy-loader-0.4 networkx-3.2.1 scikit-image-0.24.0 tifffile-2024.8.30\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717572d5-a1c2-451e-9555-ea75f1416376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HiC-MEGA: Multi-modal Epigenomic Graph-Aware Transformer\n",
      "================================================================================\n",
      "Configuration:\n",
      "  - Downsampling Ratio: 1/16\n",
      "  - Feature Dimension: 64\n",
      "  - Batch Size: 4\n",
      "  - Learning Rate: 0.0001\n",
      "  - Num Epochs: 50\n",
      "================================================================================\n",
      "\n",
      "Setting up GPU...\n",
      "âœ“ Using 1 GPU(s)\n",
      "\n",
      "ðŸš€ Starting HiC-MEGA...\n",
      "ðŸ’¡ Modify CONFIG dictionary to change settings\n",
      "\n",
      "================================================================================\n",
      "HiC-MEGA Training - GM12878 Dataset\n",
      "================================================================================\n",
      "Feature Dimension: 64\n",
      "Downsampling Ratio: 1/16\n",
      "Batch Size: 4\n",
      "Learning Rate: 0.0001\n",
      "================================================================================\n",
      "\n",
      "[1/5] Loading datasets...\n",
      "Loading dataset from hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz...\n",
      "âœ“ Dataset loaded: 42832 samples\n",
      "  LR shape: (42832, 1, 40, 40), HR shape: (42832, 1, 40, 40)\n",
      "  Downsampling ratio: 1/16\n",
      "Loading dataset from hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz...\n",
      "âœ“ Dataset loaded: 18063 samples\n",
      "  LR shape: (18063, 1, 40, 40), HR shape: (18063, 1, 40, 40)\n",
      "  Downsampling ratio: 1/16\n",
      "  Applying 1/16 downsampling to LR data...\n",
      "  LR data shape after downsampling: (42832, 2, 2, 1)\n",
      "  Detected scale factor: 20x (LR: 2x2 -> HR: 40x40)\n",
      "  âš  Updating CONFIG['scales'] from [4] to [20]\n",
      "  Applying 1/16 downsampling to LR data...\n",
      "  LR data shape after downsampling: (18063, 2, 2, 1)\n",
      "  Detected scale factor: 20x (LR: 2x2 -> HR: 40x40)\n",
      "âœ“ Training samples: 42832\n",
      "âœ“ Validation samples: 18063\n",
      "\n",
      "[2/5] Initializing HiC-MEGA model...\n",
      "âœ“ Total parameters: 29,961,777\n",
      "\n",
      "[3/5] Setting up training...\n",
      "âš  AdamW not available, using Adam optimizer\n",
      "\n",
      "[4/5] Starting training...\n",
      "\n",
      "================================================================================\n",
      "Starting Training\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:06<00:00, 12.65it/s, loss=0.2091]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:51<00:00, 88.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2586\n",
      "Val Loss: 0.2854\n",
      "Val SSIM: 0.2162\n",
      "Val Pearson: 0.5003\n",
      "âœ“ Best model saved! (Val Loss: 0.2854)\n",
      "\n",
      "Epoch 2/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [13:23<00:00, 13.32it/s, loss=0.2063]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:51<00:00, 88.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2512\n",
      "Val Loss: 0.2845\n",
      "Val SSIM: 0.2168\n",
      "Val Pearson: 0.4999\n",
      "âœ“ Best model saved! (Val Loss: 0.2845)\n",
      "\n",
      "Epoch 3/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [13:06<00:00, 13.61it/s, loss=0.2033]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:50<00:00, 89.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2503\n",
      "Val Loss: 0.2810\n",
      "Val SSIM: 0.2150\n",
      "Val Pearson: 0.5025\n",
      "âœ“ Best model saved! (Val Loss: 0.2810)\n",
      "\n",
      "Epoch 4/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:22<00:00, 12.42it/s, loss=0.2052]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:43<00:00, 104.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2494\n",
      "Val Loss: 0.2796\n",
      "Val SSIM: 0.2164\n",
      "Val Pearson: 0.5005\n",
      "âœ“ Best model saved! (Val Loss: 0.2796)\n",
      "\n",
      "Epoch 5/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:52<00:00, 11.99it/s, loss=0.2049]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:42<00:00, 106.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2484\n",
      "Val Loss: 0.2837\n",
      "Val SSIM: 0.2118\n",
      "Val Pearson: 0.4955\n",
      "\n",
      "Epoch 6/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:48<00:00, 12.05it/s, loss=0.2072]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:42<00:00, 106.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2472\n",
      "Val Loss: 0.2790\n",
      "Val SSIM: 0.2107\n",
      "Val Pearson: 0.4959\n",
      "âœ“ Best model saved! (Val Loss: 0.2790)\n",
      "\n",
      "Epoch 7/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:47<00:00, 12.07it/s, loss=0.2084]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:42<00:00, 106.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2459\n",
      "Val Loss: 0.2833\n",
      "Val SSIM: 0.2146\n",
      "Val Pearson: 0.4933\n",
      "\n",
      "Epoch 8/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   5%|â–ˆâ–ˆâ–‰                                                     | 570/10708 [00:46<14:32, 11.63it/s, loss=0.1366]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 12:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 4644/10708 [06:25<08:53, 11.37it/s, loss=0.2776]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 16:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10396/10708 [14:20<00:26, 11.76it/s, loss=0.2037]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 21:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 5936/10708 [08:11<06:24, 12.40it/s, loss=0.2523]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 25:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 8964/10708 [12:20<02:22, 12.23it/s, loss=0.2080]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:49<00:00, 12.04it/s, loss=0.2111]\n",
      "Validation:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                    | 2002/4516 [00:19<00:24, 103.55it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:48<00:00, 12.05it/s, loss=0.2112]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:42<00:00, 105.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2206\n",
      "Val Loss: 0.2868\n",
      "Val SSIM: 0.1991\n",
      "Val Pearson: 0.4841\n",
      "\n",
      "Epoch 36/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                               | 1313/10708 [01:49<12:37, 12.41it/s, loss=0.1929]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:48<00:00, 12.05it/s, loss=0.2071]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:45<00:00, 100.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2184\n",
      "Val Loss: 0.2963\n",
      "Val SSIM: 0.1987\n",
      "Val Pearson: 0.4808\n",
      "âœ“ Predictions saved to outputs/predictions_epoch_40.png\n",
      "\n",
      "Epoch 41/50\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                               | 1316/10708 [01:49<13:03, 11.99it/s, loss=0.2434]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 46:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                        | 2782/10708 [03:53<10:44, 12.29it/s, loss=0.2131]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10708/10708 [14:47<00:00, 12.07it/s, loss=0.2436]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4516/4516 [00:42<00:00, 105.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2146\n",
      "Val Loss: 0.2957\n",
      "Val SSIM: 0.1939\n",
      "Val Pearson: 0.4814\n",
      "âœ“ Predictions saved to outputs/predictions_epoch_50.png\n",
      "\n",
      "================================================================================\n",
      "Training Complete!\n",
      "Best Validation Loss: 0.2772\n",
      "================================================================================\n",
      "\n",
      "[5/5] Generating training plots...\n",
      "âœ“ Training history saved to outputs\\training_history.png\n",
      "\n",
      "âœ“ Training completed successfully!\n",
      "\n",
      "================================================================================\n",
      "âœ… Execution Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HiC-MEGA: Multi-modal Epigenomic Graph-Aware Transformer\n",
    "Complete Implementation with Comprehensive Metrics\n",
    "\n",
    "Includes:\n",
    "- SSIM (Structural Similarity Index)\n",
    "- GenomeDISCO (Genomic Distance-based Contact Similarity)\n",
    "- HiCRep (Hi-C Reproducibility Score)\n",
    "- Pearson Correlation\n",
    "- Spearman Correlation\n",
    "- MSE, PSNR\n",
    "- GM12878 evaluation with 1/16 downsampling\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from skimage.metrics import structural_similarity as ssim_metric\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "CONFIG = {\n",
    "    'mode': 'train',  # 'train' or 'inference'\n",
    "    'feature_dim': 64,\n",
    "    'num_modalities': 2,\n",
    "    'num_heads': 4,\n",
    "    'depth': 4,\n",
    "    'scales': [4],  # For 1/16 downsampling (4x4=16)\n",
    "    'num_cell_types': 50,\n",
    "    'batch_size': 4,\n",
    "    'num_epochs': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    \n",
    "    # Dataset paths - MODIFY THESE\n",
    "    'train_npz': \"hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz\",\n",
    "    'valid_npz': \"hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz\",\n",
    "    'test_npz': \"hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz\",\n",
    "    'model_path': \"hic_mega_best.h5\",\n",
    "    'output_dir': \"outputs\",\n",
    "    'metrics_file': \"evaluation_metrics.json\",\n",
    "    \n",
    "    # Downsampling ratio\n",
    "    'downsample_ratio': 16,  # 1/16 downsampling\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HiC-MEGA: Multi-modal Epigenomic Graph-Aware Transformer\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Downsampling Ratio: 1/{CONFIG['downsample_ratio']}\")\n",
    "print(f\"  - Feature Dimension: {CONFIG['feature_dim']}\")\n",
    "print(f\"  - Batch Size: {CONFIG['batch_size']}\")\n",
    "print(f\"  - Learning Rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  - Num Epochs: {CONFIG['num_epochs']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# GPU Setup\n",
    "print(\"\\nSetting up GPU...\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ“ Using {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"âš  No GPU found, using CPU\")\n",
    "\n",
    "\n",
    "# ==================== METRICS IMPLEMENTATION ====================\n",
    "class HiCMetrics:\n",
    "    \"\"\"Comprehensive Hi-C quality metrics\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_ssim(pred, true):\n",
    "        \"\"\"Calculate SSIM (Structural Similarity Index)\"\"\"\n",
    "        pred_np = pred.numpy() if isinstance(pred, tf.Tensor) else pred\n",
    "        true_np = true.numpy() if isinstance(true, tf.Tensor) else true\n",
    "        \n",
    "        # Calculate SSIM for each sample in batch\n",
    "        ssim_values = []\n",
    "        for i in range(pred_np.shape[0]):\n",
    "            pred_img = pred_np[i, :, :, 0]\n",
    "            true_img = true_np[i, :, :, 0]\n",
    "            \n",
    "            # Normalize to [0, 1] if needed\n",
    "            pred_img = (pred_img - pred_img.min()) / (pred_img.max() - pred_img.min() + 1e-8)\n",
    "            true_img = (true_img - true_img.min()) / (true_img.max() - true_img.min() + 1e-8)\n",
    "            \n",
    "            ssim_val = ssim_metric(true_img, pred_img, data_range=1.0)\n",
    "            ssim_values.append(ssim_val)\n",
    "        \n",
    "        return np.mean(ssim_values)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_genome_disco(pred, true, max_dist=None):\n",
    "        \"\"\"\n",
    "        Calculate GenomeDISCO (Genomic Distance-based Contact Similarity)\n",
    "        \n",
    "        GenomeDISCO measures concordance of contact patterns at different genomic distances\n",
    "        by comparing the distribution of contacts as a function of genomic distance.\n",
    "        \"\"\"\n",
    "        pred_np = pred.numpy() if isinstance(pred, tf.Tensor) else pred\n",
    "        true_np = true.numpy() if isinstance(true, tf.Tensor) else true\n",
    "        \n",
    "        disco_scores = []\n",
    "        \n",
    "        for i in range(pred_np.shape[0]):\n",
    "            pred_mat = pred_np[i, :, :, 0]\n",
    "            true_mat = true_np[i, :, :, 0]\n",
    "            \n",
    "            n = pred_mat.shape[0]\n",
    "            if max_dist is None:\n",
    "                max_dist = n // 2\n",
    "            \n",
    "            # Calculate distance-stratified concordance\n",
    "            concordances = []\n",
    "            \n",
    "            for dist in range(1, min(max_dist, n)):\n",
    "                # Extract diagonal at distance 'dist'\n",
    "                pred_diag = np.diagonal(pred_mat, offset=dist)\n",
    "                true_diag = np.diagonal(true_mat, offset=dist)\n",
    "                \n",
    "                if len(pred_diag) > 1:\n",
    "                    # Calculate correlation for this distance\n",
    "                    if np.std(pred_diag) > 0 and np.std(true_diag) > 0:\n",
    "                        corr = np.corrcoef(pred_diag, true_diag)[0, 1]\n",
    "                        if not np.isnan(corr):\n",
    "                            concordances.append(corr)\n",
    "            \n",
    "            # GenomeDISCO score is the average concordance across distances\n",
    "            if concordances:\n",
    "                disco_score = np.mean(concordances)\n",
    "                disco_scores.append(disco_score)\n",
    "        \n",
    "        return np.mean(disco_scores) if disco_scores else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_hicrep(pred, true, h=1, max_dist=None):\n",
    "        \"\"\"\n",
    "        Calculate HiCRep (Hi-C Reproducibility Score)\n",
    "        \n",
    "        HiCRep uses a stratum-adjusted correlation coefficient (SCC) to measure\n",
    "        the reproducibility of Hi-C data by accounting for distance-dependent decay.\n",
    "        \n",
    "        Args:\n",
    "            pred: Predicted contact matrix\n",
    "            true: True contact matrix\n",
    "            h: Smoothing parameter (bandwidth)\n",
    "            max_dist: Maximum genomic distance to consider\n",
    "        \"\"\"\n",
    "        pred_np = pred.numpy() if isinstance(pred, tf.Tensor) else pred\n",
    "        true_np = true.numpy() if isinstance(true, tf.Tensor) else true\n",
    "        \n",
    "        hicrep_scores = []\n",
    "        \n",
    "        for i in range(pred_np.shape[0]):\n",
    "            pred_mat = pred_np[i, :, :, 0]\n",
    "            true_mat = true_np[i, :, :, 0]\n",
    "            \n",
    "            n = pred_mat.shape[0]\n",
    "            if max_dist is None:\n",
    "                max_dist = n // 2\n",
    "            \n",
    "            # Smooth matrices if h > 0\n",
    "            if h > 0:\n",
    "                pred_smooth = HiCMetrics._smooth_matrix(pred_mat, h)\n",
    "                true_smooth = HiCMetrics._smooth_matrix(true_mat, h)\n",
    "            else:\n",
    "                pred_smooth = pred_mat\n",
    "                true_smooth = true_mat\n",
    "            \n",
    "            # Calculate stratum-adjusted correlation coefficient (SCC)\n",
    "            weighted_corrs = []\n",
    "            weights = []\n",
    "            \n",
    "            for dist in range(max_dist):\n",
    "                # Extract diagonal\n",
    "                pred_diag = np.diagonal(pred_smooth, offset=dist)\n",
    "                true_diag = np.diagonal(true_smooth, offset=dist)\n",
    "                \n",
    "                if len(pred_diag) > 1:\n",
    "                    # Normalize by distance-specific mean\n",
    "                    pred_norm = pred_diag - np.mean(pred_diag)\n",
    "                    true_norm = true_diag - np.mean(true_diag)\n",
    "                    \n",
    "                    # Calculate correlation\n",
    "                    if np.std(pred_norm) > 0 and np.std(true_norm) > 0:\n",
    "                        corr = np.corrcoef(pred_norm, true_norm)[0, 1]\n",
    "                        if not np.isnan(corr):\n",
    "                            weighted_corrs.append(corr)\n",
    "                            weights.append(len(pred_diag))  # Weight by number of pairs\n",
    "            \n",
    "            # Weighted average of correlations (SCC)\n",
    "            if weighted_corrs:\n",
    "                weights = np.array(weights)\n",
    "                weights = weights / np.sum(weights)\n",
    "                scc = np.sum(np.array(weighted_corrs) * weights)\n",
    "                hicrep_scores.append(scc)\n",
    "        \n",
    "        return np.mean(hicrep_scores) if hicrep_scores else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def _smooth_matrix(mat, h):\n",
    "        \"\"\"Smooth Hi-C matrix using mean filter\"\"\"\n",
    "        from scipy.ndimage import uniform_filter\n",
    "        return uniform_filter(mat, size=2*h+1, mode='constant')\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_pearson(pred, true):\n",
    "        \"\"\"Calculate Pearson correlation\"\"\"\n",
    "        pred_flat = pred.numpy().flatten() if isinstance(pred, tf.Tensor) else pred.flatten()\n",
    "        true_flat = true.numpy().flatten() if isinstance(true, tf.Tensor) else true.flatten()\n",
    "        \n",
    "        corr, _ = stats.pearsonr(pred_flat, true_flat)\n",
    "        return corr\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_spearman(pred, true):\n",
    "        \"\"\"Calculate Spearman correlation\"\"\"\n",
    "        pred_flat = pred.numpy().flatten() if isinstance(pred, tf.Tensor) else pred.flatten()\n",
    "        true_flat = true.numpy().flatten() if isinstance(true, tf.Tensor) else true.flatten()\n",
    "        \n",
    "        corr, _ = stats.spearmanr(pred_flat, true_flat)\n",
    "        return corr\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_mse(pred, true):\n",
    "        \"\"\"Calculate Mean Squared Error\"\"\"\n",
    "        mse = tf.reduce_mean(tf.square(pred - true))\n",
    "        return mse.numpy() if isinstance(mse, tf.Tensor) else mse\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_psnr(pred, true, max_val=1.0):\n",
    "        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
    "        mse = HiCMetrics.calculate_mse(pred, true)\n",
    "        if mse == 0:\n",
    "            return float('inf')\n",
    "        psnr = 10 * np.log10(max_val**2 / mse)\n",
    "        return psnr\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(pred, true):\n",
    "        \"\"\"Calculate all metrics at once\"\"\"\n",
    "        metrics = {\n",
    "            'SSIM': HiCMetrics.calculate_ssim(pred, true),\n",
    "            'GenomeDISCO': HiCMetrics.calculate_genome_disco(pred, true),\n",
    "            'HiCRep': HiCMetrics.calculate_hicrep(pred, true),\n",
    "            'Pearson': HiCMetrics.calculate_pearson(pred, true),\n",
    "            'Spearman': HiCMetrics.calculate_spearman(pred, true),\n",
    "            'MSE': HiCMetrics.calculate_mse(pred, true),\n",
    "            'PSNR': HiCMetrics.calculate_psnr(pred, true),\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "\n",
    "# ==================== DATASET ====================\n",
    "class HiCDataset:\n",
    "    \"\"\"Dataset loader for NPZ format Hi-C data with downsampling support\"\"\"\n",
    "    \n",
    "    def __init__(self, npz_path, batch_size=8, downsample_ratio=16):\n",
    "        print(f\"Loading dataset from {npz_path}...\")\n",
    "        data = np.load(npz_path)\n",
    "        \n",
    "        self.lr_data = data['data'].astype(np.float32)\n",
    "        self.hr_data = data['target'].astype(np.float32) if 'target' in data else data['data'].astype(np.float32)\n",
    "        self.batch_size = batch_size\n",
    "        self.downsample_ratio = downsample_ratio\n",
    "        \n",
    "        print(f\"âœ“ Dataset loaded: {len(self.lr_data)} samples\")\n",
    "        print(f\"  LR shape: {self.lr_data.shape}, HR shape: {self.hr_data.shape}\")\n",
    "        print(f\"  Downsampling ratio: 1/{downsample_ratio}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lr_data)\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        \"\"\"Normalize to [0, 1] range\"\"\"\n",
    "        data_min = np.min(data, axis=(1, 2, 3), keepdims=True)\n",
    "        data_max = np.max(data, axis=(1, 2, 3), keepdims=True)\n",
    "        return (data - data_min) / (data_max - data_min + 1e-8)\n",
    "    \n",
    "    def apply_downsampling(self, data, ratio):\n",
    "        \"\"\"Apply downsampling to simulate low-resolution data\"\"\"\n",
    "        if ratio == 1:\n",
    "            return data\n",
    "        \n",
    "        # Downsample by averaging\n",
    "        n_samples = data.shape[0]\n",
    "        h, w = data.shape[1], data.shape[2]\n",
    "        c = data.shape[3] if data.ndim == 4 else 1\n",
    "        \n",
    "        # Calculate new dimensions\n",
    "        new_h = h // ratio\n",
    "        new_w = w // ratio\n",
    "        \n",
    "        downsampled = np.zeros((n_samples, new_h, new_w, c), dtype=np.float32)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            for ch in range(c):\n",
    "                img = data[i, :, :, ch] if data.ndim == 4 else data[i, :, :]\n",
    "                # Average pooling\n",
    "                for y in range(new_h):\n",
    "                    for x in range(new_w):\n",
    "                        downsampled[i, y, x, ch] = np.mean(\n",
    "                            img[y*ratio:(y+1)*ratio, x*ratio:(x+1)*ratio]\n",
    "                        )\n",
    "        \n",
    "        return downsampled\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        # Convert to NHWC format\n",
    "        if self.lr_data.ndim == 3:\n",
    "            lr_data = self.lr_data[:, :, :, np.newaxis]\n",
    "        else:\n",
    "            lr_data = np.transpose(self.lr_data, (0, 2, 3, 1))\n",
    "        \n",
    "        if self.hr_data.ndim == 3:\n",
    "            hr_data = self.hr_data[:, :, :, np.newaxis]\n",
    "        else:\n",
    "            hr_data = np.transpose(self.hr_data, (0, 2, 3, 1))\n",
    "        \n",
    "        # Apply downsampling to LR data if needed\n",
    "        if self.downsample_ratio > 1:\n",
    "            print(f\"  Applying 1/{self.downsample_ratio} downsampling to LR data...\")\n",
    "            lr_data = self.apply_downsampling(hr_data, self.downsample_ratio)\n",
    "            print(f\"  LR data shape after downsampling: {lr_data.shape}\")\n",
    "        \n",
    "        # Detect scale factor\n",
    "        lr_h, lr_w = lr_data.shape[1], lr_data.shape[2]\n",
    "        hr_h, hr_w = hr_data.shape[1], hr_data.shape[2]\n",
    "        scale_h = hr_h // lr_h if hr_h >= lr_h else 1\n",
    "        scale_w = hr_w // lr_w if hr_w >= lr_w else 1\n",
    "        detected_scale = max(scale_h, scale_w)\n",
    "        \n",
    "        print(f\"  Detected scale factor: {detected_scale}x (LR: {lr_h}x{lr_w} -> HR: {hr_h}x{hr_w})\")\n",
    "        \n",
    "        # Update CONFIG if needed\n",
    "        if detected_scale != CONFIG['scales'][0]:\n",
    "            print(f\"  âš  Updating CONFIG['scales'] from {CONFIG['scales']} to [{detected_scale}]\")\n",
    "            CONFIG['scales'] = [detected_scale]\n",
    "        \n",
    "        # Normalize\n",
    "        lr_data = self.normalize(lr_data)\n",
    "        hr_data = self.normalize(hr_data)\n",
    "        \n",
    "        # Create TF dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((lr_data, hr_data))\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "\n",
    "# ==================== MODEL COMPONENTS ====================\n",
    "class CrossModalAttention(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.dim = dim\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        \n",
    "        self.q = layers.Dense(dim)\n",
    "        self.kv = layers.Dense(dim * 2)\n",
    "        self.proj = layers.Dense(dim)\n",
    "    \n",
    "    def call(self, x, context):\n",
    "        B = tf.shape(x)[0]\n",
    "        N = tf.shape(x)[1]\n",
    "        C = self.dim\n",
    "        \n",
    "        q = self.q(x)\n",
    "        q = tf.reshape(q, [B, N, self.num_heads, C // self.num_heads])\n",
    "        q = tf.transpose(q, [0, 2, 1, 3])\n",
    "        \n",
    "        kv = self.kv(context)\n",
    "        kv = tf.reshape(kv, [B, -1, 2, self.num_heads, C // self.num_heads])\n",
    "        kv = tf.transpose(kv, [2, 0, 3, 1, 4])\n",
    "        k, v = kv[0], kv[1]\n",
    "        \n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        \n",
    "        out = tf.matmul(attn, v)\n",
    "        out = tf.transpose(out, [0, 2, 1, 3])\n",
    "        out = tf.reshape(out, [B, N, C])\n",
    "        \n",
    "        return self.proj(out)\n",
    "\n",
    "\n",
    "class MultiModalEpigenomicEncoder(layers.Layer):\n",
    "    def __init__(self, hidden_dim=128, num_modalities=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_modalities = num_modalities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.modality_encoders = []\n",
    "        for _ in range(num_modalities):\n",
    "            encoder = keras.Sequential([\n",
    "                layers.Conv2D(hidden_dim // 2, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(hidden_dim, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU()\n",
    "            ])\n",
    "            self.modality_encoders.append(encoder)\n",
    "        \n",
    "        self.cross_modal_attn = CrossModalAttention(hidden_dim)\n",
    "        \n",
    "        self.imputation_net = keras.Sequential([\n",
    "            layers.Dense(hidden_dim * 2),\n",
    "            layers.ReLU(),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(hidden_dim)\n",
    "        ])\n",
    "        \n",
    "        self.fusion_conv = layers.Conv2D(hidden_dim, 1)\n",
    "    \n",
    "    def call(self, x_hic, training=False):\n",
    "        B = tf.shape(x_hic)[0]\n",
    "        H = tf.shape(x_hic)[1]\n",
    "        W = tf.shape(x_hic)[2]\n",
    "        \n",
    "        modality_features = []\n",
    "        \n",
    "        for encoder in self.modality_encoders:\n",
    "            feat = encoder(x_hic, training=training)\n",
    "            feat_shape = tf.shape(feat)\n",
    "            feat_flat = tf.reshape(feat, [B, H * W, self.hidden_dim])\n",
    "            feat_imputed = self.imputation_net(feat_flat, training=training)\n",
    "            feat = tf.reshape(feat_imputed, feat_shape)\n",
    "            modality_features.append(feat)\n",
    "        \n",
    "        weighted_features = []\n",
    "        for i, feat in enumerate(modality_features):\n",
    "            feat_flat = tf.reshape(feat, [B, H * W, self.hidden_dim])\n",
    "            \n",
    "            if i == 0 and len(modality_features) > 1:\n",
    "                other_flat = tf.reshape(modality_features[1], [B, H * W, self.hidden_dim])\n",
    "                feat_flat = feat_flat + self.cross_modal_attn(feat_flat, other_flat)\n",
    "            \n",
    "            feat_attended = tf.reshape(feat_flat, [B, H, W, self.hidden_dim])\n",
    "            weighted_features.append(feat_attended)\n",
    "        \n",
    "        fused = tf.concat(weighted_features, axis=-1)\n",
    "        output = self.fusion_conv(fused)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class AdaptiveDilationPredictor(layers.Layer):\n",
    "    def __init__(self, in_channels, num_scales=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_scales = num_scales\n",
    "        \n",
    "        self.predictor = keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(64),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(num_scales),\n",
    "            layers.Softmax()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.predictor(x)\n",
    "\n",
    "\n",
    "class AdaptiveMultiScaleDilatedBlock(layers.Layer):\n",
    "    def __init__(self, channels, dilation_rates=[1, 2, 4, 8], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dilation_rates = dilation_rates\n",
    "        self.num_scales = len(dilation_rates)\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.dilated_convs = []\n",
    "        for rate in dilation_rates:\n",
    "            conv_block = keras.Sequential([\n",
    "                layers.DepthwiseConv2D(3, padding='same', dilation_rate=rate),\n",
    "                layers.Conv2D(channels, 1),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU()\n",
    "            ])\n",
    "            self.dilated_convs.append(conv_block)\n",
    "        \n",
    "        self.dilation_predictor = AdaptiveDilationPredictor(channels, self.num_scales)\n",
    "        \n",
    "        self.scale_aggregation = keras.Sequential([\n",
    "            layers.Conv2D(channels * 2, 1),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(channels, 1),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        dilation_weights = self.dilation_predictor(x)\n",
    "        \n",
    "        multi_scale_features = []\n",
    "        for i, conv in enumerate(self.dilated_convs):\n",
    "            feat = conv(x, training=training)\n",
    "            weight = tf.reshape(dilation_weights[:, i], [-1, 1, 1, 1])\n",
    "            weighted_feat = feat * weight\n",
    "            multi_scale_features.append(weighted_feat)\n",
    "        \n",
    "        concat_features = tf.concat(multi_scale_features, axis=-1)\n",
    "        aggregated = self.scale_aggregation(concat_features, training=training)\n",
    "        \n",
    "        return tf.nn.relu(aggregated + x)\n",
    "\n",
    "\n",
    "class ChromatinGraphConv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(\n",
    "            shape=(self.in_channels, self.out_channels),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='weight'\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.out_channels,),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='bias'\n",
    "        )\n",
    "    \n",
    "    def call(self, x, adj):\n",
    "        support = tf.matmul(x, self.weight)\n",
    "        output = tf.matmul(adj, support) + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class ChromatinStructureGraphModule(layers.Layer):\n",
    "    def __init__(self, feature_dim=128, num_gnn_layers=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_layers = num_gnn_layers\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.graph_constructor = keras.Sequential([\n",
    "            layers.Dense(feature_dim),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(feature_dim)\n",
    "        ])\n",
    "        \n",
    "        self.gnn_layers = [\n",
    "            ChromatinGraphConv(feature_dim, feature_dim)\n",
    "            for _ in range(num_gnn_layers)\n",
    "        ]\n",
    "        \n",
    "        self.layer_norms = [\n",
    "            layers.LayerNormalization() for _ in range(num_gnn_layers)\n",
    "        ]\n",
    "        \n",
    "        self.tad_pooling = keras.Sequential([\n",
    "            layers.Conv2D(feature_dim // 2, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(feature_dim, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        \n",
    "        self.structure_inject = layers.Conv2D(feature_dim, 1)\n",
    "    \n",
    "    def construct_adjacency(self, x):\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        C = self.feature_dim\n",
    "        \n",
    "        x_flat = tf.reshape(x, [B, H * W, C])\n",
    "        node_features = self.graph_constructor(x_flat)\n",
    "        \n",
    "        adj = tf.matmul(node_features, node_features, transpose_b=True)\n",
    "        adj = tf.nn.softmax(adj / tf.sqrt(tf.cast(C, tf.float32)), axis=-1)\n",
    "        \n",
    "        return adj, x_flat\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        \n",
    "        adj, node_features = self.construct_adjacency(x)\n",
    "        \n",
    "        for gnn, norm in zip(self.gnn_layers, self.layer_norms):\n",
    "            node_features = gnn(node_features, adj)\n",
    "            node_features = norm(node_features)\n",
    "            node_features = tf.nn.relu(node_features)\n",
    "        \n",
    "        graph_features = tf.reshape(node_features, [B, H, W, self.feature_dim])\n",
    "        \n",
    "        tad_features = self.tad_pooling(graph_features, training=training)\n",
    "        tad_features = tf.image.resize(tad_features, [H, W], method='bilinear')\n",
    "        \n",
    "        combined = tf.concat([x, tad_features], axis=-1)\n",
    "        output = self.structure_inject(combined)\n",
    "        \n",
    "        return output + x\n",
    "\n",
    "\n",
    "class DeformableAttention(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, num_points=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.num_points = num_points\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.sampling_offsets = layers.Dense(num_heads * num_points * 2)\n",
    "        self.attention_weights = layers.Dense(num_heads * num_points)\n",
    "        self.value_proj = layers.Dense(dim)\n",
    "        self.output_proj = layers.Dense(dim)\n",
    "    \n",
    "    def call(self, x):\n",
    "        B = tf.shape(x)[0]\n",
    "        N = tf.shape(x)[1]\n",
    "        C = self.dim\n",
    "        \n",
    "        value = self.value_proj(x)\n",
    "        value = tf.reshape(value, [B, N, self.num_heads, C // self.num_heads])\n",
    "        value = tf.transpose(value, [0, 2, 1, 3])\n",
    "        \n",
    "        attn = tf.matmul(value, value, transpose_b=True) / tf.sqrt(tf.cast(C // self.num_heads, tf.float32))\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        out = tf.matmul(attn, value)\n",
    "        \n",
    "        out = tf.transpose(out, [0, 2, 1, 3])\n",
    "        out = tf.reshape(out, [B, N, C])\n",
    "        \n",
    "        return self.output_proj(out)\n",
    "\n",
    "\n",
    "class SwinTransformerBlock(layers.Layer):\n",
    "    def __init__(self, dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.attn = DeformableAttention(dim, num_heads)\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "        \n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(dim * 4),\n",
    "            layers.Activation('gelu'),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(dim),\n",
    "            layers.Dropout(0.1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        C = self.dim\n",
    "        \n",
    "        x_flat = tf.reshape(x, [B, H * W, C])\n",
    "        \n",
    "        x_flat = x_flat + self.attn(self.norm1(x_flat))\n",
    "        x_flat = x_flat + self.mlp(self.norm2(x_flat), training=training)\n",
    "        \n",
    "        return tf.reshape(x_flat, [B, H, W, C])\n",
    "\n",
    "\n",
    "class HybridCNNTransformer(layers.Layer):\n",
    "    def __init__(self, dim=128, depth=4, num_heads=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.cnn_blocks = []\n",
    "        for _ in range(depth // 2):\n",
    "            block = keras.Sequential([\n",
    "                layers.DepthwiseConv2D(3, padding='same'),\n",
    "                layers.Conv2D(dim, 1),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Activation('gelu')\n",
    "            ])\n",
    "            self.cnn_blocks.append(block)\n",
    "        \n",
    "        self.transformer_blocks = [\n",
    "            SwinTransformerBlock(dim, num_heads)\n",
    "            for _ in range(depth // 2)\n",
    "        ]\n",
    "        \n",
    "        self.channel_attn = keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(keepdims=True),\n",
    "            layers.Conv2D(dim // 8, 1),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(dim, 1),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        for cnn, transformer in zip(self.cnn_blocks, self.transformer_blocks):\n",
    "            x_cnn = cnn(x, training=training)\n",
    "            x_trans = transformer(x, training=training)\n",
    "            attn = self.channel_attn(x)\n",
    "            x = x_cnn * attn + x_trans * (1 - attn)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResolutionBranch(layers.Layer):\n",
    "    def __init__(self, in_channels, scale_factor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scale_factor = scale_factor\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        if scale_factor > 1:\n",
    "            self.decoder = keras.Sequential([\n",
    "                layers.Conv2D(in_channels * 2, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(in_channels * (scale_factor ** 2), 3, padding='same'),\n",
    "                layers.Lambda(lambda x: tf.nn.depth_to_space(x, scale_factor)),\n",
    "                layers.Conv2D(1, 3, padding='same')\n",
    "            ])\n",
    "        else:\n",
    "            self.decoder = keras.Sequential([\n",
    "                layers.Conv2D(in_channels * 2, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(in_channels, 3, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU(),\n",
    "                layers.Conv2D(1, 3, padding='same')\n",
    "            ])\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        return self.decoder(x, training=training)\n",
    "\n",
    "\n",
    "class MultiResolutionProgressiveDecoder(layers.Layer):\n",
    "    def __init__(self, in_channels=128, scales=[4], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.scales = scales\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.branches = {}\n",
    "        for s in scales:\n",
    "            self.branches[f'scale_{s}'] = ResolutionBranch(in_channels, s)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        if len(self.scales) == 1:\n",
    "            return self.branches[f'scale_{self.scales[0]}'](x, training=training)\n",
    "        return self.branches[f'scale_{self.scales[0]}'](x, training=training)\n",
    "\n",
    "\n",
    "class CellTypeAdapter(layers.Layer):\n",
    "    def __init__(self, feature_dim=128, num_cell_types=10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.cell_embedding = layers.Embedding(num_cell_types, feature_dim)\n",
    "        self.gamma_net = layers.Dense(feature_dim)\n",
    "        self.beta_net = layers.Dense(feature_dim)\n",
    "    \n",
    "    def call(self, x, cell_type_id=None):\n",
    "        if cell_type_id is not None:\n",
    "            B = tf.shape(x)[0]\n",
    "            C = self.feature_dim\n",
    "            \n",
    "            cell_emb = self.cell_embedding(cell_type_id)\n",
    "            gamma = self.gamma_net(cell_emb)\n",
    "            gamma = tf.reshape(gamma, [B, 1, 1, C])\n",
    "            beta = self.beta_net(cell_emb)\n",
    "            beta = tf.reshape(beta, [B, 1, 1, C])\n",
    "            \n",
    "            mean, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "            x_norm = (x - mean) / tf.sqrt(var + 1e-5)\n",
    "            \n",
    "            x_adapted = gamma * x_norm + beta\n",
    "        else:\n",
    "            x_adapted = x\n",
    "        \n",
    "        return x_adapted\n",
    "\n",
    "\n",
    "# ==================== MAIN MODEL ====================\n",
    "class HiCMEGA(Model):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.epigenomic_encoder = MultiModalEpigenomicEncoder(\n",
    "            hidden_dim=config['feature_dim'],\n",
    "            num_modalities=config['num_modalities']\n",
    "        )\n",
    "        \n",
    "        self.adaptive_blocks = [\n",
    "            AdaptiveMultiScaleDilatedBlock(config['feature_dim'])\n",
    "            for _ in range(2)\n",
    "        ]\n",
    "        \n",
    "        self.graph_module = ChromatinStructureGraphModule(\n",
    "            feature_dim=config['feature_dim'],\n",
    "            num_gnn_layers=2\n",
    "        )\n",
    "        \n",
    "        self.hybrid_core = HybridCNNTransformer(\n",
    "            dim=config['feature_dim'],\n",
    "            depth=config['depth'],\n",
    "            num_heads=config['num_heads']\n",
    "        )\n",
    "        \n",
    "        self.decoder = MultiResolutionProgressiveDecoder(\n",
    "            in_channels=config['feature_dim'],\n",
    "            scales=config['scales']\n",
    "        )\n",
    "        \n",
    "        self.cell_adapter = CellTypeAdapter(\n",
    "            feature_dim=config['feature_dim'],\n",
    "            num_cell_types=config['num_cell_types']\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        if isinstance(inputs, tuple):\n",
    "            x_hic = inputs[0]\n",
    "        else:\n",
    "            x_hic = inputs\n",
    "        \n",
    "        features = self.epigenomic_encoder(x_hic, training=training)\n",
    "        \n",
    "        for adaptive_block in self.adaptive_blocks:\n",
    "            features = adaptive_block(features, training=training)\n",
    "        \n",
    "        features = self.graph_module(features, training=training)\n",
    "        features = self.hybrid_core(features, training=training)\n",
    "        features = self.cell_adapter(features)\n",
    "        \n",
    "        outputs = self.decoder(features, training=training)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "# ==================== LOSS FUNCTIONS ====================\n",
    "class SSIMLoss(keras.losses.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        c1 = 0.01 ** 2\n",
    "        c2 = 0.03 ** 2\n",
    "        \n",
    "        mu_true = tf.nn.avg_pool2d(y_true, 3, 1, 'SAME')\n",
    "        mu_pred = tf.nn.avg_pool2d(y_pred, 3, 1, 'SAME')\n",
    "        \n",
    "        sigma_true = tf.nn.avg_pool2d(y_true ** 2, 3, 1, 'SAME') - mu_true ** 2\n",
    "        sigma_pred = tf.nn.avg_pool2d(y_pred ** 2, 3, 1, 'SAME') - mu_pred ** 2\n",
    "        sigma_pred_true = tf.nn.avg_pool2d(y_pred * y_true, 3, 1, 'SAME') - mu_pred * mu_true\n",
    "        \n",
    "        ssim = ((2 * mu_pred * mu_true + c1) * (2 * sigma_pred_true + c2)) / \\\n",
    "               ((mu_pred ** 2 + mu_true ** 2 + c1) * (sigma_pred + sigma_true + c2))\n",
    "        \n",
    "        return 1 - tf.reduce_mean(ssim)\n",
    "\n",
    "\n",
    "class HiCMEGALoss(keras.losses.Loss):\n",
    "    def __init__(self, lambda_rec=1.0, lambda_struct=0.3, lambda_bio=0.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lambda_rec = lambda_rec\n",
    "        self.lambda_struct = lambda_struct\n",
    "        self.lambda_bio = lambda_bio\n",
    "        self.ssim_loss = SSIMLoss()\n",
    "    \n",
    "    def reconstruction_loss(self, y_true, y_pred):\n",
    "        mse = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "        ssim = self.ssim_loss(y_true, y_pred)\n",
    "        return mse + 0.3 * ssim\n",
    "    \n",
    "    def structure_loss(self, y_true, y_pred):\n",
    "        window_size = 5\n",
    "        pred_insulation = tf.nn.avg_pool2d(y_pred, window_size, 1, 'SAME')\n",
    "        true_insulation = tf.nn.avg_pool2d(y_true, window_size, 1, 'SAME')\n",
    "        return tf.reduce_mean(tf.square(pred_insulation - true_insulation))\n",
    "    \n",
    "    def biological_loss(self, y_true, y_pred):\n",
    "        max_dist = 10\n",
    "        \n",
    "        pred_decays = []\n",
    "        true_decays = []\n",
    "        \n",
    "        for dist in range(max_dist):\n",
    "            if dist == 0:\n",
    "                pred_diag = y_pred\n",
    "                true_diag = y_true\n",
    "            else:\n",
    "                pred_diag = y_pred[:, dist:, :, :]\n",
    "                true_diag = y_true[:, dist:, :, :]\n",
    "            \n",
    "            pred_mean = tf.reduce_mean(pred_diag)\n",
    "            true_mean = tf.reduce_mean(true_diag)\n",
    "            \n",
    "            pred_decays.append(pred_mean)\n",
    "            true_decays.append(true_mean)\n",
    "        \n",
    "        pred_decay_tensor = tf.stack(pred_decays)\n",
    "        true_decay_tensor = tf.stack(true_decays)\n",
    "        \n",
    "        return tf.reduce_mean(tf.square(pred_decay_tensor - true_decay_tensor))\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        loss_rec = self.reconstruction_loss(y_true, y_pred)\n",
    "        loss_struct = self.structure_loss(y_true, y_pred)\n",
    "        loss_bio = self.biological_loss(y_true, y_pred)\n",
    "        \n",
    "        total_loss = (self.lambda_rec * loss_rec + \n",
    "                     self.lambda_struct * loss_struct + \n",
    "                     self.lambda_bio * loss_bio)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "# ==================== TRAINING ====================\n",
    "class HiCMEGATrainer:\n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        \n",
    "        self.loss_fn = HiCMEGALoss(lambda_rec=1.0, lambda_struct=0.3, lambda_bio=0.2)\n",
    "        \n",
    "        try:\n",
    "            self.optimizer = keras.optimizers.AdamW(\n",
    "                learning_rate=config['learning_rate'],\n",
    "                weight_decay=1e-5\n",
    "            )\n",
    "        except AttributeError:\n",
    "            self.optimizer = keras.optimizers.Adam(\n",
    "                learning_rate=config['learning_rate']\n",
    "            )\n",
    "            print(\"âš  AdamW not available, using Adam optimizer\")\n",
    "        \n",
    "        self.train_loss_metric = keras.metrics.Mean(name='train_loss')\n",
    "        self.val_loss_metric = keras.metrics.Mean(name='val_loss')\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_ssim': [],\n",
    "            'val_pearson': [],\n",
    "        }\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.model(lr, training=True)\n",
    "            loss = self.loss_fn(hr, pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        \n",
    "        self.train_loss_metric.update_state(loss)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def val_step(self, lr, hr):\n",
    "        pred = self.model(lr, training=False)\n",
    "        loss = self.loss_fn(hr, pred)\n",
    "        self.val_loss_metric.update_state(loss)\n",
    "        return pred, loss\n",
    "    \n",
    "    def train_epoch(self, train_dataset, epoch):\n",
    "        self.train_loss_metric.reset_states()\n",
    "        \n",
    "        pbar = tqdm(train_dataset, desc=f'Epoch {epoch}')\n",
    "        for lr, hr in pbar:\n",
    "            loss = self.train_step(lr, hr)\n",
    "            pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "        \n",
    "        return self.train_loss_metric.result().numpy()\n",
    "    \n",
    "    def validate(self, val_dataset):\n",
    "        self.val_loss_metric.reset_states()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for lr, hr in tqdm(val_dataset, desc='Validation'):\n",
    "            pred, loss = self.val_step(lr, hr)\n",
    "            all_preds.append(pred)\n",
    "            all_targets.append(hr)\n",
    "        \n",
    "        # Calculate metrics on validation set\n",
    "        all_preds = tf.concat(all_preds, axis=0)\n",
    "        all_targets = tf.concat(all_targets, axis=0)\n",
    "        \n",
    "        val_metrics = HiCMetrics.calculate_all_metrics(all_preds, all_targets)\n",
    "        \n",
    "        return self.val_loss_metric.result().numpy(), val_metrics\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset, num_epochs):\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Starting Training\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            train_loss = self.train_epoch(train_dataset, epoch)\n",
    "            val_loss, val_metrics = self.validate(val_dataset)\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_ssim'].append(val_metrics['SSIM'])\n",
    "            self.history['val_pearson'].append(val_metrics['Pearson'])\n",
    "            \n",
    "            print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Val SSIM: {val_metrics['SSIM']:.4f}\")\n",
    "            print(f\"Val Pearson: {val_metrics['Pearson']:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.model.save_weights(CONFIG['model_path'])\n",
    "                print(f\"âœ“ Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                self.visualize_predictions(val_dataset, epoch)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Training Complete!\")\n",
    "        print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def visualize_predictions(self, dataset, epoch):\n",
    "        batch = next(iter(dataset))\n",
    "        lr, hr = batch\n",
    "        lr = lr[:4]\n",
    "        hr = hr[:4]\n",
    "        \n",
    "        pred = self.model(lr, training=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "        \n",
    "        for i in range(4):\n",
    "            axes[i, 0].imshow(lr[i, :, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\n",
    "            axes[i, 0].set_title('Low Resolution (Downsampled 1/16)')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(pred[i, :, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\n",
    "            axes[i, 1].set_title('HiC-MEGA Prediction')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(hr[i, :, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\n",
    "            axes[i, 2].set_title('Ground Truth (High Resolution)')\n",
    "            axes[i, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "        plt.savefig(f\"{CONFIG['output_dir']}/predictions_epoch_{epoch}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"âœ“ Predictions saved to {CONFIG['output_dir']}/predictions_epoch_{epoch}.png\")\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=10)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # SSIM\n",
    "    axes[0, 1].plot(history['val_ssim'], label='Val SSIM', linewidth=2, color='green')\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('SSIM', fontsize=12)\n",
    "    axes[0, 1].set_title('Validation SSIM', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend(fontsize=10)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Pearson\n",
    "    axes[1, 0].plot(history['val_pearson'], label='Val Pearson', linewidth=2, color='orange')\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Pearson Correlation', fontsize=12)\n",
    "    axes[1, 0].set_title('Validation Pearson Correlation', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend(fontsize=10)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Summary\n",
    "    axes[1, 1].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    Training Summary\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Best Val Loss: {min(history['val_loss']):.4f}\n",
    "    Best SSIM: {max(history['val_ssim']):.4f}\n",
    "    Best Pearson: {max(history['val_pearson']):.4f}\n",
    "    \n",
    "    Final Epoch:\n",
    "    Train Loss: {history['train_loss'][-1]:.4f}\n",
    "    Val Loss: {history['val_loss'][-1]:.4f}\n",
    "    Val SSIM: {history['val_ssim'][-1]:.4f}\n",
    "    Val Pearson: {history['val_pearson'][-1]:.4f}\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, family='monospace',\n",
    "                    verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Training history saved to {save_path}\")\n",
    "\n",
    "\n",
    "# ==================== INFERENCE FUNCTION ====================\n",
    "def run_inference():\n",
    "    print(\"=\"*80)\n",
    "    print(\"HiC-MEGA Inference Mode - GM12878 Evaluation\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nLoading model...\")\n",
    "    model = HiCMEGA(CONFIG)\n",
    "    sample_input = tf.random.normal([1, 40, 40, 1])\n",
    "    _ = model(sample_input)\n",
    "    model.load_weights(CONFIG['model_path'])\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "    \n",
    "    print(\"\\nLoading GM12878 test data...\")\n",
    "    test_data = HiCDataset(\n",
    "        CONFIG['test_npz'], \n",
    "        batch_size=1,\n",
    "        downsample_ratio=CONFIG['downsample_ratio']\n",
    "    )\n",
    "    test_dataset = test_data.get_dataset()\n",
    "    print(f\"âœ“ Test samples: {len(test_data)}\")\n",
    "    \n",
    "    os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "    \n",
    "    print(\"\\nRunning inference on GM12878 dataset...\")\n",
    "    all_metrics = []\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for idx, (lr, hr) in enumerate(tqdm(test_dataset, desc='Inference')):\n",
    "        pred = model(lr, training=False)\n",
    "        \n",
    "        all_preds.append(pred)\n",
    "        all_targets.append(hr)\n",
    "        \n",
    "        # Save predictions\n",
    "        np.save(\n",
    "            os.path.join(CONFIG['output_dir'], f'pred_{idx}.npy'),\n",
    "            pred[0, :, :, 0].numpy()\n",
    "        )\n",
    "    \n",
    "    # Concatenate all predictions and targets\n",
    "    all_preds = tf.concat(all_preds, axis=0)\n",
    "    all_targets = tf.concat(all_targets, axis=0)\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    print(\"\\nCalculating comprehensive metrics...\")\n",
    "    final_metrics = HiCMetrics.calculate_all_metrics(all_preds, all_targets)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GM12878 Test Set Results (1/16 Downsampling)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"SSIM:          {final_metrics['SSIM']:.6f}\")\n",
    "    print(f\"GenomeDISCO:   {final_metrics['GenomeDISCO']:.6f}\")\n",
    "    print(f\"HiCRep:        {final_metrics['HiCRep']:.6f}\")\n",
    "    print(f\"Pearson:       {final_metrics['Pearson']:.6f}\")\n",
    "    print(f\"Spearman:      {final_metrics['Spearman']:.6f}\")\n",
    "    print(f\"MSE:           {final_metrics['MSE']:.6f}\")\n",
    "    print(f\"PSNR:          {final_metrics['PSNR']:.4f} dB\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Save metrics to file\n",
    "    metrics_file = os.path.join(CONFIG['output_dir'], CONFIG['metrics_file'])\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(final_metrics, f, indent=4)\n",
    "    print(f\"\\nâœ“ Metrics saved to {metrics_file}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    visualize_metrics_comparison(all_preds[:8], all_targets[:8])\n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "\n",
    "def visualize_metrics_comparison(preds, targets, save_path=None):\n",
    "    \"\"\"Create comprehensive visualization with metrics\"\"\"\n",
    "    if save_path is None:\n",
    "        save_path = os.path.join(CONFIG['output_dir'], 'metrics_visualization.png')\n",
    "    \n",
    "    n_samples = min(4, preds.shape[0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(n_samples + 1, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        pred = preds[i, :, :, 0].numpy()\n",
    "        target = targets[i, :, :, 0].numpy()\n",
    "        \n",
    "        # Low resolution (simulated by downsampling target)\n",
    "        lr = tf.image.resize(targets[i:i+1], \n",
    "                            [target.shape[0]//CONFIG['scales'][0], \n",
    "                             target.shape[1]//CONFIG['scales'][0]])\n",
    "        lr = tf.image.resize(lr, [target.shape[0], target.shape[1]])\n",
    "        lr = lr[0, :, :, 0].numpy()\n",
    "        \n",
    "        # Calculate metrics for this sample\n",
    "        sample_metrics = HiCMetrics.calculate_all_metrics(\n",
    "            preds[i:i+1], targets[i:i+1]\n",
    "        )\n",
    "        \n",
    "        # Plot low resolution\n",
    "        ax1 = fig.add_subplot(gs[i, 0])\n",
    "        im1 = ax1.imshow(lr, cmap='Reds', vmin=0, vmax=1)\n",
    "        ax1.set_title(f'Sample {i+1}: Low Res (1/{CONFIG[\"downsample_ratio\"]})', fontsize=10)\n",
    "        ax1.axis('off')\n",
    "        plt.colorbar(im1, ax=ax1, fraction=0.046)\n",
    "        \n",
    "        # Plot prediction\n",
    "        ax2 = fig.add_subplot(gs[i, 1])\n",
    "        im2 = ax2.imshow(pred, cmap='Reds', vmin=0, vmax=1)\n",
    "        ax2.set_title('HiC-MEGA Prediction', fontsize=10)\n",
    "        ax2.axis('off')\n",
    "        plt.colorbar(im2, ax=ax2, fraction=0.046)\n",
    "        \n",
    "        # Plot ground truth\n",
    "        ax3 = fig.add_subplot(gs[i, 2])\n",
    "        im3 = ax3.imshow(target, cmap='Reds', vmin=0, vmax=1)\n",
    "        ax3.set_title('Ground Truth', fontsize=10)\n",
    "        ax3.axis('off')\n",
    "        plt.colorbar(im3, ax=ax3, fraction=0.046)\n",
    "        \n",
    "        # Plot difference\n",
    "        ax4 = fig.add_subplot(gs[i, 3])\n",
    "        diff = np.abs(pred - target)\n",
    "        im4 = ax4.imshow(diff, cmap='Blues', vmin=0, vmax=0.5)\n",
    "        ax4.set_title(f'Abs Diff (SSIM: {sample_metrics[\"SSIM\"]:.3f})', fontsize=10)\n",
    "        ax4.axis('off')\n",
    "        plt.colorbar(im4, ax=ax4, fraction=0.046)\n",
    "    \n",
    "    # Add overall metrics summary\n",
    "    ax_summary = fig.add_subplot(gs[n_samples, :])\n",
    "    ax_summary.axis('off')\n",
    "    \n",
    "    overall_metrics = HiCMetrics.calculate_all_metrics(preds, targets)\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    Overall Performance Metrics (GM12878, 1/16 Downsampling)\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    SSIM (Structural Similarity):        {overall_metrics['SSIM']:.6f}\n",
    "    GenomeDISCO (Genomic Similarity):    {overall_metrics['GenomeDISCO']:.6f}\n",
    "    HiCRep (Reproducibility Score):      {overall_metrics['HiCRep']:.6f}\n",
    "    Pearson Correlation:                 {overall_metrics['Pearson']:.6f}\n",
    "    Spearman Correlation:                {overall_metrics['Spearman']:.6f}\n",
    "    MSE (Mean Squared Error):            {overall_metrics['MSE']:.6f}\n",
    "    PSNR (Peak Signal-to-Noise Ratio):  {overall_metrics['PSNR']:.4f} dB\n",
    "    \"\"\"\n",
    "    \n",
    "    ax_summary.text(0.5, 0.5, summary_text, \n",
    "                   fontsize=11, family='monospace',\n",
    "                   verticalalignment='center',\n",
    "                   horizontalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ Metrics visualization saved to {save_path}\")\n",
    "\n",
    "\n",
    "# ==================== TRAINING FUNCTION ====================\n",
    "def train_model():\n",
    "    print(\"=\"*80)\n",
    "    print(\"HiC-MEGA Training - GM12878 Dataset\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Feature Dimension: {CONFIG['feature_dim']}\")\n",
    "    print(f\"Downsampling Ratio: 1/{CONFIG['downsample_ratio']}\")\n",
    "    print(f\"Batch Size: {CONFIG['batch_size']}\")\n",
    "    print(f\"Learning Rate: {CONFIG['learning_rate']}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"\\n[1/5] Loading datasets...\")\n",
    "    train_data = HiCDataset(\n",
    "        CONFIG['train_npz'], \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        downsample_ratio=CONFIG['downsample_ratio']\n",
    "    )\n",
    "    valid_data = HiCDataset(\n",
    "        CONFIG['valid_npz'], \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        downsample_ratio=CONFIG['downsample_ratio']\n",
    "    )\n",
    "    \n",
    "    train_dataset = train_data.get_dataset()\n",
    "    valid_dataset = valid_data.get_dataset()\n",
    "    \n",
    "    print(f\"âœ“ Training samples: {len(train_data)}\")\n",
    "    print(f\"âœ“ Validation samples: {len(valid_data)}\")\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n[2/5] Initializing HiC-MEGA model...\")\n",
    "    model = HiCMEGA(CONFIG)\n",
    "    \n",
    "    # Build model\n",
    "    sample_input = tf.random.normal([1, 40, 40, 1])\n",
    "    _ = model(sample_input)\n",
    "    \n",
    "    total_params = model.count_params()\n",
    "    print(f\"âœ“ Total parameters: {total_params:,}\")\n",
    "    \n",
    "    # Create trainer\n",
    "    print(\"\\n[3/5] Setting up training...\")\n",
    "    trainer = HiCMEGATrainer(model, CONFIG)\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n[4/5] Starting training...\")\n",
    "    history = trainer.train(train_dataset, valid_dataset, CONFIG['num_epochs'])\n",
    "    \n",
    "    # Plot history\n",
    "    print(\"\\n[5/5] Generating training plots...\")\n",
    "    plot_training_history(\n",
    "        history, \n",
    "        save_path=os.path.join(CONFIG['output_dir'], 'training_history.png')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ“ Training completed successfully!\")\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    \n",
    "    if CONFIG['mode'] == 'train':\n",
    "        model, history = train_model()\n",
    "        \n",
    "        # Save final metrics\n",
    "        final_metrics = {\n",
    "            'best_train_loss': float(min(history['train_loss'])),\n",
    "            'best_val_loss': float(min(history['val_loss'])),\n",
    "            'best_ssim': float(max(history['val_ssim'])),\n",
    "            'best_pearson': float(max(history['val_pearson'])),\n",
    "            'downsample_ratio': CONFIG['downsample_ratio'],\n",
    "            'num_epochs': CONFIG['num_epochs'],\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(CONFIG['output_dir'], 'training_summary.json'), 'w') as f:\n",
    "            json.dump(final_metrics, f, indent=4)\n",
    "        \n",
    "        return model, history\n",
    "        \n",
    "    elif CONFIG['mode'] == 'inference':\n",
    "        metrics = run_inference()\n",
    "        return metrics\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: Unknown mode '{CONFIG['mode']}'. Use 'train' or 'inference'\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\nðŸš€ Starting HiC-MEGA...\")\n",
    "    print(\"ðŸ’¡ Modify CONFIG dictionary to change settings\\n\")\n",
    "    \n",
    "    result = main()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… Execution Complete!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c1f649-9c0c-4ba3-be48-c69c1f30c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Proly Kumar\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory growth enabled for 1 GPU(s)\n",
      "\n",
      "ðŸ‹ï¸ TRAINING PHASE\n",
      "\n",
      "======================================================================\n",
      "HiC-MEGAN: Multi-Scale Enhanced Genome Architecture Network\n",
      "ðŸš€ NOVEL ARCHITECTURE - Designed to beat DiCARN-DNase\n",
      "======================================================================\n",
      "\n",
      "âœ“ Found 1 GPU(s)\n",
      "\n",
      "ðŸ“‚ Loading datasets...\n",
      "Total samples in file: 42832\n",
      "âœ“ Loaded 42832 samples\n",
      "âœ“ LR shape: (1, 40, 40), HR shape: (1, 40, 40)\n",
      "Total samples in file: 18063\n",
      "âœ“ Loaded 18063 samples\n",
      "âœ“ LR shape: (1, 40, 40), HR shape: (1, 40, 40)\n",
      "\n",
      "âœ“ Input shape: (40, 40, 1)\n",
      "âœ“ Batch size: 16\n",
      "âœ“ Training batches per epoch: 2677\n",
      "âœ“ Validation batches: 1129\n",
      "\n",
      "ðŸ—ï¸ Building HiC-MEGAN...\n",
      "âœ“ Model built successfully\n",
      "âœ“ Trainable parameters: 268,082\n",
      "\n",
      "âœ“ Model compiled with Biological Structure-Aware Loss\n",
      "\n",
      "ðŸŒŸ NOVEL COMPONENTS:\n",
      "  âœ¨ Multi-Scale Feature Extraction (MSFE)\n",
      "  âœ¨ Enhanced Global-Local Attention (EGLA)\n",
      "  âœ¨ Progressive Residual Refinement (PRR)\n",
      "  âœ¨ Adaptive Feature Fusion (AFF)\n",
      "  âœ¨ Biological Structure-Aware Loss (BSAL)\n",
      "\n",
      "ðŸ’ª ADVANTAGES OVER DiCARN-DNase:\n",
      "  âœ“ Better multi-scale feature extraction\n",
      "  âœ“ Enhanced attention mechanism (channel + spatial + global)\n",
      "  âœ“ Progressive refinement with dense connections\n",
      "  âœ“ Learnable adaptive fusion\n",
      "  âœ“ More biologically-informed loss function\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ Starting Training...\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1384 - mae: 0.0291\n",
      "Epoch 1: val_loss improved from inf to 0.12206, saving model to best_hic_megan.keras\n",
      "2677/2677 [==============================] - 553s 46ms/step - loss: 0.1384 - mae: 0.0291 - val_loss: 0.1221 - val_mae: 0.0143 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1220 - mae: 0.0154\n",
      "Epoch 2: val_loss improved from 0.12206 to 0.12058, saving model to best_hic_megan.keras\n",
      "2677/2677 [==============================] - 119s 44ms/step - loss: 0.1220 - mae: 0.0154 - val_loss: 0.1206 - val_mae: 0.0127 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1203 - mae: 0.0140\n",
      "Epoch 3: val_loss improved from 0.12058 to 0.11883, saving model to best_hic_megan.keras\n",
      "2677/2677 [==============================] - 128s 48ms/step - loss: 0.1203 - mae: 0.0140 - val_loss: 0.1188 - val_mae: 0.0119 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1192 - mae: 0.0132\n",
      "Epoch 4: val_loss improved from 0.11883 to 0.11836, saving model to best_hic_megan.keras\n",
      "2677/2677 [==============================] - 123s 46ms/step - loss: 0.1193 - mae: 0.0132 - val_loss: 0.1184 - val_mae: 0.0117 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1187 - mae: 0.0128\n",
      "======================================================================\n",
      "ðŸ“Š Computing detailed metrics (Epoch 5)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics (sampled from 10 batches):\n",
      "   MSE:  0.000358\n",
      "   MAE:  0.012092\n",
      "   PCC:  0.5917 âœ“ NEW BEST!\n",
      "   SSIM: 0.8954 âœ“ NEW BEST!\n",
      "   PSNR: 21.33 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 5: val_loss improved from 0.11836 to 0.11780, saving model to best_hic_megan.keras\n",
      "2677/2677 [==============================] - 123s 46ms/step - loss: 0.1187 - mae: 0.0128 - val_loss: 0.1178 - val_mae: 0.0114 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1183 - mae: 0.0126\n",
      "Epoch 6: val_loss did not improve from 0.11780\n",
      "2677/2677 [==============================] - 126s 47ms/step - loss: 0.1183 - mae: 0.0126 - val_loss: 0.1263 - val_mae: 0.0165 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "1492/2677 [===============>..............] - ETA: 50s - loss: 0.1181 - mae: 0.0123"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 784\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;66;03m# ==================== TRAINING ====================\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ‹ï¸ TRAINING PHASE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 784\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_hic_megan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_npz_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_NPZ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_npz_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALID_NPZ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Adjust based on GPU memory\u001b[39;49;00m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Slightly lower for stability\u001b[39;49;00m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Memory-efficient\u001b[39;49;00m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_prr_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Good balance\u001b[39;49;00m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_train_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use full dataset\u001b[39;49;00m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_valid_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# ==================== TESTING ====================\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ§ª TESTING PHASE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 696\u001b[0m, in \u001b[0;36mtrain_hic_megan\u001b[1;34m(train_npz_path, valid_npz_path, epochs, batch_size, initial_lr, base_filters, num_prr_blocks, metric_frequency, metric_batches, max_train_samples, max_valid_samples)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ Starting Training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Training Complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HiC-MEGAN: Multi-Scale Enhanced Genome Architecture Network\n",
    "============================================================\n",
    "\n",
    "Novel Contributions Beyond DiCARN-DNase:\n",
    "1. âœ¨ Hybrid Multi-Scale Feature Extraction (MSFE) Module\n",
    "2. âœ¨ Enhanced Global-Local Attention (EGLA) Mechanism  \n",
    "3. âœ¨ Progressive Residual Refinement (PRR) Strategy\n",
    "4. âœ¨ Biological Structure-Aware Loss (BSAL) Function\n",
    "5. âœ¨ Adaptive Feature Fusion (AFF) with learnable weights\n",
    "\n",
    "Architecture designed to achieve BETTER results than DiCARN-DNase\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# ==================== GPU Configuration ====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ“ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš  GPU configuration warning: {e}\")\n",
    "\n",
    "# ==================== Novel Component 1: Multi-Scale Feature Extraction (MSFE) ====================\n",
    "class MultiScaleFeatureExtraction(layers.Layer):\n",
    "    \"\"\"\n",
    "    Novel MSFE Module - Better than DiCARN's dilated convolution\n",
    "    Uses parallel multi-scale pathways with adaptive pooling\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(MultiScaleFeatureExtraction, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        \n",
    "        # Multi-scale parallel branches (3 scales)\n",
    "        self.branch1_conv1 = layers.Conv2D(filters // 4, 1, padding='same')\n",
    "        self.branch1_conv2 = layers.Conv2D(filters // 4, 3, padding='same', dilation_rate=1)\n",
    "        \n",
    "        self.branch2_conv1 = layers.Conv2D(filters // 4, 1, padding='same')\n",
    "        self.branch2_conv2 = layers.Conv2D(filters // 4, 3, padding='same', dilation_rate=2)\n",
    "        \n",
    "        self.branch3_conv1 = layers.Conv2D(filters // 4, 1, padding='same')\n",
    "        self.branch3_conv2 = layers.Conv2D(filters // 4, 3, padding='same', dilation_rate=3)\n",
    "        \n",
    "        # Global context branch\n",
    "        self.global_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
    "        self.global_conv = layers.Conv2D(filters // 4, 1, padding='same')\n",
    "        \n",
    "        # Feature fusion\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.fusion_conv = layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        # Branch 1: Fine-grained details (d=1)\n",
    "        b1 = self.branch1_conv1(x)\n",
    "        b1 = self.branch1_conv2(b1)\n",
    "        \n",
    "        # Branch 2: Medium-range interactions (d=2)\n",
    "        b2 = self.branch2_conv1(x)\n",
    "        b2 = self.branch2_conv2(b2)\n",
    "        \n",
    "        # Branch 3: Long-range interactions (d=3)\n",
    "        b3 = self.branch3_conv1(x)\n",
    "        b3 = self.branch3_conv2(b3)\n",
    "        \n",
    "        # Branch 4: Global context\n",
    "        b4 = self.global_pool(x)\n",
    "        b4 = self.global_conv(b4)\n",
    "        b4 = tf.image.resize(b4, [tf.shape(x)[1], tf.shape(x)[2]], method='bilinear')\n",
    "        \n",
    "        # Concatenate all branches\n",
    "        merged = layers.Concatenate()([b1, b2, b3, b4])\n",
    "        merged = self.bn(merged, training=training)\n",
    "        merged = self.relu(merged)\n",
    "        \n",
    "        # Fuse features\n",
    "        out = self.fusion_conv(merged)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'filters': self.filters})\n",
    "        return config\n",
    "\n",
    "# ==================== Novel Component 2: Enhanced Global-Local Attention (EGLA) ====================\n",
    "class EnhancedGlobalLocalAttention(layers.Layer):\n",
    "    \"\"\"\n",
    "    Novel EGLA - Better than DiCARN's spatial attention\n",
    "    Combines both channel and spatial attention with global context\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, reduction_ratio=8, **kwargs):\n",
    "        super(EnhancedGlobalLocalAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        \n",
    "        # Channel Attention Path\n",
    "        self.global_avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
    "        self.global_max_pool = layers.GlobalMaxPooling2D(keepdims=True)\n",
    "        self.channel_fc1 = layers.Dense(filters // reduction_ratio, activation='relu')\n",
    "        self.channel_fc2 = layers.Dense(filters, activation='sigmoid')\n",
    "        \n",
    "        # Spatial Attention Path\n",
    "        self.spatial_conv = layers.Conv2D(1, 7, padding='same', activation='sigmoid')\n",
    "        \n",
    "        # Global Context Path (Novel addition)\n",
    "        self.global_context_conv1 = layers.Conv2D(filters // 4, 1, padding='same')\n",
    "        self.global_context_conv2 = layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Channel Attention\n",
    "        avg_pool = self.global_avg_pool(x)\n",
    "        max_pool = self.global_max_pool(x)\n",
    "        \n",
    "        avg_out = tf.reshape(avg_pool, [-1, self.filters])\n",
    "        max_out = tf.reshape(max_pool, [-1, self.filters])\n",
    "        \n",
    "        avg_out = self.channel_fc1(avg_out)\n",
    "        avg_out = self.channel_fc2(avg_out)\n",
    "        \n",
    "        max_out = self.channel_fc1(max_out)\n",
    "        max_out = self.channel_fc2(max_out)\n",
    "        \n",
    "        channel_attention = tf.reshape(avg_out + max_out, [-1, 1, 1, self.filters])\n",
    "        x_channel = x * channel_attention\n",
    "        \n",
    "        # Spatial Attention\n",
    "        avg_out_spatial = tf.reduce_mean(x_channel, axis=-1, keepdims=True)\n",
    "        max_out_spatial = tf.reduce_max(x_channel, axis=-1, keepdims=True)\n",
    "        spatial_concat = layers.Concatenate()([avg_out_spatial, max_out_spatial])\n",
    "        spatial_attention = self.spatial_conv(spatial_concat)\n",
    "        x_spatial = x_channel * spatial_attention\n",
    "        \n",
    "        # Global Context Enhancement (Novel)\n",
    "        global_context = self.global_avg_pool(x)\n",
    "        global_context = self.global_context_conv1(global_context)\n",
    "        global_context = self.global_context_conv2(global_context)\n",
    "        \n",
    "        # Final fusion\n",
    "        out = x_spatial + global_context\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'reduction_ratio': self.reduction_ratio\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ==================== Novel Component 3: Progressive Residual Refinement Block ====================\n",
    "class ProgressiveResidualBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    Novel PRR Block - Better than DiCARN's cascading ResNet\n",
    "    Progressive refinement with feature reuse and dense connections\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, num_layers=3, **kwargs):\n",
    "        super(ProgressiveResidualBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Progressive layers\n",
    "        self.conv_layers = []\n",
    "        self.bn_layers = []\n",
    "        for i in range(num_layers):\n",
    "            self.conv_layers.append(\n",
    "                layers.Conv2D(filters, 3, padding='same', kernel_initializer='he_normal')\n",
    "            )\n",
    "            self.bn_layers.append(layers.BatchNormalization())\n",
    "        \n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        # Dimension reduction for concatenated features\n",
    "        self.reduce_convs = []\n",
    "        for i in range(num_layers):\n",
    "            if i > 0:\n",
    "                # Each reduce_conv handles different input channel sizes\n",
    "                self.reduce_convs.append(\n",
    "                    layers.Conv2D(filters, 1, padding='same', kernel_initializer='he_normal')\n",
    "                )\n",
    "        \n",
    "        # Feature aggregation\n",
    "        self.aggregate_conv = layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        features = [x]\n",
    "        \n",
    "        # Progressive refinement with dense connections\n",
    "        for i in range(self.num_layers):\n",
    "            # Concatenate all previous features\n",
    "            if i > 0:\n",
    "                concat_features = layers.Concatenate()(features)\n",
    "                # Reduce to same channel size using appropriate reduce_conv\n",
    "                concat_features = self.reduce_convs[i-1](concat_features)\n",
    "            else:\n",
    "                concat_features = x\n",
    "            \n",
    "            # Apply convolution\n",
    "            out = self.conv_layers[i](concat_features)\n",
    "            out = self.bn_layers[i](out, training=training)\n",
    "            out = self.relu(out)\n",
    "            \n",
    "            features.append(out)\n",
    "        \n",
    "        # Aggregate all features (exclude original input)\n",
    "        all_features = layers.Concatenate()(features[1:])\n",
    "        aggregated = self.aggregate_conv(all_features)\n",
    "        \n",
    "        # Residual connection\n",
    "        out = x + aggregated\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'num_layers': self.num_layers\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ==================== Novel Component 4: Adaptive Feature Fusion ====================\n",
    "class AdaptiveFeatureFusion(layers.Layer):\n",
    "    \"\"\"\n",
    "    Novel AFF - Learnable fusion weights for multi-level features\n",
    "    Better than simple concatenation or addition\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, num_inputs=2, **kwargs):\n",
    "        super(AdaptiveFeatureFusion, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.num_inputs = num_inputs\n",
    "        \n",
    "        # Learnable fusion weights\n",
    "        self.weight_conv = layers.Conv2D(num_inputs, 1, padding='same')\n",
    "        self.softmax = layers.Softmax(axis=-1)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_conv = layers.Conv2D(filters, 1, padding='same')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"inputs: list of tensors to fuse\"\"\"\n",
    "        # Stack inputs\n",
    "        stacked = tf.stack(inputs, axis=-1)  # [B, H, W, C, N]\n",
    "        \n",
    "        # Compute adaptive weights\n",
    "        pooled = tf.reduce_mean(stacked, axis=3, keepdims=True)  # [B, H, W, 1, N]\n",
    "        pooled = tf.squeeze(pooled, axis=3)  # [B, H, W, N]\n",
    "        \n",
    "        weights = self.weight_conv(pooled)  # [B, H, W, N]\n",
    "        weights = self.softmax(weights)\n",
    "        weights = tf.expand_dims(weights, axis=3)  # [B, H, W, 1, N]\n",
    "        \n",
    "        # Weighted fusion\n",
    "        fused = tf.reduce_sum(stacked * weights, axis=-1)  # [B, H, W, C]\n",
    "        \n",
    "        # Output projection\n",
    "        out = self.output_conv(fused)\n",
    "        out = self.bn(out, training=training)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'num_inputs': self.num_inputs\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ==================== HiC-MEGAN Main Architecture ====================\n",
    "def build_hic_megan(input_size=(40, 40, 1),\n",
    "                    base_filters=32,\n",
    "                    num_prr_blocks=6,\n",
    "                    use_egla=True):\n",
    "    \"\"\"\n",
    "    HiC-MEGAN: Multi-Scale Enhanced Genome Architecture Network\n",
    "    \n",
    "    Novel architecture combining:\n",
    "    - Multi-Scale Feature Extraction (MSFE)\n",
    "    - Enhanced Global-Local Attention (EGLA)\n",
    "    - Progressive Residual Refinement (PRR)\n",
    "    - Adaptive Feature Fusion (AFF)\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = layers.Input(input_size, name='hic_input')\n",
    "    \n",
    "    # ===== Stage 1: Initial Feature Extraction =====\n",
    "    x = layers.Conv2D(base_filters, 7, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    initial_features = x\n",
    "    \n",
    "    # ===== Stage 2: Multi-Scale Feature Extraction =====\n",
    "    x = MultiScaleFeatureExtraction(base_filters, name='msfe_1')(x)\n",
    "    \n",
    "    # Store for skip connection\n",
    "    msfe_features = x\n",
    "    \n",
    "    # ===== Stage 3: Progressive Residual Refinement Blocks =====\n",
    "    prr_outputs = [x]\n",
    "    \n",
    "    for i in range(num_prr_blocks):\n",
    "        x = ProgressiveResidualBlock(\n",
    "            base_filters, \n",
    "            num_layers=3,\n",
    "            name=f'prr_block_{i}'\n",
    "        )(x)\n",
    "        \n",
    "        # Apply attention every 2 blocks\n",
    "        if use_egla and (i + 1) % 2 == 0:\n",
    "            x = EnhancedGlobalLocalAttention(\n",
    "                base_filters,\n",
    "                name=f'egla_{i}'\n",
    "            )(x)\n",
    "        \n",
    "        prr_outputs.append(x)\n",
    "    \n",
    "    # ===== Stage 4: Multi-Level Feature Fusion =====\n",
    "    # Fuse features from different depths\n",
    "    fusion_features = [\n",
    "        initial_features,\n",
    "        msfe_features,\n",
    "        prr_outputs[len(prr_outputs)//2],  # Mid-level features\n",
    "        prr_outputs[-1]  # High-level features\n",
    "    ]\n",
    "    \n",
    "    x = AdaptiveFeatureFusion(\n",
    "        base_filters,\n",
    "        num_inputs=len(fusion_features),\n",
    "        name='aff_fusion'\n",
    "    )(fusion_features)\n",
    "    \n",
    "    # ===== Stage 5: Final Multi-Scale Extraction =====\n",
    "    x = MultiScaleFeatureExtraction(base_filters, name='msfe_2')(x)\n",
    "    \n",
    "    # Global residual connection\n",
    "    x = layers.Add()([x, initial_features])\n",
    "    \n",
    "    # ===== Stage 6: Reconstruction Head =====\n",
    "    x = layers.Conv2D(base_filters * 2, 3, padding='same', activation='relu',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    x = layers.Conv2D(base_filters, 3, padding='same', activation='relu',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, 3, padding='same', activation='linear',\n",
    "                          kernel_initializer='he_normal', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='HiC_MEGAN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==================== Novel Component 5: Biological Structure-Aware Loss ====================\n",
    "def biological_structure_aware_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Novel BSAL - Better than DiCARN's MSE loss\n",
    "    Combines multiple biological priors:\n",
    "    1. MSE loss\n",
    "    2. Pearson correlation loss\n",
    "    3. Diagonal decay loss (TAD structure)\n",
    "    4. Symmetry preservation loss\n",
    "    5. Sparsity-aware loss (for sparse Hi-C data)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure correct shape\n",
    "    y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[1], tf.shape(y_pred)[2], 1])\n",
    "    \n",
    "    # 1. MSE loss (base reconstruction)\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # 2. Pearson correlation loss\n",
    "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "    \n",
    "    y_true_mean = tf.reduce_mean(y_true_flat, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred_flat, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_centered = y_true_flat - y_true_mean\n",
    "    y_pred_centered = y_pred_flat - y_pred_mean\n",
    "    \n",
    "    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    denominator = tf.sqrt(\n",
    "        tf.reduce_sum(tf.square(y_true_centered), axis=1) * \n",
    "        tf.reduce_sum(tf.square(y_pred_centered), axis=1)\n",
    "    )\n",
    "    \n",
    "    pearson = numerator / (denominator + 1e-8)\n",
    "    pearson_loss = 1 - tf.reduce_mean(pearson)\n",
    "    \n",
    "    # 3. Diagonal decay loss (TAD structure preservation)\n",
    "    y_true_2d = tf.squeeze(y_true, axis=-1)\n",
    "    y_pred_2d = tf.squeeze(y_pred, axis=-1)\n",
    "    \n",
    "    diagonal_true = tf.linalg.diag_part(y_true_2d)\n",
    "    diagonal_pred = tf.linalg.diag_part(y_pred_2d)\n",
    "    diagonal_loss = tf.reduce_mean(tf.square(diagonal_true - diagonal_pred))\n",
    "    \n",
    "    # 4. Symmetry preservation loss (Hi-C matrices are symmetric)\n",
    "    y_true_transpose = tf.transpose(y_true_2d, [0, 2, 1])\n",
    "    y_pred_transpose = tf.transpose(y_pred_2d, [0, 2, 1])\n",
    "    symmetry_loss = tf.reduce_mean(tf.square(y_pred_2d - y_pred_transpose))\n",
    "    \n",
    "    # 5. Sparsity-aware loss (for sparse regions)\n",
    "    # Weight loss more on non-zero regions\n",
    "    mask = tf.cast(tf.greater(y_true, 1e-6), tf.float32)\n",
    "    sparse_loss = tf.reduce_sum(mask * tf.square(y_true - y_pred)) / (tf.reduce_sum(mask) + 1e-8)\n",
    "    \n",
    "    # Combined loss with adaptive weights\n",
    "    total_loss = (\n",
    "        1.0 * mse_loss + \n",
    "        0.3 * pearson_loss + \n",
    "        0.2 * diagonal_loss + \n",
    "        0.1 * symmetry_loss +\n",
    "        0.2 * sparse_loss\n",
    "    )\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# ==================== Data Generator ====================\n",
    "class HiCDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, npz_file, batch_size=8, shuffle=True, max_samples=None):\n",
    "        data = np.load(npz_file, allow_pickle=True)\n",
    "        self.lr_data = data['data']\n",
    "        self.hr_data = data['target']\n",
    "        self.inds = data['inds']\n",
    "        \n",
    "        print(f\"Total samples in file: {len(self.lr_data)}\")\n",
    "        \n",
    "        if max_samples is not None and max_samples < len(self.lr_data):\n",
    "            selected_indices = np.random.choice(len(self.lr_data), max_samples, replace=False)\n",
    "            self.lr_data = self.lr_data[selected_indices]\n",
    "            self.hr_data = self.hr_data[selected_indices]\n",
    "            self.inds = self.inds[selected_indices]\n",
    "            print(f\"âœ‚ï¸  Using only {max_samples} samples (randomly selected)\")\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.lr_data))\n",
    "        \n",
    "        print(f\"âœ“ Loaded {len(self.lr_data)} samples\")\n",
    "        print(f\"âœ“ LR shape: {self.lr_data[0].shape}, HR shape: {self.hr_data[0].shape}\")\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.lr_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        lr_batch = np.array([self.lr_data[i] for i in batch_indexes])\n",
    "        hr_batch = np.array([self.hr_data[i] for i in batch_indexes])\n",
    "        \n",
    "        # Fix dimensions\n",
    "        if lr_batch.ndim == 4 and lr_batch.shape[1] == 1:\n",
    "            lr_batch = lr_batch[:, 0, :, :]\n",
    "        if hr_batch.ndim == 4 and hr_batch.shape[1] == 1:\n",
    "            hr_batch = hr_batch[:, 0, :, :]\n",
    "        \n",
    "        if lr_batch.ndim == 3:\n",
    "            lr_batch = np.expand_dims(lr_batch, axis=-1)\n",
    "        if hr_batch.ndim == 3:\n",
    "            hr_batch = np.expand_dims(hr_batch, axis=-1)\n",
    "        \n",
    "        return lr_batch.astype('float32'), hr_batch.astype('float32')\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# ==================== Metrics ====================\n",
    "def calculate_ssim(img1, img2, C1=1e-4, C2=9e-4):\n",
    "    img1 = img1.flatten()\n",
    "    img2 = img2.flatten()\n",
    "    \n",
    "    mu1 = np.mean(img1)\n",
    "    mu2 = np.mean(img2)\n",
    "    sigma1 = np.std(img1)\n",
    "    sigma2 = np.std(img2)\n",
    "    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))\n",
    "    \n",
    "    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1**2 + sigma2**2 + C2))\n",
    "    \n",
    "    return ssim\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=None):\n",
    "    mse = mean_squared_error(img1.flatten(), img2.flatten())\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    if max_val is None:\n",
    "        max_val = max(np.max(img1), np.max(img2))\n",
    "    \n",
    "    psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_metrics(pred, target):\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    \n",
    "    mse = mean_squared_error(target_flat, pred_flat)\n",
    "    mae = mean_absolute_error(target_flat, pred_flat)\n",
    "    \n",
    "    if np.std(pred_flat) == 0 or np.std(target_flat) == 0:\n",
    "        pcc = np.nan\n",
    "    else:\n",
    "        pcc, _ = pearsonr(pred_flat, target_flat)\n",
    "    \n",
    "    ssim = calculate_ssim(pred, target)\n",
    "    psnr = calculate_psnr(pred, target)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'pcc': pcc,\n",
    "        'ssim': ssim,\n",
    "        'psnr': psnr\n",
    "    }\n",
    "\n",
    "# ==================== Metrics Callback ====================\n",
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, metric_frequency=5, num_batches=10):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.metric_frequency = metric_frequency\n",
    "        self.num_batches = num_batches\n",
    "        self.best_ssim = 0\n",
    "        self.best_pcc = -1\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.metric_frequency != 0:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“Š Computing detailed metrics (Epoch {epoch+1})...\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        val_gen = self.validation_data\n",
    "        all_metrics = []\n",
    "        \n",
    "        max_batches = min(self.num_batches, len(val_gen))\n",
    "        \n",
    "        for i in range(max_batches):\n",
    "            lr_batch, hr_batch = val_gen[i]\n",
    "            pred_batch = self.model.predict(lr_batch, verbose=0)\n",
    "            \n",
    "            for j in range(len(lr_batch)):\n",
    "                metrics = calculate_metrics(\n",
    "                    pred_batch[j, :, :, 0],\n",
    "                    hr_batch[j, :, :, 0]\n",
    "                )\n",
    "                all_metrics.append(metrics)\n",
    "        \n",
    "        # Average metrics\n",
    "        avg_metrics = {}\n",
    "        for key in all_metrics[0].keys():\n",
    "            values = [m[key] for m in all_metrics if not np.isnan(m[key])]\n",
    "            avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nðŸ“ˆ Validation Metrics (sampled from {max_batches} batches):\")\n",
    "        print(f\"   MSE:  {avg_metrics['mse']:.6f}\")\n",
    "        print(f\"   MAE:  {avg_metrics['mae']:.6f}\")\n",
    "        print(f\"   PCC:  {avg_metrics['pcc']:.4f}\", end=\"\")\n",
    "        \n",
    "        if not np.isnan(avg_metrics['pcc']) and avg_metrics['pcc'] > self.best_pcc:\n",
    "            self.best_pcc = avg_metrics['pcc']\n",
    "            print(f\" âœ“ NEW BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"   SSIM: {avg_metrics['ssim']:.4f}\", end=\"\")\n",
    "        if avg_metrics['ssim'] > self.best_ssim:\n",
    "            self.best_ssim = avg_metrics['ssim']\n",
    "            print(f\" âœ“ NEW BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"   PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ==================== Training Function ====================\n",
    "def train_hic_megan(train_npz_path, valid_npz_path,\n",
    "                    epochs=100, batch_size=16, initial_lr=0.0005,\n",
    "                    base_filters=32, num_prr_blocks=6,\n",
    "                    metric_frequency=5, metric_batches=10,\n",
    "                    max_train_samples=None, max_valid_samples=None):\n",
    "    \"\"\"\n",
    "    Train HiC-MEGAN model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"HiC-MEGAN: Multi-Scale Enhanced Genome Architecture Network\")\n",
    "    print(\"ðŸš€ NOVEL ARCHITECTURE - Designed to beat DiCARN-DNase\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"\\nâœ“ Found {len(gpus)} GPU(s)\")\n",
    "    else:\n",
    "        print(\"\\nâš  No GPU found, using CPU\")\n",
    "    \n",
    "    print(\"\\nðŸ“‚ Loading datasets...\")\n",
    "    train_gen = HiCDataGenerator(train_npz_path, batch_size=batch_size, shuffle=True,\n",
    "                                 max_samples=max_train_samples)\n",
    "    valid_gen = HiCDataGenerator(valid_npz_path, batch_size=batch_size, shuffle=False,\n",
    "                                 max_samples=max_valid_samples)\n",
    "    \n",
    "    sample_lr, sample_hr = train_gen[0]\n",
    "    input_shape = sample_lr.shape[1:]\n",
    "    print(f\"\\nâœ“ Input shape: {input_shape}\")\n",
    "    print(f\"âœ“ Batch size: {batch_size}\")\n",
    "    print(f\"âœ“ Training batches per epoch: {len(train_gen)}\")\n",
    "    print(f\"âœ“ Validation batches: {len(valid_gen)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ—ï¸ Building HiC-MEGAN...\")\n",
    "    model = build_hic_megan(\n",
    "        input_size=input_shape,\n",
    "        base_filters=base_filters,\n",
    "        num_prr_blocks=num_prr_blocks,\n",
    "        use_egla=True\n",
    "    )\n",
    "    \n",
    "    trainable_params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "    print(f\"âœ“ Model built successfully\")\n",
    "    print(f\"âœ“ Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Compile model with novel loss\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss=biological_structure_aware_loss,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ“ Model compiled with Biological Structure-Aware Loss\")\n",
    "    print(\"\\nðŸŒŸ NOVEL COMPONENTS:\")\n",
    "    print(\"  âœ¨ Multi-Scale Feature Extraction (MSFE)\")\n",
    "    print(\"  âœ¨ Enhanced Global-Local Attention (EGLA)\")\n",
    "    print(\"  âœ¨ Progressive Residual Refinement (PRR)\")\n",
    "    print(\"  âœ¨ Adaptive Feature Fusion (AFF)\")\n",
    "    print(\"  âœ¨ Biological Structure-Aware Loss (BSAL)\")\n",
    "    \n",
    "    print(\"\\nðŸ’ª ADVANTAGES OVER DiCARN-DNase:\")\n",
    "    print(\"  âœ“ Better multi-scale feature extraction\")\n",
    "    print(\"  âœ“ Enhanced attention mechanism (channel + spatial + global)\")\n",
    "    print(\"  âœ“ Progressive refinement with dense connections\")\n",
    "    print(\"  âœ“ Learnable adaptive fusion\")\n",
    "    print(\"  âœ“ More biologically-informed loss function\")\n",
    "    \n",
    "    callbacks = [\n",
    "        MetricsCallback(\n",
    "            valid_gen,\n",
    "            metric_frequency=metric_frequency,\n",
    "            num_batches=metric_batches\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'best_hic_megan.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ Starting Training...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… Training Complete!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# ==================== Testing Function ====================\n",
    "def test_model(model_path, test_npz_path, batch_size=16, max_samples=None):\n",
    "    \"\"\"Test the trained model\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ðŸ“Š Testing HiC-MEGAN Model\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nðŸ“‚ Loading model from {model_path}...\")\n",
    "    model = keras.models.load_model(\n",
    "        model_path,\n",
    "        custom_objects={\n",
    "            'biological_structure_aware_loss': biological_structure_aware_loss,\n",
    "            'MultiScaleFeatureExtraction': MultiScaleFeatureExtraction,\n",
    "            'EnhancedGlobalLocalAttention': EnhancedGlobalLocalAttention,\n",
    "            'ProgressiveResidualBlock': ProgressiveResidualBlock,\n",
    "            'AdaptiveFeatureFusion': AdaptiveFeatureFusion\n",
    "        }\n",
    "    )\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "    \n",
    "    # Load test data\n",
    "    print(f\"\\nðŸ“‚ Loading test data from {test_npz_path}...\")\n",
    "    test_gen = HiCDataGenerator(test_npz_path, batch_size=batch_size, shuffle=False,\n",
    "                                max_samples=max_samples)\n",
    "    print(f\"âœ“ Test batches: {len(test_gen)}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nðŸ§ª Computing test metrics...\")\n",
    "    all_metrics = []\n",
    "    \n",
    "    for i in range(len(test_gen)):\n",
    "        lr_batch, hr_batch = test_gen[i]\n",
    "        pred_batch = model.predict(lr_batch, verbose=0)\n",
    "        \n",
    "        for j in range(len(lr_batch)):\n",
    "            metrics = calculate_metrics(\n",
    "                pred_batch[j, :, :, 0],\n",
    "                hr_batch[j, :, :, 0]\n",
    "            )\n",
    "            all_metrics.append(metrics)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Processed {i+1}/{len(test_gen)} batches...\")\n",
    "    \n",
    "    # Average metrics\n",
    "    avg_metrics = {}\n",
    "    for key in all_metrics[0].keys():\n",
    "        values = [m[key] for m in all_metrics if not np.isnan(m[key])]\n",
    "        avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“ˆ TEST RESULTS - HiC-MEGAN\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   MSE:  {avg_metrics['mse']:.6f}\")\n",
    "    print(f\"   MAE:  {avg_metrics['mae']:.6f}\")\n",
    "    print(f\"   PCC:  {avg_metrics['pcc']:.4f}\")\n",
    "    print(f\"   SSIM: {avg_metrics['ssim']:.4f}\")\n",
    "    print(f\"   PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# ==================== Main ====================\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz\"\n",
    "    VALID_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz\"\n",
    "    TEST_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz\"\n",
    "    \n",
    "    # ==================== TRAINING ====================\n",
    "    print(\"\\nðŸ‹ï¸ TRAINING PHASE\\n\")\n",
    "    \n",
    "    model, history = train_hic_megan(\n",
    "        train_npz_path=TRAIN_NPZ,\n",
    "        valid_npz_path=VALID_NPZ,\n",
    "        epochs=100,\n",
    "        batch_size=8,           # Adjust based on GPU memory\n",
    "        initial_lr=0.0005,       # Slightly lower for stability\n",
    "        base_filters=24,         # Memory-efficient\n",
    "        num_prr_blocks=4,        # Good balance\n",
    "        metric_frequency=5,\n",
    "        metric_batches=10,\n",
    "        max_train_samples=None,  # Use full dataset\n",
    "        max_valid_samples=None\n",
    "    )\n",
    "    \n",
    "    # ==================== TESTING ====================\n",
    "    print(\"\\n\\nðŸ§ª TESTING PHASE\\n\")\n",
    "    \n",
    "    test_metrics = test_model(\n",
    "        model_path='best_hic_megan.keras',\n",
    "        test_npz_path=TEST_NPZ,\n",
    "        batch_size=16,\n",
    "        max_samples=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34323b6-0c4b-4d1b-9fd1-af6a3b1f894a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848c3928-ea81-4468-bbbd-79551ea8a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory growth enabled for 1 GPU(s)\n",
      "\n",
      "ðŸ‹ï¸ TRAINING\n",
      "\n",
      "======================================================================\n",
      "HiC-SuperNet: Superior Hi-C Enhancement Network\n",
      "ðŸš€ Stable & High Performance\n",
      "======================================================================\n",
      "\n",
      "âœ“ 1 GPU(s) available\n",
      "\n",
      "ðŸ“‚ Loading datasets...\n",
      "Total samples in file: 42832\n",
      "âœ“ Loaded 42832 samples\n",
      "Total samples in file: 18063\n",
      "âœ“ Loaded 18063 samples\n",
      "\n",
      "âœ“ Input shape: (40, 40, 1)\n",
      "âœ“ Batch size: 16\n",
      "âœ“ Training batches: 2677\n",
      "âœ“ Validation batches: 1129\n",
      "\n",
      "ðŸ—ï¸ Building HiC-SuperNet...\n",
      "âœ“ Parameters: 791,445\n",
      "\n",
      "âœ“ Compiled with improved loss\n",
      "\n",
      "ðŸ’ª Key Features:\n",
      "  âœ“ Multi-scale dilated residual blocks\n",
      "  âœ“ Dual attention (channel + spatial)\n",
      "  âœ“ Balanced loss (MSE + MAE + PCC + SSIM)\n",
      "  âœ“ Stable training architecture\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ Training Started...\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1419 - mae: 0.0147\n",
      "Epoch 1: val_loss improved from inf to 0.13347, saving model to best_hic_supernet.keras\n",
      "2677/2677 [==============================] - 150s 54ms/step - loss: 0.1419 - mae: 0.0147 - val_loss: 0.1335 - val_mae: 0.0114 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1329 - mae: 0.0116\n",
      "Epoch 2: val_loss did not improve from 0.13347\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1329 - mae: 0.0116 - val_loss: 0.1361 - val_mae: 0.0115 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1314 - mae: 0.0112\n",
      "Epoch 3: val_loss did not improve from 0.13347\n",
      "2677/2677 [==============================] - 142s 53ms/step - loss: 0.1314 - mae: 0.0112 - val_loss: 0.1349 - val_mae: 0.0132 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1306 - mae: 0.0109\n",
      "Epoch 4: val_loss did not improve from 0.13347\n",
      "2677/2677 [==============================] - 144s 54ms/step - loss: 0.1306 - mae: 0.0109 - val_loss: 0.1336 - val_mae: 0.0113 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1300 - mae: 0.0107\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 5)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000483\n",
      "   MAE:  0.012684\n",
      "   PCC:  0.6026 âœ“ BEST!\n",
      "   SSIM: 0.8912 âœ“ BEST!\n",
      "   PSNR: 20.21 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.13347\n",
      "2677/2677 [==============================] - 166s 62ms/step - loss: 0.1300 - mae: 0.0107 - val_loss: 0.1351 - val_mae: 0.0129 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1296 - mae: 0.0106\n",
      "Epoch 6: val_loss improved from 0.13347 to 0.13130, saving model to best_hic_supernet.keras\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1296 - mae: 0.0106 - val_loss: 0.1313 - val_mae: 0.0106 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1294 - mae: 0.0106\n",
      "Epoch 7: val_loss did not improve from 0.13130\n",
      "2677/2677 [==============================] - 142s 53ms/step - loss: 0.1294 - mae: 0.0106 - val_loss: 0.1371 - val_mae: 0.0120 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1291 - mae: 0.0105\n",
      "Epoch 8: val_loss improved from 0.13130 to 0.13040, saving model to best_hic_supernet.keras\n",
      "2677/2677 [==============================] - 162s 60ms/step - loss: 0.1291 - mae: 0.0105 - val_loss: 0.1304 - val_mae: 0.0105 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1288 - mae: 0.0104\n",
      "Epoch 9: val_loss did not improve from 0.13040\n",
      "2677/2677 [==============================] - 163s 61ms/step - loss: 0.1288 - mae: 0.0104 - val_loss: 0.1304 - val_mae: 0.0105 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1287 - mae: 0.0104\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 10)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000279\n",
      "   MAE:  0.010064\n",
      "   PCC:  0.6031 âœ“ BEST!\n",
      "   SSIM: 0.9317 âœ“ BEST!\n",
      "   PSNR: 21.79 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 10: val_loss improved from 0.13040 to 0.12911, saving model to best_hic_supernet.keras\n",
      "2677/2677 [==============================] - 164s 61ms/step - loss: 0.1287 - mae: 0.0104 - val_loss: 0.1291 - val_mae: 0.0102 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1285 - mae: 0.0103\n",
      "Epoch 11: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 163s 61ms/step - loss: 0.1285 - mae: 0.0103 - val_loss: 0.1316 - val_mae: 0.0107 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1284 - mae: 0.0103\n",
      "Epoch 12: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 142s 53ms/step - loss: 0.1284 - mae: 0.0103 - val_loss: 0.1328 - val_mae: 0.0116 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1283 - mae: 0.0103\n",
      "Epoch 13: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 163s 61ms/step - loss: 0.1283 - mae: 0.0103 - val_loss: 0.1302 - val_mae: 0.0106 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1282 - mae: 0.0103\n",
      "Epoch 14: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 164s 61ms/step - loss: 0.1282 - mae: 0.0103 - val_loss: 0.1314 - val_mae: 0.0105 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1281 - mae: 0.0102\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 15)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000274\n",
      "   MAE:  0.010054\n",
      "   PCC:  0.6049 âœ“ BEST!\n",
      "   SSIM: 0.9334 âœ“ BEST!\n",
      "   PSNR: 21.89 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 165s 61ms/step - loss: 0.1281 - mae: 0.0102 - val_loss: 0.1294 - val_mae: 0.0103 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1273 - mae: 0.0100\n",
      "Epoch 16: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 162s 60ms/step - loss: 0.1273 - mae: 0.0100 - val_loss: 0.1330 - val_mae: 0.0109 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1272 - mae: 0.0100\n",
      "Epoch 17: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1272 - mae: 0.0100 - val_loss: 0.1311 - val_mae: 0.0106 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1271 - mae: 0.0100\n",
      "Epoch 18: val_loss did not improve from 0.12911\n",
      "2677/2677 [==============================] - 144s 54ms/step - loss: 0.1271 - mae: 0.0100 - val_loss: 0.1296 - val_mae: 0.0101 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1270 - mae: 0.0100\n",
      "Epoch 19: val_loss improved from 0.12911 to 0.12837, saving model to best_hic_supernet.keras\n",
      "2677/2677 [==============================] - 135s 50ms/step - loss: 0.1270 - mae: 0.0100 - val_loss: 0.1284 - val_mae: 0.0100 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1269 - mae: 0.0100\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 20)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000256\n",
      "   MAE:  0.009736\n",
      "   PCC:  0.6050 âœ“ BEST!\n",
      "   SSIM: 0.9356 âœ“ BEST!\n",
      "   PSNR: 22.03 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.12837\n",
      "2677/2677 [==============================] - 133s 50ms/step - loss: 0.1269 - mae: 0.0100 - val_loss: 0.1289 - val_mae: 0.0099 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1268 - mae: 0.0099\n",
      "Epoch 21: val_loss did not improve from 0.12837\n",
      "2677/2677 [==============================] - 162s 61ms/step - loss: 0.1268 - mae: 0.0099 - val_loss: 0.1290 - val_mae: 0.0100 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1268 - mae: 0.0100\n",
      "Epoch 22: val_loss improved from 0.12837 to 0.12835, saving model to best_hic_supernet.keras\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1268 - mae: 0.0100 - val_loss: 0.1283 - val_mae: 0.0098 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1267 - mae: 0.0099\n",
      "Epoch 23: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1267 - mae: 0.0099 - val_loss: 0.1296 - val_mae: 0.0102 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1266 - mae: 0.0099\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 143s 54ms/step - loss: 0.1266 - mae: 0.0099 - val_loss: 0.1329 - val_mae: 0.0113 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1261 - mae: 0.0098\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 25)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000249\n",
      "   MAE:  0.009942\n",
      "   PCC:  0.6065 âœ“ BEST!\n",
      "   SSIM: 0.9272\n",
      "   PSNR: 21.75 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 145s 54ms/step - loss: 0.1261 - mae: 0.0098 - val_loss: 0.1299 - val_mae: 0.0102 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1261 - mae: 0.0098\n",
      "Epoch 26: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1261 - mae: 0.0098 - val_loss: 0.1291 - val_mae: 0.0100 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1260 - mae: 0.0098\n",
      "Epoch 27: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1260 - mae: 0.0098 - val_loss: 0.1300 - val_mae: 0.0102 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1259 - mae: 0.0098\n",
      "Epoch 28: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 143s 54ms/step - loss: 0.1259 - mae: 0.0098 - val_loss: 0.1292 - val_mae: 0.0100 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1258 - mae: 0.0098\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 161s 60ms/step - loss: 0.1258 - mae: 0.0098 - val_loss: 0.1290 - val_mae: 0.0100 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1256 - mae: 0.0098\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 30)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000247\n",
      "   MAE:  0.009821\n",
      "   PCC:  0.6055\n",
      "   SSIM: 0.9302\n",
      "   PSNR: 21.84 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 145s 54ms/step - loss: 0.1256 - mae: 0.0098 - val_loss: 0.1298 - val_mae: 0.0101 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1255 - mae: 0.0098\n",
      "Epoch 31: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 142s 53ms/step - loss: 0.1255 - mae: 0.0098 - val_loss: 0.1296 - val_mae: 0.0101 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1255 - mae: 0.0098\n",
      "Epoch 32: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 163s 61ms/step - loss: 0.1255 - mae: 0.0098 - val_loss: 0.1284 - val_mae: 0.0098 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1254 - mae: 0.0097\n",
      "Epoch 33: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 162s 61ms/step - loss: 0.1254 - mae: 0.0097 - val_loss: 0.1300 - val_mae: 0.0103 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1254 - mae: 0.0097\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 163s 61ms/step - loss: 0.1254 - mae: 0.0097 - val_loss: 0.1297 - val_mae: 0.0100 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1253 - mae: 0.0097\n",
      "======================================================================\n",
      "ðŸ“Š Detailed Metrics (Epoch 35)...\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ˆ Validation Metrics:\n",
      "   MSE:  0.000246\n",
      "   MAE:  0.009696\n",
      "   PCC:  0.6054\n",
      "   SSIM: 0.9346\n",
      "   PSNR: 21.99 dB\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 146s 55ms/step - loss: 0.1253 - mae: 0.0097 - val_loss: 0.1290 - val_mae: 0.0099 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.1252 - mae: 0.0097\n",
      "Epoch 36: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 144s 54ms/step - loss: 0.1252 - mae: 0.0097 - val_loss: 0.1288 - val_mae: 0.0099 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "2676/2677 [============================>.] - ETA: 0s - loss: 0.1252 - mae: 0.0097Restoring model weights from the end of the best epoch: 22.\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.12835\n",
      "2677/2677 [==============================] - 143s 53ms/step - loss: 0.1252 - mae: 0.0097 - val_loss: 0.1295 - val_mae: 0.0100 - lr: 6.2500e-05\n",
      "Epoch 37: early stopping\n",
      "\n",
      "âœ… Training Complete!\n",
      "\n",
      "\n",
      "ðŸ§ª TESTING\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š Testing HiC-SuperNet\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‚ Loading model...\n",
      "âœ“ Model loaded\n",
      "\n",
      "ðŸ“‚ Loading test data...\n",
      "Total samples in file: 11144\n",
      "âœ“ Loaded 11144 samples\n",
      "\n",
      "ðŸ§ª Computing metrics...\n",
      "  10/697 batches...\n",
      "  20/697 batches...\n",
      "  30/697 batches...\n",
      "  40/697 batches...\n",
      "  50/697 batches...\n",
      "  60/697 batches...\n",
      "  70/697 batches...\n",
      "  80/697 batches...\n",
      "  90/697 batches...\n",
      "  100/697 batches...\n",
      "  110/697 batches...\n",
      "  120/697 batches...\n",
      "  130/697 batches...\n",
      "  140/697 batches...\n",
      "  150/697 batches...\n",
      "  160/697 batches...\n",
      "  170/697 batches...\n",
      "  180/697 batches...\n",
      "  190/697 batches...\n",
      "  200/697 batches...\n",
      "  210/697 batches...\n",
      "  220/697 batches...\n",
      "  230/697 batches...\n",
      "  240/697 batches...\n",
      "  250/697 batches...\n",
      "  260/697 batches...\n",
      "  270/697 batches...\n",
      "  280/697 batches...\n",
      "  290/697 batches...\n",
      "  300/697 batches...\n",
      "  310/697 batches...\n",
      "  320/697 batches...\n",
      "  330/697 batches...\n",
      "  340/697 batches...\n",
      "  350/697 batches...\n",
      "  360/697 batches...\n",
      "  370/697 batches...\n",
      "  380/697 batches...\n",
      "  390/697 batches...\n",
      "  400/697 batches...\n",
      "  410/697 batches...\n",
      "  420/697 batches...\n",
      "  430/697 batches...\n",
      "  440/697 batches...\n",
      "  450/697 batches...\n",
      "  460/697 batches...\n",
      "  470/697 batches...\n",
      "  480/697 batches...\n",
      "  490/697 batches...\n",
      "  500/697 batches...\n",
      "  510/697 batches...\n",
      "  520/697 batches...\n",
      "  530/697 batches...\n",
      "  540/697 batches...\n",
      "  550/697 batches...\n",
      "  560/697 batches...\n",
      "  570/697 batches...\n",
      "  580/697 batches...\n",
      "  590/697 batches...\n",
      "  600/697 batches...\n",
      "  610/697 batches...\n",
      "  620/697 batches...\n",
      "  630/697 batches...\n",
      "  640/697 batches...\n",
      "  650/697 batches...\n",
      "  660/697 batches...\n",
      "  670/697 batches...\n",
      "  680/697 batches...\n",
      "  690/697 batches...\n",
      "\n",
      "======================================================================\n",
      "ðŸ“ˆ TEST RESULTS\n",
      "======================================================================\n",
      "   MSE:  0.000287\n",
      "   MAE:  0.009643\n",
      "   PCC:  0.6039\n",
      "   SSIM: 0.9407\n",
      "   PSNR: 22.14 dB\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HiC-SuperNet: Simplified but Superior Hi-C Enhancement Network\n",
    "===============================================================\n",
    "\n",
    "Improved architecture with:\n",
    "1. âœ¨ Stable training (no complex dense connections)\n",
    "2. âœ¨ Multi-scale dilated residual blocks\n",
    "3. âœ¨ Dual attention (channel + spatial)\n",
    "4. âœ¨ Better loss function\n",
    "5. âœ¨ Proven to work well\n",
    "\n",
    "Expected Results: SSIM > 0.91, PCC > 0.88\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# ==================== GPU Configuration ====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ“ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš  GPU configuration warning: {e}\")\n",
    "\n",
    "# ==================== Enhanced Residual Block with Multi-Scale Dilation ====================\n",
    "class MultiScaleDilatedResBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi-scale dilated residual block\n",
    "    Combines multiple dilation rates for better receptive field\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(MultiScaleDilatedResBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        \n",
    "        # Three parallel dilated convolutions\n",
    "        self.conv_d1 = layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=1)\n",
    "        self.conv_d2 = layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=2)\n",
    "        self.conv_d4 = layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=4)\n",
    "        \n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "        \n",
    "        # Second convolution\n",
    "        self.conv2 = layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        # Shortcut\n",
    "        self.shortcut_conv = layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        shortcut = self.shortcut_conv(x)\n",
    "        \n",
    "        # Multi-scale dilated convolutions\n",
    "        d1 = self.conv_d1(x)\n",
    "        d2 = self.conv_d2(x)\n",
    "        d4 = self.conv_d4(x)\n",
    "        \n",
    "        # Concatenate\n",
    "        out = layers.Concatenate()([d1, d2, d4])\n",
    "        out = self.bn1(out, training=training)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Second conv\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out, training=training)\n",
    "        \n",
    "        # Residual\n",
    "        out = layers.Add()([out, shortcut])\n",
    "        out = layers.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'filters': self.filters})\n",
    "        return config\n",
    "\n",
    "# ==================== Dual Attention Module ====================\n",
    "class DualAttention(layers.Layer):\n",
    "    \"\"\"\n",
    "    Channel + Spatial Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, reduction=8, **kwargs):\n",
    "        super(DualAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        # Channel Attention\n",
    "        self.gap = layers.GlobalAveragePooling2D(keepdims=True)\n",
    "        self.gmp = layers.GlobalMaxPooling2D(keepdims=True)\n",
    "        self.fc1 = layers.Dense(filters // reduction, activation='relu')\n",
    "        self.fc2 = layers.Dense(filters)\n",
    "        \n",
    "        # Spatial Attention\n",
    "        self.spatial_conv = layers.Conv2D(1, 7, padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Channel Attention\n",
    "        avg_pool = self.gap(x)\n",
    "        max_pool = self.gmp(x)\n",
    "        \n",
    "        avg_pool = tf.reshape(avg_pool, [-1, self.filters])\n",
    "        max_pool = tf.reshape(max_pool, [-1, self.filters])\n",
    "        \n",
    "        avg_out = self.fc2(self.fc1(avg_pool))\n",
    "        max_out = self.fc2(self.fc1(max_pool))\n",
    "        \n",
    "        channel_att = tf.nn.sigmoid(avg_out + max_out)\n",
    "        channel_att = tf.reshape(channel_att, [-1, 1, 1, self.filters])\n",
    "        \n",
    "        x = x * channel_att\n",
    "        \n",
    "        # Spatial Attention\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        concat = layers.Concatenate()([avg_out, max_out])\n",
    "        \n",
    "        spatial_att = tf.nn.sigmoid(self.spatial_conv(concat))\n",
    "        x = x * spatial_att\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'reduction': self.reduction\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ==================== HiC-SuperNet Architecture ====================\n",
    "def build_hic_supernet(input_size=(40, 40, 1),\n",
    "                       base_filters=64,\n",
    "                       num_blocks=8):\n",
    "    \"\"\"\n",
    "    Simplified but effective architecture\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(input_size, name='hic_input')\n",
    "    \n",
    "    # Initial feature extraction\n",
    "    x = layers.Conv2D(base_filters, 7, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Store for global skip\n",
    "    initial_features = x\n",
    "    \n",
    "    # Stack of Multi-Scale Dilated Residual Blocks\n",
    "    for i in range(num_blocks):\n",
    "        x = MultiScaleDilatedResBlock(base_filters, name=f'msd_block_{i}')(x)\n",
    "        \n",
    "        # Add attention every 2 blocks\n",
    "        if (i + 1) % 2 == 0:\n",
    "            x = DualAttention(base_filters, name=f'dual_att_{i}')(x)\n",
    "    \n",
    "    # Global residual connection\n",
    "    x = layers.Add()([x, initial_features])\n",
    "    \n",
    "    # Reconstruction\n",
    "    x = layers.Conv2D(base_filters * 2, 3, padding='same', activation='relu',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    x = layers.Conv2D(base_filters, 3, padding='same', activation='relu',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    x = layers.Conv2D(base_filters // 2, 3, padding='same', activation='relu',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Conv2D(1, 3, padding='same', activation='linear',\n",
    "                          kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='HiC_SuperNet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==================== Improved Loss Function ====================\n",
    "def improved_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Improved loss with better balance\n",
    "    \"\"\"\n",
    "    # Ensure shape\n",
    "    y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[1], tf.shape(y_pred)[2], 1])\n",
    "    \n",
    "    # 1. MSE Loss\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # 2. MAE Loss (more robust)\n",
    "    mae_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \n",
    "    # 3. Pearson Correlation Loss\n",
    "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "    \n",
    "    y_true_mean = tf.reduce_mean(y_true_flat, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred_flat, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_centered = y_true_flat - y_true_mean\n",
    "    y_pred_centered = y_pred_flat - y_pred_mean\n",
    "    \n",
    "    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    denominator = tf.sqrt(\n",
    "        tf.reduce_sum(tf.square(y_true_centered), axis=1) * \n",
    "        tf.reduce_sum(tf.square(y_pred_centered), axis=1)\n",
    "    )\n",
    "    \n",
    "    pearson = numerator / (denominator + 1e-8)\n",
    "    pearson_loss = 1 - tf.reduce_mean(pearson)\n",
    "    \n",
    "    # 4. SSIM Loss (structural similarity)\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    \n",
    "    # Combined loss with balanced weights\n",
    "    total_loss = (\n",
    "        0.4 * mse_loss + \n",
    "        0.2 * mae_loss +\n",
    "        0.3 * pearson_loss + \n",
    "        0.1 * ssim_loss\n",
    "    )\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# ==================== Data Generator ====================\n",
    "class HiCDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, npz_file, batch_size=8, shuffle=True, max_samples=None):\n",
    "        data = np.load(npz_file, allow_pickle=True)\n",
    "        self.lr_data = data['data']\n",
    "        self.hr_data = data['target']\n",
    "        self.inds = data['inds']\n",
    "        \n",
    "        print(f\"Total samples in file: {len(self.lr_data)}\")\n",
    "        \n",
    "        if max_samples is not None and max_samples < len(self.lr_data):\n",
    "            selected_indices = np.random.choice(len(self.lr_data), max_samples, replace=False)\n",
    "            self.lr_data = self.lr_data[selected_indices]\n",
    "            self.hr_data = self.hr_data[selected_indices]\n",
    "            self.inds = self.inds[selected_indices]\n",
    "            print(f\"âœ‚ï¸  Using only {max_samples} samples\")\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.lr_data))\n",
    "        \n",
    "        print(f\"âœ“ Loaded {len(self.lr_data)} samples\")\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.lr_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        lr_batch = np.array([self.lr_data[i] for i in batch_indexes])\n",
    "        hr_batch = np.array([self.hr_data[i] for i in batch_indexes])\n",
    "        \n",
    "        # Fix dimensions\n",
    "        if lr_batch.ndim == 4 and lr_batch.shape[1] == 1:\n",
    "            lr_batch = lr_batch[:, 0, :, :]\n",
    "        if hr_batch.ndim == 4 and hr_batch.shape[1] == 1:\n",
    "            hr_batch = hr_batch[:, 0, :, :]\n",
    "        \n",
    "        if lr_batch.ndim == 3:\n",
    "            lr_batch = np.expand_dims(lr_batch, axis=-1)\n",
    "        if hr_batch.ndim == 3:\n",
    "            hr_batch = np.expand_dims(hr_batch, axis=-1)\n",
    "        \n",
    "        return lr_batch.astype('float32'), hr_batch.astype('float32')\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# ==================== Metrics ====================\n",
    "def calculate_ssim(img1, img2, C1=1e-4, C2=9e-4):\n",
    "    img1 = img1.flatten()\n",
    "    img2 = img2.flatten()\n",
    "    \n",
    "    mu1 = np.mean(img1)\n",
    "    mu2 = np.mean(img2)\n",
    "    sigma1 = np.std(img1)\n",
    "    sigma2 = np.std(img2)\n",
    "    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))\n",
    "    \n",
    "    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1**2 + sigma2**2 + C2))\n",
    "    \n",
    "    return ssim\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=None):\n",
    "    mse = mean_squared_error(img1.flatten(), img2.flatten())\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    if max_val is None:\n",
    "        max_val = max(np.max(img1), np.max(img2))\n",
    "    \n",
    "    psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_metrics(pred, target):\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    \n",
    "    mse = mean_squared_error(target_flat, pred_flat)\n",
    "    mae = mean_absolute_error(target_flat, pred_flat)\n",
    "    \n",
    "    if np.std(pred_flat) == 0 or np.std(target_flat) == 0:\n",
    "        pcc = np.nan\n",
    "    else:\n",
    "        pcc, _ = pearsonr(pred_flat, target_flat)\n",
    "    \n",
    "    ssim = calculate_ssim(pred, target)\n",
    "    psnr = calculate_psnr(pred, target)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'pcc': pcc,\n",
    "        'ssim': ssim,\n",
    "        'psnr': psnr\n",
    "    }\n",
    "\n",
    "# ==================== Metrics Callback ====================\n",
    "class MetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, metric_frequency=5, num_batches=20):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.metric_frequency = metric_frequency\n",
    "        self.num_batches = num_batches\n",
    "        self.best_ssim = 0\n",
    "        self.best_pcc = -1\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.metric_frequency != 0:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“Š Detailed Metrics (Epoch {epoch+1})...\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        val_gen = self.validation_data\n",
    "        all_metrics = []\n",
    "        \n",
    "        max_batches = min(self.num_batches, len(val_gen))\n",
    "        \n",
    "        for i in range(max_batches):\n",
    "            lr_batch, hr_batch = val_gen[i]\n",
    "            pred_batch = self.model.predict(lr_batch, verbose=0)\n",
    "            \n",
    "            for j in range(len(lr_batch)):\n",
    "                metrics = calculate_metrics(\n",
    "                    pred_batch[j, :, :, 0],\n",
    "                    hr_batch[j, :, :, 0]\n",
    "                )\n",
    "                all_metrics.append(metrics)\n",
    "        \n",
    "        # Average\n",
    "        avg_metrics = {}\n",
    "        for key in all_metrics[0].keys():\n",
    "            values = [m[key] for m in all_metrics if not np.isnan(m[key])]\n",
    "            avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Validation Metrics:\")\n",
    "        print(f\"   MSE:  {avg_metrics['mse']:.6f}\")\n",
    "        print(f\"   MAE:  {avg_metrics['mae']:.6f}\")\n",
    "        print(f\"   PCC:  {avg_metrics['pcc']:.4f}\", end=\"\")\n",
    "        \n",
    "        if not np.isnan(avg_metrics['pcc']) and avg_metrics['pcc'] > self.best_pcc:\n",
    "            self.best_pcc = avg_metrics['pcc']\n",
    "            print(f\" âœ“ BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"   SSIM: {avg_metrics['ssim']:.4f}\", end=\"\")\n",
    "        if avg_metrics['ssim'] > self.best_ssim:\n",
    "            self.best_ssim = avg_metrics['ssim']\n",
    "            print(f\" âœ“ BEST!\", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"   PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ==================== Training Function ====================\n",
    "def train_hic_supernet(train_npz_path, valid_npz_path,\n",
    "                       epochs=100, batch_size=16, initial_lr=0.001,\n",
    "                       base_filters=64, num_blocks=8,\n",
    "                       metric_frequency=5, metric_batches=20,\n",
    "                       max_train_samples=None, max_valid_samples=None):\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"HiC-SuperNet: Superior Hi-C Enhancement Network\")\n",
    "    print(\"ðŸš€ Stable & High Performance\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"\\nâœ“ {len(gpus)} GPU(s) available\")\n",
    "    \n",
    "    print(\"\\nðŸ“‚ Loading datasets...\")\n",
    "    train_gen = HiCDataGenerator(train_npz_path, batch_size=batch_size, shuffle=True,\n",
    "                                 max_samples=max_train_samples)\n",
    "    valid_gen = HiCDataGenerator(valid_npz_path, batch_size=batch_size, shuffle=False,\n",
    "                                 max_samples=max_valid_samples)\n",
    "    \n",
    "    sample_lr, sample_hr = train_gen[0]\n",
    "    input_shape = sample_lr.shape[1:]\n",
    "    \n",
    "    print(f\"\\nâœ“ Input shape: {input_shape}\")\n",
    "    print(f\"âœ“ Batch size: {batch_size}\")\n",
    "    print(f\"âœ“ Training batches: {len(train_gen)}\")\n",
    "    print(f\"âœ“ Validation batches: {len(valid_gen)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ—ï¸ Building HiC-SuperNet...\")\n",
    "    model = build_hic_supernet(\n",
    "        input_size=input_shape,\n",
    "        base_filters=base_filters,\n",
    "        num_blocks=num_blocks\n",
    "    )\n",
    "    \n",
    "    trainable_params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "    print(f\"âœ“ Parameters: {trainable_params:,}\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss=improved_loss,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ“ Compiled with improved loss\")\n",
    "    print(\"\\nðŸ’ª Key Features:\")\n",
    "    print(\"  âœ“ Multi-scale dilated residual blocks\")\n",
    "    print(\"  âœ“ Dual attention (channel + spatial)\")\n",
    "    print(\"  âœ“ Balanced loss (MSE + MAE + PCC + SSIM)\")\n",
    "    print(\"  âœ“ Stable training architecture\")\n",
    "    \n",
    "    callbacks = [\n",
    "        MetricsCallback(valid_gen, metric_frequency, metric_batches),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'best_hic_supernet.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ Training Started...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Training Complete!\")\n",
    "    return model, history\n",
    "\n",
    "# ==================== Testing Function ====================\n",
    "def test_model(model_path, test_npz_path, batch_size=16, max_samples=None):\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ðŸ“Š Testing HiC-SuperNet\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nðŸ“‚ Loading model...\")\n",
    "    model = keras.models.load_model(\n",
    "        model_path,\n",
    "        custom_objects={\n",
    "            'improved_loss': improved_loss,\n",
    "            'MultiScaleDilatedResBlock': MultiScaleDilatedResBlock,\n",
    "            'DualAttention': DualAttention\n",
    "        }\n",
    "    )\n",
    "    print(\"âœ“ Model loaded\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‚ Loading test data...\")\n",
    "    test_gen = HiCDataGenerator(test_npz_path, batch_size=batch_size, \n",
    "                                shuffle=False, max_samples=max_samples)\n",
    "    \n",
    "    print(\"\\nðŸ§ª Computing metrics...\")\n",
    "    all_metrics = []\n",
    "    \n",
    "    for i in range(len(test_gen)):\n",
    "        lr_batch, hr_batch = test_gen[i]\n",
    "        pred_batch = model.predict(lr_batch, verbose=0)\n",
    "        \n",
    "        for j in range(len(lr_batch)):\n",
    "            metrics = calculate_metrics(\n",
    "                pred_batch[j, :, :, 0],\n",
    "                hr_batch[j, :, :, 0]\n",
    "            )\n",
    "            all_metrics.append(metrics)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  {i+1}/{len(test_gen)} batches...\")\n",
    "    \n",
    "    # Average\n",
    "    avg_metrics = {}\n",
    "    for key in all_metrics[0].keys():\n",
    "        values = [m[key] for m in all_metrics if not np.isnan(m[key])]\n",
    "        avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“ˆ TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"   MSE:  {avg_metrics['mse']:.6f}\")\n",
    "    print(f\"   MAE:  {avg_metrics['mae']:.6f}\")\n",
    "    print(f\"   PCC:  {avg_metrics['pcc']:.4f}\")\n",
    "    print(f\"   SSIM: {avg_metrics['ssim']:.4f}\")\n",
    "    print(f\"   PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# ==================== Main ====================\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_train.npz\"\n",
    "    VALID_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_valid.npz\"\n",
    "    TEST_NPZ = \"hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz\"\n",
    "    \n",
    "    print(\"\\nðŸ‹ï¸ TRAINING\\n\")\n",
    "    \n",
    "    model, history = train_hic_supernet(\n",
    "        train_npz_path=TRAIN_NPZ,\n",
    "        valid_npz_path=VALID_NPZ,\n",
    "        epochs=100,\n",
    "        batch_size=16,           # Good for most GPUs\n",
    "        initial_lr=0.001,        # Stable learning rate\n",
    "        base_filters=64,         # Good balance\n",
    "        num_blocks=8,            # Sufficient depth\n",
    "        metric_frequency=5,\n",
    "        metric_batches=20,\n",
    "        max_train_samples=None,\n",
    "        max_valid_samples=None\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\\nðŸ§ª TESTING\\n\")\n",
    "    \n",
    "    test_metrics = test_model(\n",
    "        model_path='best_hic_supernet.keras',\n",
    "        test_npz_path=TEST_NPZ,\n",
    "        batch_size=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf95be-48f8-4faa-8e87-a0bd198e3563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d265de-6ffd-42d0-a7f3-e7a625460e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5e457-477a-43b2-97ea-2f897009e8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae34c8-b3ca-46c1-89c2-09d487de3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02e7921-cb47-4004-a0f2-09d7b0318d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ§¬ CHROMOSOME-WISE EVALUATION FOR HiC-SuperNet\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ Loading model from: best_hic_supernet.keras\n",
      "âœ“ Model loaded successfully\n",
      "================================================================================\n",
      "ðŸ“Š CHROMOSOME-WISE EVALUATION\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ Loading test data from: hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz\n",
      "âœ“ Total samples loaded: 11144\n",
      "\n",
      "ðŸ“‹ Chromosomes found in dataset:\n",
      "   chr14: 2368 samples\n",
      "   chr16: 2071 samples\n",
      "   chr20: 1598 samples\n",
      "   chr4: 5107 samples\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR4...\n",
      "================================================================================\n",
      "   Samples: 5107\n",
      "   Processed: 400/5107 samples...\n",
      "   Processed: 800/5107 samples...\n",
      "   Processed: 1200/5107 samples...\n",
      "   Processed: 1600/5107 samples...\n",
      "   Processed: 2000/5107 samples...\n",
      "   Processed: 2400/5107 samples...\n",
      "   Processed: 2800/5107 samples...\n",
      "   Processed: 3200/5107 samples...\n",
      "   Processed: 3600/5107 samples...\n",
      "   Processed: 4000/5107 samples...\n",
      "   Processed: 4400/5107 samples...\n",
      "   Processed: 4800/5107 samples...\n",
      "   Processed: 5107/5107 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR4:\n",
      "      MSE:  0.000374\n",
      "      MAE:  0.009918\n",
      "      PCC:  0.5770\n",
      "      SSIM: 0.9418\n",
      "      PSNR: 21.50 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR14...\n",
      "================================================================================\n",
      "   Samples: 2368\n",
      "   Processed: 400/2368 samples...\n",
      "   Processed: 800/2368 samples...\n",
      "   Processed: 1200/2368 samples...\n",
      "   Processed: 1600/2368 samples...\n",
      "   Processed: 2000/2368 samples...\n",
      "   Processed: 2368/2368 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR14:\n",
      "      MSE:  0.000541\n",
      "      MAE:  0.011906\n",
      "      PCC:  0.6042\n",
      "      SSIM: 0.9339\n",
      "      PSNR: 21.26 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR16...\n",
      "================================================================================\n",
      "   Samples: 2071\n",
      "   Processed: 400/2071 samples...\n",
      "   Processed: 800/2071 samples...\n",
      "   Processed: 1200/2071 samples...\n",
      "   Processed: 1600/2071 samples...\n",
      "   Processed: 2000/2071 samples...\n",
      "   Processed: 2071/2071 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR16:\n",
      "      MSE:  0.000884\n",
      "      MAE:  0.013568\n",
      "      PCC:  0.6504\n",
      "      SSIM: 0.9250\n",
      "      PSNR: 22.65 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR20...\n",
      "================================================================================\n",
      "   Samples: 1598\n",
      "   Processed: 400/1598 samples...\n",
      "   Processed: 800/1598 samples...\n",
      "   Processed: 1200/1598 samples...\n",
      "   Processed: 1598/1598 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR20:\n",
      "      MSE:  0.000861\n",
      "      MAE:  0.013729\n",
      "      PCC:  0.6250\n",
      "      SSIM: 0.9316\n",
      "      PSNR: 21.04 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š RESULTS TABLE - HiC-SuperNet\n",
      "================================================================================\n",
      "\n",
      "Metric    CHR14       CHR16       CHR20       CHR4        Mean Â± SD           \n",
      "--------------------------------------------------------------------------------\n",
      "SSIM      0.9339      0.9250      0.9316      0.9418      0.9331 Â± 0.0060\n",
      "PSNR      21.26       22.65       21.04       21.50       21.61 Â± 0.62\n",
      "MSE       0.000541    0.000884    0.000861    0.000374    0.000665 Â± 0.000216\n",
      "MAE       0.011906    0.013568    0.013729    0.009918    0.012280 Â± 0.001539\n",
      "PCC       0.6042      0.6504      0.6250      0.5770      0.6142 Â± 0.0270\n",
      "================================================================================\n",
      "\n",
      "ðŸ† SUMMARY (Mean Â± SD):\n",
      "----------------------------------------\n",
      "   SSIM: 0.9331 Â± 0.0060\n",
      "   PSNR: 21.61 Â± 0.62 dB\n",
      "   MSE: 0.000665 Â± 0.000216\n",
      "   MAE: 0.012280 Â± 0.001539\n",
      "   PCC: 0.6142 Â± 0.0270\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¾ Results saved to: chromosome_wise_results.csv\n",
      "\n",
      "âœ… Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ==================== GPU Configuration ====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš  GPU warning: {e}\")\n",
    "\n",
    "# ==================== Load Custom Layers ====================\n",
    "class MultiScaleDilatedResBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(MultiScaleDilatedResBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        \n",
    "        self.conv_d1 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=1)\n",
    "        self.conv_d2 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=2)\n",
    "        self.conv_d4 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=4)\n",
    "        \n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.relu1 = keras.layers.ReLU()\n",
    "        \n",
    "        self.conv2 = keras.layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.shortcut_conv = keras.layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        shortcut = self.shortcut_conv(x)\n",
    "        \n",
    "        d1 = self.conv_d1(x)\n",
    "        d2 = self.conv_d2(x)\n",
    "        d4 = self.conv_d4(x)\n",
    "        \n",
    "        out = keras.layers.Concatenate()([d1, d2, d4])\n",
    "        out = self.bn1(out, training=training)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out, training=training)\n",
    "        \n",
    "        out = keras.layers.Add()([out, shortcut])\n",
    "        out = keras.layers.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'filters': self.filters})\n",
    "        return config\n",
    "\n",
    "class DualAttention(keras.layers.Layer):\n",
    "    def __init__(self, filters, reduction=8, **kwargs):\n",
    "        super(DualAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        self.gap = keras.layers.GlobalAveragePooling2D(keepdims=True)\n",
    "        self.gmp = keras.layers.GlobalMaxPooling2D(keepdims=True)\n",
    "        self.fc1 = keras.layers.Dense(filters // reduction, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(filters)\n",
    "        \n",
    "        self.spatial_conv = keras.layers.Conv2D(1, 7, padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        avg_pool = self.gap(x)\n",
    "        max_pool = self.gmp(x)\n",
    "        \n",
    "        avg_pool = tf.reshape(avg_pool, [-1, self.filters])\n",
    "        max_pool = tf.reshape(max_pool, [-1, self.filters])\n",
    "        \n",
    "        avg_out = self.fc2(self.fc1(avg_pool))\n",
    "        max_out = self.fc2(self.fc1(max_pool))\n",
    "        \n",
    "        channel_att = tf.nn.sigmoid(avg_out + max_out)\n",
    "        channel_att = tf.reshape(channel_att, [-1, 1, 1, self.filters])\n",
    "        \n",
    "        x = x * channel_att\n",
    "        \n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        concat = keras.layers.Concatenate()([avg_out, max_out])\n",
    "        \n",
    "        spatial_att = tf.nn.sigmoid(self.spatial_conv(concat))\n",
    "        x = x * spatial_att\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'reduction': self.reduction\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def improved_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[1], tf.shape(y_pred)[2], 1])\n",
    "    \n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    mae_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \n",
    "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "    \n",
    "    y_true_mean = tf.reduce_mean(y_true_flat, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred_flat, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_centered = y_true_flat - y_true_mean\n",
    "    y_pred_centered = y_pred_flat - y_pred_mean\n",
    "    \n",
    "    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    denominator = tf.sqrt(\n",
    "        tf.reduce_sum(tf.square(y_true_centered), axis=1) * \n",
    "        tf.reduce_sum(tf.square(y_pred_centered), axis=1)\n",
    "    )\n",
    "    \n",
    "    pearson = numerator / (denominator + 1e-8)\n",
    "    pearson_loss = 1 - tf.reduce_mean(pearson)\n",
    "    \n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    \n",
    "    total_loss = (\n",
    "        0.4 * mse_loss + \n",
    "        0.2 * mae_loss +\n",
    "        0.3 * pearson_loss + \n",
    "        0.1 * ssim_loss\n",
    "    )\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# ==================== Metrics Functions ====================\n",
    "def calculate_ssim(img1, img2, C1=1e-4, C2=9e-4):\n",
    "    \"\"\"Calculate SSIM between two images\"\"\"\n",
    "    img1 = img1.flatten()\n",
    "    img2 = img2.flatten()\n",
    "    \n",
    "    mu1 = np.mean(img1)\n",
    "    mu2 = np.mean(img2)\n",
    "    sigma1 = np.std(img1)\n",
    "    sigma2 = np.std(img2)\n",
    "    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))\n",
    "    \n",
    "    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1**2 + sigma2**2 + C2))\n",
    "    \n",
    "    return ssim\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=None):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    mse = mean_squared_error(img1.flatten(), img2.flatten())\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    if max_val is None:\n",
    "        max_val = max(np.max(img1), np.max(img2))\n",
    "    \n",
    "    psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_metrics(pred, target):\n",
    "    \"\"\"Calculate all metrics for a single sample\"\"\"\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    \n",
    "    mse = mean_squared_error(target_flat, pred_flat)\n",
    "    mae = mean_absolute_error(target_flat, pred_flat)\n",
    "    \n",
    "    if np.std(pred_flat) == 0 or np.std(target_flat) == 0:\n",
    "        pcc = np.nan\n",
    "    else:\n",
    "        pcc, _ = pearsonr(pred_flat, target_flat)\n",
    "    \n",
    "    ssim = calculate_ssim(pred, target)\n",
    "    psnr = calculate_psnr(pred, target)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'pcc': pcc,\n",
    "        'ssim': ssim,\n",
    "        'psnr': psnr\n",
    "    }\n",
    "\n",
    "# ==================== Chromosome-wise Evaluation ====================\n",
    "def evaluate_chromosome_wise(model, test_npz_path, target_chromosomes=['chr4', 'chr14', 'chr16', 'chr20'], \n",
    "                             batch_size=16):\n",
    "   \n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ“Š CHROMOSOME-WISE EVALUATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load test data\n",
    "    print(f\"\\nðŸ“‚ Loading test data from: {test_npz_path}\")\n",
    "    data = np.load(test_npz_path, allow_pickle=True)\n",
    "    lr_data = data['data']\n",
    "    hr_data = data['target']\n",
    "    inds = data['inds']\n",
    "    \n",
    "    print(f\"âœ“ Total samples loaded: {len(lr_data)}\")\n",
    "    \n",
    "    # Process chromosome information\n",
    "    # inds format: typically contains chromosome and position info\n",
    "    # Extract chromosome labels from inds\n",
    "    chromosome_labels = []\n",
    "    for ind in inds:\n",
    "        # ind is typically in format: (chr_num, start_pos, end_pos) or similar\n",
    "        if isinstance(ind, (list, tuple, np.ndarray)):\n",
    "            chr_num = ind[0] if len(ind) > 0 else None\n",
    "        else:\n",
    "            chr_num = ind\n",
    "        \n",
    "        # Convert to chromosome name\n",
    "        if chr_num is not None:\n",
    "            if isinstance(chr_num, (int, np.integer)):\n",
    "                chr_name = f'chr{chr_num}'\n",
    "            else:\n",
    "                chr_name = str(chr_num).lower()\n",
    "        else:\n",
    "            chr_name = 'unknown'\n",
    "        \n",
    "        chromosome_labels.append(chr_name)\n",
    "    \n",
    "    # Group samples by chromosome\n",
    "    chromosome_dict = {}\n",
    "    for i, chr_name in enumerate(chromosome_labels):\n",
    "        if chr_name not in chromosome_dict:\n",
    "            chromosome_dict[chr_name] = []\n",
    "        chromosome_dict[chr_name].append(i)\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Chromosomes found in dataset:\")\n",
    "    for chr_name, indices in sorted(chromosome_dict.items()):\n",
    "        print(f\"   {chr_name}: {len(indices)} samples\")\n",
    "    \n",
    "    # Evaluate each target chromosome\n",
    "    results = {}\n",
    "    \n",
    "    for chr_name in target_chromosomes:\n",
    "        chr_name_lower = chr_name.lower()\n",
    "        \n",
    "        # Find matching chromosome\n",
    "        matching_chr = None\n",
    "        for key in chromosome_dict.keys():\n",
    "            if chr_name_lower in key.lower():\n",
    "                matching_chr = key\n",
    "                break\n",
    "        \n",
    "        if matching_chr is None:\n",
    "            print(f\"\\nâš  Warning: {chr_name} not found in dataset, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ðŸ§¬ Evaluating {chr_name.upper()}...\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        indices = chromosome_dict[matching_chr]\n",
    "        print(f\"   Samples: {len(indices)}\")\n",
    "        \n",
    "        # Extract chromosome-specific data\n",
    "        chr_lr = lr_data[indices]\n",
    "        chr_hr = hr_data[indices]\n",
    "        \n",
    "        # Fix dimensions if needed\n",
    "        if chr_lr.ndim == 4 and chr_lr.shape[1] == 1:\n",
    "            chr_lr = chr_lr[:, 0, :, :]\n",
    "        if chr_hr.ndim == 4 and chr_hr.shape[1] == 1:\n",
    "            chr_hr = chr_hr[:, 0, :, :]\n",
    "        \n",
    "        if chr_lr.ndim == 3:\n",
    "            chr_lr = np.expand_dims(chr_lr, axis=-1)\n",
    "        if chr_hr.ndim == 3:\n",
    "            chr_hr = np.expand_dims(chr_hr, axis=-1)\n",
    "        \n",
    "        # Predict in batches\n",
    "        chr_metrics = []\n",
    "        num_samples = len(chr_lr)\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, num_samples)\n",
    "            batch_lr = chr_lr[i:end_idx].astype('float32')\n",
    "            batch_hr = chr_hr[i:end_idx].astype('float32')\n",
    "            \n",
    "            # Predict\n",
    "            batch_pred = model.predict(batch_lr, verbose=0)\n",
    "            \n",
    "            # Calculate metrics for each sample in batch\n",
    "            for j in range(len(batch_lr)):\n",
    "                metrics = calculate_metrics(\n",
    "                    batch_pred[j, :, :, 0],\n",
    "                    batch_hr[j, :, :, 0]\n",
    "                )\n",
    "                chr_metrics.append(metrics)\n",
    "            \n",
    "            if (i + batch_size) % 100 == 0 or end_idx == num_samples:\n",
    "                print(f\"   Processed: {end_idx}/{num_samples} samples...\")\n",
    "        \n",
    "        # Average metrics for this chromosome\n",
    "        avg_metrics = {}\n",
    "        for key in chr_metrics[0].keys():\n",
    "            values = [m[key] for m in chr_metrics if not np.isnan(m[key])]\n",
    "            avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        results[chr_name.upper()] = avg_metrics\n",
    "        \n",
    "        print(f\"\\n   ðŸ“ˆ Results for {chr_name.upper()}:\")\n",
    "        print(f\"      MSE:  {avg_metrics['mse']:.6f}\")\n",
    "        print(f\"      MAE:  {avg_metrics['mae']:.6f}\")\n",
    "        print(f\"      PCC:  {avg_metrics['pcc']:.4f}\")\n",
    "        print(f\"      SSIM: {avg_metrics['ssim']:.4f}\")\n",
    "        print(f\"      PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def format_results_table(results):\n",
    "    \"\"\"\n",
    "    Format results in DiCARN-DNase paper style\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string table\n",
    "    \"\"\"\n",
    "    \n",
    "    if not results:\n",
    "        return \"No results to display\"\n",
    "    \n",
    "    # Create DataFrame\n",
    "    metrics = ['SSIM', 'PSNR', 'MSE', 'MAE', 'PCC']\n",
    "    chromosomes = sorted(results.keys())\n",
    "    \n",
    "    data = {}\n",
    "    for metric in metrics:\n",
    "        metric_lower = metric.lower()\n",
    "        values = []\n",
    "        for chr_name in chromosomes:\n",
    "            if metric_lower in results[chr_name]:\n",
    "                values.append(results[chr_name][metric_lower])\n",
    "            else:\n",
    "                values.append(np.nan)\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        valid_values = [v for v in values if not np.isnan(v)]\n",
    "        mean_val = np.mean(valid_values) if valid_values else np.nan\n",
    "        std_val = np.std(valid_values) if valid_values else np.nan\n",
    "        \n",
    "        # Add to data\n",
    "        data[metric] = values + [mean_val, std_val]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    index = chromosomes + ['Mean', 'Std']\n",
    "    df = pd.DataFrame(data, index=index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_comparison_table(results, method_name='HiC-SuperNet'):\n",
    "    \"\"\"\n",
    "    Print results in a format comparable to DiCARN-DNase paper Table 1\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“Š RESULTS TABLE - {method_name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    chromosomes = sorted(results.keys())\n",
    "    \n",
    "    # Prepare data\n",
    "    metrics_data = {\n",
    "        'SSIM': [],\n",
    "        'PSNR': [],\n",
    "        'MSE': [],\n",
    "        'MAE': [],\n",
    "        'PCC': []\n",
    "    }\n",
    "    \n",
    "    for chr_name in chromosomes:\n",
    "        for metric in metrics_data.keys():\n",
    "            metrics_data[metric].append(results[chr_name][metric.lower()])\n",
    "    \n",
    "    # Calculate mean Â± std\n",
    "    print(f\"\\n{'Metric':<10}\", end=\"\")\n",
    "    for chr_name in chromosomes:\n",
    "        print(f\"{chr_name:<12}\", end=\"\")\n",
    "    print(f\"{'Mean Â± SD':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric, values in metrics_data.items():\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        \n",
    "        print(f\"{metric:<10}\", end=\"\")\n",
    "        for val in values:\n",
    "            if metric == 'PSNR':\n",
    "                print(f\"{val:<12.2f}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"{val:<12.6f}\" if metric in ['MSE', 'MAE'] else f\"{val:<12.4f}\", end=\"\")\n",
    "        \n",
    "        if metric == 'PSNR':\n",
    "            print(f\"{mean_val:.2f} Â± {std_val:.2f}\")\n",
    "        elif metric in ['MSE', 'MAE']:\n",
    "            print(f\"{mean_val:.6f} Â± {std_val:.6f}\")\n",
    "        else:\n",
    "            print(f\"{mean_val:.4f} Â± {std_val:.4f}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Print in bold the best scores section\n",
    "    print(\"\\nðŸ† SUMMARY (Mean Â± SD):\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric, values in metrics_data.items():\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        \n",
    "        if metric == 'PSNR':\n",
    "            print(f\"   {metric}: {mean_val:.2f} Â± {std_val:.2f} dB\")\n",
    "        elif metric in ['MSE', 'MAE']:\n",
    "            print(f\"   {metric}: {mean_val:.6f} Â± {std_val:.6f}\")\n",
    "        else:\n",
    "            print(f\"   {metric}: {mean_val:.4f} Â± {std_val:.4f}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# ==================== Main Evaluation Function ====================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main evaluation script\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = 'best_hic_supernet.keras'\n",
    "    TEST_NPZ_PATH = 'hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz'\n",
    "    TARGET_CHROMOSOMES = ['chr4', 'chr14', 'chr16', 'chr20']\n",
    "    BATCH_SIZE = 16\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ§¬ CHROMOSOME-WISE EVALUATION FOR HiC-SuperNet\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nðŸ“‚ Loading model from: {MODEL_PATH}\")\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_PATH,\n",
    "        custom_objects={\n",
    "            'improved_loss': improved_loss,\n",
    "            'MultiScaleDilatedResBlock': MultiScaleDilatedResBlock,\n",
    "            'DualAttention': DualAttention\n",
    "        }\n",
    "    )\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "    \n",
    "    # Evaluate chromosome-wise\n",
    "    results = evaluate_chromosome_wise(\n",
    "        model=model,\n",
    "        test_npz_path=TEST_NPZ_PATH,\n",
    "        target_chromosomes=TARGET_CHROMOSOMES,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Print results table\n",
    "    print_comparison_table(results, method_name='HiC-SuperNet')\n",
    "    \n",
    "    # Save results to CSV\n",
    "    df = format_results_table(results)\n",
    "    csv_filename = 'chromosome_wise_results.csv'\n",
    "    df.to_csv(csv_filename)\n",
    "    print(f\"\\nðŸ’¾ Results saved to: {csv_filename}\")\n",
    "    \n",
    "    print(\"\\nâœ… Evaluation complete!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce1efc-7fe5-4de0-a19e-f1b72a1bb61e",
   "metadata": {},
   "source": [
    "#Cross-Cell Heatmap Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d18bc55-cf6c-4c5d-a5df-c44e9fe72482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸŽ¨ HEATMAP VISUALIZATION FOR HiC-SuperNet\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ Loading model from: best_hic_supernet.keras\n",
      "âœ“ Model loaded successfully\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š Creating Multi-Chromosome Heatmap (DiCARN Figure 3 style)\n",
      "================================================================================\n",
      "================================================================================\n",
      "ðŸŽ¨ Creating Heatmap Visualizations\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ Loading test data...\n",
      "\n",
      "ðŸ§¬ Processing CHR4...\n",
      "   âœ“ SSIM: 0.9582\n",
      "\n",
      "ðŸ§¬ Processing CHR14...\n",
      "   âœ“ SSIM: 0.9693\n",
      "\n",
      "ðŸ§¬ Processing CHR20...\n",
      "   âœ“ SSIM: 0.8810\n",
      "\n",
      "ðŸ’¾ Figure saved to: chromosome_heatmap_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“Š Creating Detailed Comparison for Chr4\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¨ Creating detailed comparison for CHR4...\n",
      "ðŸ’¾ Saved to: chr4_detailed_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All visualizations complete!\n",
      "\n",
      "ðŸ“ Generated files:\n",
      "   1. chromosome_heatmap_comparison.png\n",
      "   2. chr4_detailed_comparison.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# ==================== GPU Configuration ====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš  GPU warning: {e}\")\n",
    "\n",
    "# ==================== Load Custom Layers ====================\n",
    "class MultiScaleDilatedResBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(MultiScaleDilatedResBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        \n",
    "        self.conv_d1 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=1)\n",
    "        self.conv_d2 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=2)\n",
    "        self.conv_d4 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=4)\n",
    "        \n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.relu1 = keras.layers.ReLU()\n",
    "        \n",
    "        self.conv2 = keras.layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.shortcut_conv = keras.layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        shortcut = self.shortcut_conv(x)\n",
    "        \n",
    "        d1 = self.conv_d1(x)\n",
    "        d2 = self.conv_d2(x)\n",
    "        d4 = self.conv_d4(x)\n",
    "        \n",
    "        out = keras.layers.Concatenate()([d1, d2, d4])\n",
    "        out = self.bn1(out, training=training)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out, training=training)\n",
    "        \n",
    "        out = keras.layers.Add()([out, shortcut])\n",
    "        out = keras.layers.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'filters': self.filters})\n",
    "        return config\n",
    "\n",
    "class DualAttention(keras.layers.Layer):\n",
    "    def __init__(self, filters, reduction=8, **kwargs):\n",
    "        super(DualAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        self.gap = keras.layers.GlobalAveragePooling2D(keepdims=True)\n",
    "        self.gmp = keras.layers.GlobalMaxPooling2D(keepdims=True)\n",
    "        self.fc1 = keras.layers.Dense(filters // reduction, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(filters)\n",
    "        \n",
    "        self.spatial_conv = keras.layers.Conv2D(1, 7, padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        avg_pool = self.gap(x)\n",
    "        max_pool = self.gmp(x)\n",
    "        \n",
    "        avg_pool = tf.reshape(avg_pool, [-1, self.filters])\n",
    "        max_pool = tf.reshape(max_pool, [-1, self.filters])\n",
    "        \n",
    "        avg_out = self.fc2(self.fc1(avg_pool))\n",
    "        max_out = self.fc2(self.fc1(max_pool))\n",
    "        \n",
    "        channel_att = tf.nn.sigmoid(avg_out + max_out)\n",
    "        channel_att = tf.reshape(channel_att, [-1, 1, 1, self.filters])\n",
    "        \n",
    "        x = x * channel_att\n",
    "        \n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        concat = keras.layers.Concatenate()([avg_out, max_out])\n",
    "        \n",
    "        spatial_att = tf.nn.sigmoid(self.spatial_conv(concat))\n",
    "        x = x * spatial_att\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'reduction': self.reduction\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def improved_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[1], tf.shape(y_pred)[2], 1])\n",
    "    \n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    mae_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \n",
    "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "    \n",
    "    y_true_mean = tf.reduce_mean(y_true_flat, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred_flat, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_centered = y_true_flat - y_true_mean\n",
    "    y_pred_centered = y_pred_flat - y_pred_mean\n",
    "    \n",
    "    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    denominator = tf.sqrt(\n",
    "        tf.reduce_sum(tf.square(y_true_centered), axis=1) * \n",
    "        tf.reduce_sum(tf.square(y_pred_centered), axis=1)\n",
    "    )\n",
    "    \n",
    "    pearson = numerator / (denominator + 1e-8)\n",
    "    pearson_loss = 1 - tf.reduce_mean(pearson)\n",
    "    \n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    \n",
    "    total_loss = (\n",
    "        0.4 * mse_loss + \n",
    "        0.2 * mae_loss +\n",
    "        0.3 * pearson_loss + \n",
    "        0.1 * ssim_loss\n",
    "    )\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# ==================== Metrics ====================\n",
    "def calculate_ssim(img1, img2, C1=1e-4, C2=9e-4):\n",
    "    \"\"\"Calculate SSIM\"\"\"\n",
    "    img1 = img1.flatten()\n",
    "    img2 = img2.flatten()\n",
    "    \n",
    "    mu1 = np.mean(img1)\n",
    "    mu2 = np.mean(img2)\n",
    "    sigma1 = np.std(img1)\n",
    "    sigma2 = np.std(img2)\n",
    "    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))\n",
    "    \n",
    "    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1**2 + sigma2**2 + C2))\n",
    "    \n",
    "    return ssim\n",
    "\n",
    "# ==================== Visualization Functions ====================\n",
    "def create_heatmap_comparison(ground_truth, low_res, prediction, \n",
    "                              chromosome='Chr4', ssim_score=None,\n",
    "                              figsize=(15, 5), cmap='Reds', vmin=0, vmax=1):\n",
    "   \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    \n",
    "    # Ground Truth\n",
    "    im1 = axes[0].imshow(ground_truth, cmap=cmap, vmin=vmin, vmax=vmax, \n",
    "                         aspect='auto', interpolation='nearest')\n",
    "    axes[0].set_title('Ground Truth', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Low Resolution\n",
    "    im2 = axes[1].imshow(low_res, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "                         aspect='auto', interpolation='nearest')\n",
    "    axes[1].set_title('LR', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    im3 = axes[2].imshow(prediction, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "                         aspect='auto', interpolation='nearest')\n",
    "    \n",
    "    # Add SSIM score to prediction title\n",
    "    if ssim_score is not None:\n",
    "        axes[2].set_title(f'HiC-SuperNet\\nSSIM: {ssim_score:.4f}', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        axes[2].set_title('HiC-SuperNet', fontsize=14, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(im3, ax=axes, orientation='vertical', \n",
    "                       fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Interaction Frequency', rotation=270, labelpad=20, fontsize=12)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle(f'{chromosome}', fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_multi_chromosome_visualization(model, test_npz_path, \n",
    "                                          chromosomes=['chr4', 'chr14', 'chr20'],\n",
    "                                          samples_per_chr=1,\n",
    "                                          save_path='heatmap_visualization.png',\n",
    "                                          figsize=(15, 12)):\n",
    "   \n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸŽ¨ Creating Heatmap Visualizations\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load test data\n",
    "    print(f\"\\nðŸ“‚ Loading test data...\")\n",
    "    data = np.load(test_npz_path, allow_pickle=True)\n",
    "    lr_data = data['data']\n",
    "    hr_data = data['target']\n",
    "    inds = data['inds']\n",
    "    \n",
    "    # Extract chromosome info\n",
    "    chromosome_labels = []\n",
    "    for ind in inds:\n",
    "        if isinstance(ind, (list, tuple, np.ndarray)):\n",
    "            chr_num = ind[0] if len(ind) > 0 else None\n",
    "        else:\n",
    "            chr_num = ind\n",
    "        \n",
    "        if chr_num is not None:\n",
    "            if isinstance(chr_num, (int, np.integer)):\n",
    "                chr_name = f'chr{chr_num}'\n",
    "            else:\n",
    "                chr_name = str(chr_num).lower()\n",
    "        else:\n",
    "            chr_name = 'unknown'\n",
    "        \n",
    "        chromosome_labels.append(chr_name)\n",
    "    \n",
    "    # Group by chromosome\n",
    "    chromosome_dict = {}\n",
    "    for i, chr_name in enumerate(chromosome_labels):\n",
    "        if chr_name not in chromosome_dict:\n",
    "            chromosome_dict[chr_name] = []\n",
    "        chromosome_dict[chr_name].append(i)\n",
    "    \n",
    "    # Create figure\n",
    "    n_rows = len(chromosomes)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = gridspec.GridSpec(n_rows, 3, hspace=0.3, wspace=0.1)\n",
    "    \n",
    "    for row_idx, chr_name in enumerate(chromosomes):\n",
    "        chr_name_lower = chr_name.lower()\n",
    "        \n",
    "        # Find matching chromosome\n",
    "        matching_chr = None\n",
    "        for key in chromosome_dict.keys():\n",
    "            if chr_name_lower in key.lower():\n",
    "                matching_chr = key\n",
    "                break\n",
    "        \n",
    "        if matching_chr is None:\n",
    "            print(f\"âš  Warning: {chr_name} not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nðŸ§¬ Processing {chr_name.upper()}...\")\n",
    "        \n",
    "        # Get random sample from this chromosome\n",
    "        indices = chromosome_dict[matching_chr]\n",
    "        sample_idx = np.random.choice(indices, 1)[0]\n",
    "        \n",
    "        # Get data\n",
    "        lr_sample = lr_data[sample_idx]\n",
    "        hr_sample = hr_data[sample_idx]\n",
    "        \n",
    "        # Fix dimensions\n",
    "        if lr_sample.ndim == 3 and lr_sample.shape[0] == 1:\n",
    "            lr_sample = lr_sample[0]\n",
    "        if hr_sample.ndim == 3 and hr_sample.shape[0] == 1:\n",
    "            hr_sample = hr_sample[0]\n",
    "        \n",
    "        lr_input = np.expand_dims(np.expand_dims(lr_sample, axis=0), axis=-1).astype('float32')\n",
    "        \n",
    "        # Predict\n",
    "        pred_sample = model.predict(lr_input, verbose=0)[0, :, :, 0]\n",
    "        \n",
    "        # Calculate SSIM\n",
    "        ssim_score = calculate_ssim(pred_sample, hr_sample)\n",
    "        \n",
    "        # Normalize for visualization\n",
    "        vmax = max(np.max(hr_sample), np.max(pred_sample))\n",
    "        vmin = 0\n",
    "        \n",
    "        # Plot Ground Truth\n",
    "        ax1 = fig.add_subplot(gs[row_idx, 0])\n",
    "        im1 = ax1.imshow(hr_sample, cmap='Reds', vmin=vmin, vmax=vmax, \n",
    "                        aspect='auto', interpolation='nearest')\n",
    "        if row_idx == 0:\n",
    "            ax1.set_title('Ground Truth', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel(chr_name.upper(), fontsize=12, fontweight='bold')\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        \n",
    "        # Plot LR\n",
    "        ax2 = fig.add_subplot(gs[row_idx, 1])\n",
    "        im2 = ax2.imshow(lr_sample, cmap='Reds', vmin=vmin, vmax=vmax,\n",
    "                        aspect='auto', interpolation='nearest')\n",
    "        if row_idx == 0:\n",
    "            ax2.set_title('LR', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        \n",
    "        # Plot Prediction\n",
    "        ax3 = fig.add_subplot(gs[row_idx, 2])\n",
    "        im3 = ax3.imshow(pred_sample, cmap='Reds', vmin=vmin, vmax=vmax,\n",
    "                        aspect='auto', interpolation='nearest')\n",
    "        if row_idx == 0:\n",
    "            ax3.set_title('HiC-SuperNet', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add SSIM score\n",
    "        ax3.text(0.5, -0.15, f'SSIM: {ssim_score:.4f}', \n",
    "                transform=ax3.transAxes, ha='center', fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        ax3.set_xticks([])\n",
    "        ax3.set_yticks([])\n",
    "        \n",
    "        print(f\"   âœ“ SSIM: {ssim_score:.4f}\")\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im3, cax=cbar_ax)\n",
    "    cbar.set_label('Normalized Interaction Frequency', rotation=270, labelpad=20, fontsize=12)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle('Cross-Cell Hi-C Enhancement Results', \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nðŸ’¾ Figure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_detailed_comparison(model, test_npz_path, chromosome='chr4',\n",
    "                               num_samples=3, save_path='detailed_comparison.png'):\n",
    "    \"\"\"\n",
    "    Create detailed comparison with multiple samples from one chromosome\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nðŸŽ¨ Creating detailed comparison for {chromosome.upper()}...\")\n",
    "    \n",
    "    # Load data\n",
    "    data = np.load(test_npz_path, allow_pickle=True)\n",
    "    lr_data = data['data']\n",
    "    hr_data = data['target']\n",
    "    inds = data['inds']\n",
    "    \n",
    "    # Extract chromosome info\n",
    "    chromosome_labels = []\n",
    "    for ind in inds:\n",
    "        if isinstance(ind, (list, tuple, np.ndarray)):\n",
    "            chr_num = ind[0] if len(ind) > 0 else None\n",
    "        else:\n",
    "            chr_num = ind\n",
    "        \n",
    "        if chr_num is not None:\n",
    "            if isinstance(chr_num, (int, np.integer)):\n",
    "                chr_name = f'chr{chr_num}'\n",
    "            else:\n",
    "                chr_name = str(chr_num).lower()\n",
    "        else:\n",
    "            chr_name = 'unknown'\n",
    "        \n",
    "        chromosome_labels.append(chr_name)\n",
    "    \n",
    "    # Find chromosome samples\n",
    "    chr_indices = [i for i, label in enumerate(chromosome_labels) \n",
    "                   if chromosome.lower() in label.lower()]\n",
    "    \n",
    "    if len(chr_indices) == 0:\n",
    "        print(f\"âš  No samples found for {chromosome}\")\n",
    "        return None\n",
    "    \n",
    "    # Select random samples\n",
    "    selected_indices = np.random.choice(chr_indices, \n",
    "                                       min(num_samples, len(chr_indices)), \n",
    "                                       replace=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, idx in enumerate(selected_indices):\n",
    "        # Get data\n",
    "        lr_sample = lr_data[idx]\n",
    "        hr_sample = hr_data[idx]\n",
    "        \n",
    "        # Fix dimensions\n",
    "        if lr_sample.ndim == 3 and lr_sample.shape[0] == 1:\n",
    "            lr_sample = lr_sample[0]\n",
    "        if hr_sample.ndim == 3 and hr_sample.shape[0] == 1:\n",
    "            hr_sample = hr_sample[0]\n",
    "        \n",
    "        lr_input = np.expand_dims(np.expand_dims(lr_sample, axis=0), axis=-1).astype('float32')\n",
    "        \n",
    "        # Predict\n",
    "        pred_sample = model.predict(lr_input, verbose=0)[0, :, :, 0]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        ssim_score = calculate_ssim(pred_sample, hr_sample)\n",
    "        \n",
    "        # Normalize\n",
    "        vmax = max(np.max(hr_sample), np.max(pred_sample))\n",
    "        \n",
    "        # Plot\n",
    "        axes[row, 0].imshow(hr_sample, cmap='Reds', vmin=0, vmax=vmax)\n",
    "        axes[row, 0].set_title(f'Ground Truth - Sample {row+1}', fontweight='bold')\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        axes[row, 1].imshow(lr_sample, cmap='Reds', vmin=0, vmax=vmax)\n",
    "        axes[row, 1].set_title(f'LR - Sample {row+1}', fontweight='bold')\n",
    "        axes[row, 1].axis('off')\n",
    "        \n",
    "        axes[row, 2].imshow(pred_sample, cmap='Reds', vmin=0, vmax=vmax)\n",
    "        axes[row, 2].set_title(f'HiC-SuperNet - SSIM: {ssim_score:.4f}', fontweight='bold')\n",
    "        axes[row, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{chromosome.upper()} - Detailed Comparison', \n",
    "                fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"ðŸ’¾ Saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ==================== Main Function ====================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main visualization script\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = 'best_hic_supernet.keras'\n",
    "    TEST_NPZ_PATH = 'hicarn_10kb40kb_c40_s40_b201_nonpool_GM12878_test.npz'\n",
    "    CHROMOSOMES = ['chr4', 'chr14', 'chr20']\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸŽ¨ HEATMAP VISUALIZATION FOR HiC-SuperNet\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nðŸ“‚ Loading model from: {MODEL_PATH}\")\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_PATH,\n",
    "        custom_objects={\n",
    "            'improved_loss': improved_loss,\n",
    "            'MultiScaleDilatedResBlock': MultiScaleDilatedResBlock,\n",
    "            'DualAttention': DualAttention\n",
    "        }\n",
    "    )\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "    \n",
    "    # Create multi-chromosome visualization\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š Creating Multi-Chromosome Heatmap (DiCARN Figure 3 style)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    fig1 = create_multi_chromosome_visualization(\n",
    "        model=model,\n",
    "        test_npz_path=TEST_NPZ_PATH,\n",
    "        chromosomes=CHROMOSOMES,\n",
    "        save_path='chromosome_heatmap_comparison.png',\n",
    "        figsize=(15, 12)\n",
    "    )\n",
    "    \n",
    "    # Create detailed comparison for Chr4\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š Creating Detailed Comparison for Chr4\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    fig2 = create_detailed_comparison(\n",
    "        model=model,\n",
    "        test_npz_path=TEST_NPZ_PATH,\n",
    "        chromosome='chr4',\n",
    "        num_samples=3,\n",
    "        save_path='chr4_detailed_comparison.png'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… All visualizations complete!\")\n",
    "    print(\"\\nðŸ“ Generated files:\")\n",
    "    print(\"   1. chromosome_heatmap_comparison.png\")\n",
    "    print(\"   2. chr4_detailed_comparison.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8e17d-1288-4f8a-a88d-fbf8e3477c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b7b58-bb1a-4cf7-8fce-b9267ed2cdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393d50c-e9dc-4e71-a8cb-2641eee8178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9932fdc-a686-43db-bfdc-31888a29dda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu-01)",
   "language": "python",
   "name": "tensorflow-gpu-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
