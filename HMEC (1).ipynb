{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61e48fb-0c86-4472-b3a7-ee95e00cc642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Proly Kumar\\AppData\\Local\\anaconda3\\envs\\tensorflow-gpu-01\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ§¬ CHROMOSOME-WISE EVALUATION FOR HiC-SuperNet\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ Loading model from: best_hic_supernet.keras\n",
      "âœ“ Model loaded successfully\n",
      "================================================================================\n",
      "ðŸ“Š CHROMOSOME-WISE EVALUATION\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‚ Loading test data from: hicarn_10kb40kb_c40_s40_b201_nonpool_HMEC_test.npz\n",
      "âœ“ Total samples loaded: 11144\n",
      "\n",
      "ðŸ“‹ Chromosomes found in dataset:\n",
      "   chr14: 2368 samples\n",
      "   chr16: 2060 samples\n",
      "   chr20: 1598 samples\n",
      "   chr4: 5118 samples\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR4...\n",
      "================================================================================\n",
      "   Samples: 5118\n",
      "   Processed: 400/5118 samples...\n",
      "   Processed: 800/5118 samples...\n",
      "   Processed: 1200/5118 samples...\n",
      "   Processed: 1600/5118 samples...\n",
      "   Processed: 2000/5118 samples...\n",
      "   Processed: 2400/5118 samples...\n",
      "   Processed: 2800/5118 samples...\n",
      "   Processed: 3200/5118 samples...\n",
      "   Processed: 3600/5118 samples...\n",
      "   Processed: 4000/5118 samples...\n",
      "   Processed: 4400/5118 samples...\n",
      "   Processed: 4800/5118 samples...\n",
      "   Processed: 5118/5118 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR4:\n",
      "      MSE:  0.000738\n",
      "      MAE:  0.005218\n",
      "      PCC:  0.4219\n",
      "      SSIM: 0.9200\n",
      "      PSNR: 18.86 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR14...\n",
      "================================================================================\n",
      "   Samples: 2368\n",
      "   Processed: 400/2368 samples...\n",
      "   Processed: 800/2368 samples...\n",
      "   Processed: 1200/2368 samples...\n",
      "   Processed: 1600/2368 samples...\n",
      "   Processed: 2000/2368 samples...\n",
      "   Processed: 2368/2368 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR14:\n",
      "      MSE:  0.000917\n",
      "      MAE:  0.005483\n",
      "      PCC:  0.4226\n",
      "      SSIM: 0.9176\n",
      "      PSNR: 18.59 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR16...\n",
      "================================================================================\n",
      "   Samples: 2060\n",
      "   Processed: 400/2060 samples...\n",
      "   Processed: 800/2060 samples...\n",
      "   Processed: 1200/2060 samples...\n",
      "   Processed: 1600/2060 samples...\n",
      "   Processed: 2000/2060 samples...\n",
      "   Processed: 2060/2060 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR16:\n",
      "      MSE:  0.001028\n",
      "      MAE:  0.005597\n",
      "      PCC:  0.4562\n",
      "      SSIM: 0.9167\n",
      "      PSNR: 20.11 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ§¬ Evaluating CHR20...\n",
      "================================================================================\n",
      "   Samples: 1598\n",
      "   Processed: 400/1598 samples...\n",
      "   Processed: 800/1598 samples...\n",
      "   Processed: 1200/1598 samples...\n",
      "   Processed: 1598/1598 samples...\n",
      "\n",
      "   ðŸ“ˆ Results for CHR20:\n",
      "      MSE:  0.001155\n",
      "      MAE:  0.005904\n",
      "      PCC:  0.4410\n",
      "      SSIM: 0.9191\n",
      "      PSNR: 18.70 dB\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š RESULTS TABLE - HiC-SuperNet\n",
      "================================================================================\n",
      "\n",
      "Metric    CHR14       CHR16       CHR20       CHR4        Mean Â± SD           \n",
      "--------------------------------------------------------------------------------\n",
      "SSIM      0.9176      0.9167      0.9191      0.9200      0.9184 Â± 0.0013\n",
      "PSNR      18.59       20.11       18.70       18.86       19.06 Â± 0.61\n",
      "MSE       0.000917    0.001028    0.001155    0.000738    0.000959 Â± 0.000153\n",
      "MAE       0.005483    0.005597    0.005904    0.005218    0.005551 Â± 0.000246\n",
      "PCC       0.4226      0.4562      0.4410      0.4219      0.4354 Â± 0.0142\n",
      "================================================================================\n",
      "\n",
      "ðŸ† SUMMARY (Mean Â± SD):\n",
      "----------------------------------------\n",
      "   SSIM: 0.9184 Â± 0.0013\n",
      "   PSNR: 19.06 Â± 0.61 dB\n",
      "   MSE: 0.000959 Â± 0.000153\n",
      "   MAE: 0.005551 Â± 0.000246\n",
      "   PCC: 0.4354 Â± 0.0142\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¾ Results saved to: chromosome_wise_results.csv\n",
      "\n",
      "âœ… Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Chromosome-wise Evaluation for HiC-SuperNet\n",
    "============================================\n",
    "\n",
    "Evaluates model performance on specific chromosomes:\n",
    "- Chr4, Chr14, Chr16, Chr20\n",
    "- Computes Mean Â± SD across chromosomes\n",
    "- Comparable to DiCARN-DNase paper format\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# ==================== GPU Configuration ====================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš  GPU warning: {e}\")\n",
    "\n",
    "# ==================== Load Custom Layers ====================\n",
    "class MultiScaleDilatedResBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(MultiScaleDilatedResBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        \n",
    "        self.conv_d1 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=1)\n",
    "        self.conv_d2 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=2)\n",
    "        self.conv_d4 = keras.layers.Conv2D(filters // 3, 3, padding='same', dilation_rate=4)\n",
    "        \n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.relu1 = keras.layers.ReLU()\n",
    "        \n",
    "        self.conv2 = keras.layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.shortcut_conv = keras.layers.Conv2D(filters, 1, padding='same')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        shortcut = self.shortcut_conv(x)\n",
    "        \n",
    "        d1 = self.conv_d1(x)\n",
    "        d2 = self.conv_d2(x)\n",
    "        d4 = self.conv_d4(x)\n",
    "        \n",
    "        out = keras.layers.Concatenate()([d1, d2, d4])\n",
    "        out = self.bn1(out, training=training)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out, training=training)\n",
    "        \n",
    "        out = keras.layers.Add()([out, shortcut])\n",
    "        out = keras.layers.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'filters': self.filters})\n",
    "        return config\n",
    "\n",
    "class DualAttention(keras.layers.Layer):\n",
    "    def __init__(self, filters, reduction=8, **kwargs):\n",
    "        super(DualAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        self.gap = keras.layers.GlobalAveragePooling2D(keepdims=True)\n",
    "        self.gmp = keras.layers.GlobalMaxPooling2D(keepdims=True)\n",
    "        self.fc1 = keras.layers.Dense(filters // reduction, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(filters)\n",
    "        \n",
    "        self.spatial_conv = keras.layers.Conv2D(1, 7, padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        avg_pool = self.gap(x)\n",
    "        max_pool = self.gmp(x)\n",
    "        \n",
    "        avg_pool = tf.reshape(avg_pool, [-1, self.filters])\n",
    "        max_pool = tf.reshape(max_pool, [-1, self.filters])\n",
    "        \n",
    "        avg_out = self.fc2(self.fc1(avg_pool))\n",
    "        max_out = self.fc2(self.fc1(max_pool))\n",
    "        \n",
    "        channel_att = tf.nn.sigmoid(avg_out + max_out)\n",
    "        channel_att = tf.reshape(channel_att, [-1, 1, 1, self.filters])\n",
    "        \n",
    "        x = x * channel_att\n",
    "        \n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        concat = keras.layers.Concatenate()([avg_out, max_out])\n",
    "        \n",
    "        spatial_att = tf.nn.sigmoid(self.spatial_conv(concat))\n",
    "        x = x * spatial_att\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'reduction': self.reduction\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def improved_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1, tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, tf.shape(y_pred)[1], tf.shape(y_pred)[2], 1])\n",
    "    \n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    mae_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    \n",
    "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "    \n",
    "    y_true_mean = tf.reduce_mean(y_true_flat, axis=1, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred_flat, axis=1, keepdims=True)\n",
    "    \n",
    "    y_true_centered = y_true_flat - y_true_mean\n",
    "    y_pred_centered = y_pred_flat - y_pred_mean\n",
    "    \n",
    "    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    denominator = tf.sqrt(\n",
    "        tf.reduce_sum(tf.square(y_true_centered), axis=1) * \n",
    "        tf.reduce_sum(tf.square(y_pred_centered), axis=1)\n",
    "    )\n",
    "    \n",
    "    pearson = numerator / (denominator + 1e-8)\n",
    "    pearson_loss = 1 - tf.reduce_mean(pearson)\n",
    "    \n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    \n",
    "    total_loss = (\n",
    "        0.4 * mse_loss + \n",
    "        0.2 * mae_loss +\n",
    "        0.3 * pearson_loss + \n",
    "        0.1 * ssim_loss\n",
    "    )\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# ==================== Metrics Functions ====================\n",
    "def calculate_ssim(img1, img2, C1=1e-4, C2=9e-4):\n",
    "    \"\"\"Calculate SSIM between two images\"\"\"\n",
    "    img1 = img1.flatten()\n",
    "    img2 = img2.flatten()\n",
    "    \n",
    "    mu1 = np.mean(img1)\n",
    "    mu2 = np.mean(img2)\n",
    "    sigma1 = np.std(img1)\n",
    "    sigma2 = np.std(img2)\n",
    "    sigma12 = np.mean((img1 - mu1) * (img2 - mu2))\n",
    "    \n",
    "    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1**2 + sigma2**2 + C2))\n",
    "    \n",
    "    return ssim\n",
    "\n",
    "def calculate_psnr(img1, img2, max_val=None):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    mse = mean_squared_error(img1.flatten(), img2.flatten())\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    if max_val is None:\n",
    "        max_val = max(np.max(img1), np.max(img2))\n",
    "    \n",
    "    psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_metrics(pred, target):\n",
    "    \"\"\"Calculate all metrics for a single sample\"\"\"\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    \n",
    "    mse = mean_squared_error(target_flat, pred_flat)\n",
    "    mae = mean_absolute_error(target_flat, pred_flat)\n",
    "    \n",
    "    if np.std(pred_flat) == 0 or np.std(target_flat) == 0:\n",
    "        pcc = np.nan\n",
    "    else:\n",
    "        pcc, _ = pearsonr(pred_flat, target_flat)\n",
    "    \n",
    "    ssim = calculate_ssim(pred, target)\n",
    "    psnr = calculate_psnr(pred, target)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'pcc': pcc,\n",
    "        'ssim': ssim,\n",
    "        'psnr': psnr\n",
    "    }\n",
    "\n",
    "# ==================== Chromosome-wise Evaluation ====================\n",
    "def evaluate_chromosome_wise(model, test_npz_path, target_chromosomes=['chr4', 'chr14', 'chr16', 'chr20'], \n",
    "                             batch_size=16):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on specific chromosomes\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        test_npz_path: Path to test npz file\n",
    "        target_chromosomes: List of chromosome names to evaluate\n",
    "        batch_size: Batch size for prediction\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with chromosome-wise results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ“Š CHROMOSOME-WISE EVALUATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load test data\n",
    "    print(f\"\\nðŸ“‚ Loading test data from: {test_npz_path}\")\n",
    "    data = np.load(test_npz_path, allow_pickle=True)\n",
    "    lr_data = data['data']\n",
    "    hr_data = data['target']\n",
    "    inds = data['inds']\n",
    "    \n",
    "    print(f\"âœ“ Total samples loaded: {len(lr_data)}\")\n",
    "    \n",
    "    # Process chromosome information\n",
    "    # inds format: typically contains chromosome and position info\n",
    "    # Extract chromosome labels from inds\n",
    "    chromosome_labels = []\n",
    "    for ind in inds:\n",
    "        # ind is typically in format: (chr_num, start_pos, end_pos) or similar\n",
    "        if isinstance(ind, (list, tuple, np.ndarray)):\n",
    "            chr_num = ind[0] if len(ind) > 0 else None\n",
    "        else:\n",
    "            chr_num = ind\n",
    "        \n",
    "        # Convert to chromosome name\n",
    "        if chr_num is not None:\n",
    "            if isinstance(chr_num, (int, np.integer)):\n",
    "                chr_name = f'chr{chr_num}'\n",
    "            else:\n",
    "                chr_name = str(chr_num).lower()\n",
    "        else:\n",
    "            chr_name = 'unknown'\n",
    "        \n",
    "        chromosome_labels.append(chr_name)\n",
    "    \n",
    "    # Group samples by chromosome\n",
    "    chromosome_dict = {}\n",
    "    for i, chr_name in enumerate(chromosome_labels):\n",
    "        if chr_name not in chromosome_dict:\n",
    "            chromosome_dict[chr_name] = []\n",
    "        chromosome_dict[chr_name].append(i)\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Chromosomes found in dataset:\")\n",
    "    for chr_name, indices in sorted(chromosome_dict.items()):\n",
    "        print(f\"   {chr_name}: {len(indices)} samples\")\n",
    "    \n",
    "    # Evaluate each target chromosome\n",
    "    results = {}\n",
    "    \n",
    "    for chr_name in target_chromosomes:\n",
    "        chr_name_lower = chr_name.lower()\n",
    "        \n",
    "        # Find matching chromosome\n",
    "        matching_chr = None\n",
    "        for key in chromosome_dict.keys():\n",
    "            if chr_name_lower in key.lower():\n",
    "                matching_chr = key\n",
    "                break\n",
    "        \n",
    "        if matching_chr is None:\n",
    "            print(f\"\\nâš  Warning: {chr_name} not found in dataset, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ðŸ§¬ Evaluating {chr_name.upper()}...\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        indices = chromosome_dict[matching_chr]\n",
    "        print(f\"   Samples: {len(indices)}\")\n",
    "        \n",
    "        # Extract chromosome-specific data\n",
    "        chr_lr = lr_data[indices]\n",
    "        chr_hr = hr_data[indices]\n",
    "        \n",
    "        # Fix dimensions if needed\n",
    "        if chr_lr.ndim == 4 and chr_lr.shape[1] == 1:\n",
    "            chr_lr = chr_lr[:, 0, :, :]\n",
    "        if chr_hr.ndim == 4 and chr_hr.shape[1] == 1:\n",
    "            chr_hr = chr_hr[:, 0, :, :]\n",
    "        \n",
    "        if chr_lr.ndim == 3:\n",
    "            chr_lr = np.expand_dims(chr_lr, axis=-1)\n",
    "        if chr_hr.ndim == 3:\n",
    "            chr_hr = np.expand_dims(chr_hr, axis=-1)\n",
    "        \n",
    "        # Predict in batches\n",
    "        chr_metrics = []\n",
    "        num_samples = len(chr_lr)\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, num_samples)\n",
    "            batch_lr = chr_lr[i:end_idx].astype('float32')\n",
    "            batch_hr = chr_hr[i:end_idx].astype('float32')\n",
    "            \n",
    "            # Predict\n",
    "            batch_pred = model.predict(batch_lr, verbose=0)\n",
    "            \n",
    "            # Calculate metrics for each sample in batch\n",
    "            for j in range(len(batch_lr)):\n",
    "                metrics = calculate_metrics(\n",
    "                    batch_pred[j, :, :, 0],\n",
    "                    batch_hr[j, :, :, 0]\n",
    "                )\n",
    "                chr_metrics.append(metrics)\n",
    "            \n",
    "            if (i + batch_size) % 100 == 0 or end_idx == num_samples:\n",
    "                print(f\"   Processed: {end_idx}/{num_samples} samples...\")\n",
    "        \n",
    "        # Average metrics for this chromosome\n",
    "        avg_metrics = {}\n",
    "        for key in chr_metrics[0].keys():\n",
    "            values = [m[key] for m in chr_metrics if not np.isnan(m[key])]\n",
    "            avg_metrics[key] = np.mean(values) if values else np.nan\n",
    "        \n",
    "        results[chr_name.upper()] = avg_metrics\n",
    "        \n",
    "        print(f\"\\n   ðŸ“ˆ Results for {chr_name.upper()}:\")\n",
    "        print(f\"      MSE:  {avg_metrics['mse']:.6f}\")\n",
    "        print(f\"      MAE:  {avg_metrics['mae']:.6f}\")\n",
    "        print(f\"      PCC:  {avg_metrics['pcc']:.4f}\")\n",
    "        print(f\"      SSIM: {avg_metrics['ssim']:.4f}\")\n",
    "        print(f\"      PSNR: {avg_metrics['psnr']:.2f} dB\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def format_results_table(results):\n",
    "    \"\"\"\n",
    "    Format results in DiCARN-DNase paper style\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string table\n",
    "    \"\"\"\n",
    "    \n",
    "    if not results:\n",
    "        return \"No results to display\"\n",
    "    \n",
    "    # Create DataFrame\n",
    "    metrics = ['SSIM', 'PSNR', 'MSE', 'MAE', 'PCC']\n",
    "    chromosomes = sorted(results.keys())\n",
    "    \n",
    "    data = {}\n",
    "    for metric in metrics:\n",
    "        metric_lower = metric.lower()\n",
    "        values = []\n",
    "        for chr_name in chromosomes:\n",
    "            if metric_lower in results[chr_name]:\n",
    "                values.append(results[chr_name][metric_lower])\n",
    "            else:\n",
    "                values.append(np.nan)\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        valid_values = [v for v in values if not np.isnan(v)]\n",
    "        mean_val = np.mean(valid_values) if valid_values else np.nan\n",
    "        std_val = np.std(valid_values) if valid_values else np.nan\n",
    "        \n",
    "        # Add to data\n",
    "        data[metric] = values + [mean_val, std_val]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    index = chromosomes + ['Mean', 'Std']\n",
    "    df = pd.DataFrame(data, index=index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_comparison_table(results, method_name='HiC-SuperNet'):\n",
    "    \"\"\"\n",
    "    Print results in a format comparable to DiCARN-DNase paper Table 1\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ“Š RESULTS TABLE - {method_name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    chromosomes = sorted(results.keys())\n",
    "    \n",
    "    # Prepare data\n",
    "    metrics_data = {\n",
    "        'SSIM': [],\n",
    "        'PSNR': [],\n",
    "        'MSE': [],\n",
    "        'MAE': [],\n",
    "        'PCC': []\n",
    "    }\n",
    "    \n",
    "    for chr_name in chromosomes:\n",
    "        for metric in metrics_data.keys():\n",
    "            metrics_data[metric].append(results[chr_name][metric.lower()])\n",
    "    \n",
    "    # Calculate mean Â± std\n",
    "    print(f\"\\n{'Metric':<10}\", end=\"\")\n",
    "    for chr_name in chromosomes:\n",
    "        print(f\"{chr_name:<12}\", end=\"\")\n",
    "    print(f\"{'Mean Â± SD':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric, values in metrics_data.items():\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        \n",
    "        print(f\"{metric:<10}\", end=\"\")\n",
    "        for val in values:\n",
    "            if metric == 'PSNR':\n",
    "                print(f\"{val:<12.2f}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"{val:<12.6f}\" if metric in ['MSE', 'MAE'] else f\"{val:<12.4f}\", end=\"\")\n",
    "        \n",
    "        if metric == 'PSNR':\n",
    "            print(f\"{mean_val:.2f} Â± {std_val:.2f}\")\n",
    "        elif metric in ['MSE', 'MAE']:\n",
    "            print(f\"{mean_val:.6f} Â± {std_val:.6f}\")\n",
    "        else:\n",
    "            print(f\"{mean_val:.4f} Â± {std_val:.4f}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Print in bold the best scores section\n",
    "    print(\"\\nðŸ† SUMMARY (Mean Â± SD):\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric, values in metrics_data.items():\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        \n",
    "        if metric == 'PSNR':\n",
    "            print(f\"   {metric}: {mean_val:.2f} Â± {std_val:.2f} dB\")\n",
    "        elif metric in ['MSE', 'MAE']:\n",
    "            print(f\"   {metric}: {mean_val:.6f} Â± {std_val:.6f}\")\n",
    "        else:\n",
    "            print(f\"   {metric}: {mean_val:.4f} Â± {std_val:.4f}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# ==================== Main Evaluation Function ====================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main evaluation script\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = 'best_hic_supernet.keras'\n",
    "    TEST_NPZ_PATH = 'hicarn_10kb40kb_c40_s40_b201_nonpool_HMEC_test.npz'\n",
    "    TARGET_CHROMOSOMES = ['chr4', 'chr14', 'chr16', 'chr20']\n",
    "    BATCH_SIZE = 16\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ§¬ CHROMOSOME-WISE EVALUATION FOR HiC-SuperNet\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nðŸ“‚ Loading model from: {MODEL_PATH}\")\n",
    "    model = keras.models.load_model(\n",
    "        MODEL_PATH,\n",
    "        custom_objects={\n",
    "            'improved_loss': improved_loss,\n",
    "            'MultiScaleDilatedResBlock': MultiScaleDilatedResBlock,\n",
    "            'DualAttention': DualAttention\n",
    "        }\n",
    "    )\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "    \n",
    "    # Evaluate chromosome-wise\n",
    "    results = evaluate_chromosome_wise(\n",
    "        model=model,\n",
    "        test_npz_path=TEST_NPZ_PATH,\n",
    "        target_chromosomes=TARGET_CHROMOSOMES,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Print results table\n",
    "    print_comparison_table(results, method_name='HiC-SuperNet')\n",
    "    \n",
    "    # Save results to CSV\n",
    "    df = format_results_table(results)\n",
    "    csv_filename = 'chromosome_wise_results.csv'\n",
    "    df.to_csv(csv_filename)\n",
    "    print(f\"\\nðŸ’¾ Results saved to: {csv_filename}\")\n",
    "    \n",
    "    print(\"\\nâœ… Evaluation complete!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4b24b-77d7-4710-9aad-e119d5232f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adac8f-4324-4f3a-be58-ec8a2d4f9018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu-01)",
   "language": "python",
   "name": "tensorflow-gpu-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
